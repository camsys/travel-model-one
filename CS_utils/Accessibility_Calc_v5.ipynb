{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version notes\n",
    "# V4: added highway and transit perceived travel time accessibility measures, added percentage of regional employment accessible per employment category\n",
    "# V5: correct errors with transit access not being available\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from openpyxl import Workbook\n",
    "import openmatrix as omx\n",
    "import glob, os, sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skim_dir = r'C:\\MTC_tmpy\\TM2\\tm2py\\examples\\Link21_3332\\skims\\accessibility'\n",
    "skim_dir = r'C:\\Users\\jgliebe\\Documents\\Projects\\BART\\LandUseModeling\\Accessibilities\\variables\\acc_skims_121022'\n",
    "os.chdir(skim_dir)\n",
    "\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "#out_excel_fn = r'C:\\MTC_tmpy\\TM2\\tm2py\\examples\\Link21_3332\\skims\\accessibility\\acc_measures_{date}.xlsx'.format(date = current_date)\n",
    "out_excel_fn = r'C:\\Users\\jgliebe\\Documents\\Projects\\BART\\LandUseModeling\\Accessibilities\\variables\\accessibilityacc_measures_{date}.xlsx'.format(date = current_date)\n",
    "writer = pd.ExcelWriter(out_excel_fn, engine = 'openpyxl')\n",
    "writer.book = Workbook()\n",
    "\n",
    "#df_land_use = pd.read_csv(r\"C:\\MTC_tmpy\\TM2\\tm2py\\examples\\Link21_3332\\inputs\\landuse\\tazData.csv\")\n",
    "df_land_use = pd.read_csv(r\"C:\\Users\\jgliebe\\Documents\\Projects\\BART\\LandUseModeling\\Accessibilities\\variables\\tazData.csv\")\n",
    "num_zones = len(df_land_use)\n",
    "tt_matrices = {}\n",
    "\n",
    "#TODs = ['EA','AM','MD','PM','EV']\n",
    "TODs = ['AM'] #Can change later to include all TODs\n",
    "\n",
    "emp_type = ['TOTEMP','RETEMPN','HEREMPN','EMPRES']\n",
    "cutoff_start = [0, 10, 20, 30, 40, 50, 60, 70]\n",
    "cutoff_end = [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "perc_trans_bump = 40  # offset transit cutoff ranges due to perceived transit times being so much longer\n",
    "factor_trans_binsize = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOARDS', 'CROWD', 'DDIST', 'DTIME', 'FARE', 'IVT', 'IVTCOM', 'IVTEXP', 'IVTFRY', 'IVTHVY', 'IVTLOC', 'IVTLRT', 'IVTX', 'IWAIT', 'TRN_TOT_TIME', 'WACC', 'WAIT', 'WAUX', 'WEGR', 'XWAIT']\n"
     ]
    }
   ],
   "source": [
    "# Aggregate transit travel times into a single TRN_TOT_TIME core, divided by 100\n",
    "for tod in TODs:\n",
    "    for fn in glob.glob(f'trnskm*.omx'):\n",
    "        if tod in fn:\n",
    "            with omx.open_file(fn, 'a') as f:\n",
    "                print(f.list_matrices())\n",
    "                if 'IVTX' in f.list_matrices():\n",
    "                    del f['IVTX']\n",
    "                if 'TRN_TOT_TIME' in f.list_matrices():\n",
    "                    del f['TRN_TOT_TIME']\n",
    "                ivt = np.array(f['IVT'])\n",
    "                ivt1 = ivt * (ivt>0)\n",
    "                ivt0 = 99999 * (ivt==0)\n",
    "                ivtx = ivt0 + ivt1\n",
    "                f['IVTX'] = ivtx.reshape(len(f['IVT']),len(f['IVT']))\n",
    "                f['TRN_TOT_TIME'] = np.add.reduce([np.array(f[mat]) for mat in ['IVTX','IWAIT','XWAIT','WACC','WAUX','WEGR']])/ 100\n",
    "\n",
    "acc_mode_groups = {'HWYSKM':{'mode':'highway','core':'TIMEDA'},\n",
    "            'trnskm':{'mode':'transit','core':'TRN_TOT_TIME'},\n",
    "            'nonmotskm':{'mode':'non-motorized','core':'DISTWALK'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for access_type in acc_mode_groups:\n",
    "    for tod in TODs:\n",
    "        for fn in glob.glob(f'{access_type}*.omx'):\n",
    "            if access_type == 'nonmotskm' or tod in fn:\n",
    "                with omx.open_file(fn) as f:\n",
    "                    mode = acc_mode_groups[access_type]['mode']\n",
    "                    skim_array = np.array(f[acc_mode_groups[access_type]['core']])\n",
    "                    if acc_mode_groups[access_type]['core'] =='DISTWALK':\n",
    "                        skim_array = skim_array*20\n",
    "                    tt_matrices[(tod, mode)] = skim_array[:num_zones, :num_zones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df = pd.DataFrame(0, index = df_land_use.ZONE.values, columns = [])\n",
    "all_zones_df.index.name = 'zone_ID'\n",
    "\n",
    "all_zones_pct_df = pd.DataFrame(0, index = df_land_use.ZONE.values, columns = [])\n",
    "all_zones_pct_df.index.name = 'zone_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for employment in emp_type:\n",
    "    for tod in TODs:\n",
    "        for access_type in acc_mode_groups:\n",
    "            mode = acc_mode_groups[access_type]['mode']\n",
    "            new_key = (tod,mode)\n",
    "            if new_key in tt_matrices:\n",
    "                for (cutoff_s, cutoff_e) in zip(cutoff_start, cutoff_end):\n",
    "                    grp_tt = (tt_matrices[(tod,mode)])\n",
    "                    grp_tt = ((grp_tt >= cutoff_s) & (grp_tt < cutoff_e)).astype(int)\n",
    "                    all_zones_df[f'{employment}_{tod}_{mode}_{cutoff_s}_{cutoff_e}'] = (grp_tt*df_land_use[f'{employment}'].values).sum(axis=1)\n",
    "                    all_zones_pct_df[f'{employment}_{tod}_{mode}_{cutoff_s}_{cutoff_e}'] = (grp_tt*df_land_use[f'{employment}'].values).sum(axis=1) / df_land_use[f'{employment}'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df.to_excel(writer,sheet_name = 'simple')\n",
    "all_zones_pct_df.to_excel(writer,sheet_name = 'simple_PCT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessibility based on perceived time/cost\n",
    "ptt_matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highway parameters\n",
    "segment_suffixes = [\"LowInc\", \"MedInc\", \"HighInc\", \"XHighInc\"]\n",
    "cutoffs = [0, 30000, 60000, 100000]\n",
    "VOTs = {\"LowInc\": 6.01, \"MedInc\": 8.81, \"HighInc\": 10.44, \"XHighInc\": 12.86} # uses VOT according to mean HH income per TAZ\n",
    "hh = pd.read_csv('hhFile.2015.csv')\n",
    "hh_mean_inc = hh.groupby(['TAZ'])['HINC'].mean().reindex(df_land_use.ZONE.values).rename('mean_inc')\n",
    "hh_mean_inc = hh_mean_inc.fillna(hh.HINC.mean())\n",
    "assert len(hh_mean_inc) == len(df_land_use) and hh_mean_inc.isna().sum() == 0, 'HH mean income is incomplete'\n",
    "hh_mean_inc = hh_mean_inc.reset_index()\n",
    "hh_mean_inc['income_seg'] = pd.cut(hh_mean_inc['mean_inc'], right = False, bins = cutoffs + [float('inf')], labels = segment_suffixes).astype(str)\n",
    "hh_mean_inc['VOT_per_hour'] = hh_mean_inc['income_seg'].map(VOTs) \n",
    "hh_mean_inc['VOT_per_min'] = hh_mean_inc['VOT_per_hour']/ 60 # values from VOTs are in $/hour, convert into $/minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost units are cents, expressed in year 2000 dollars.\n",
    "for fn in glob.glob('hwyskm*.omx'):\n",
    "    for tod in TODs:\n",
    "        if tod in fn:\n",
    "            with omx.open_file(fn) as f:\n",
    "                mode = 'highway'\n",
    "                time_array = np.array(f['TIMEDA'])[:num_zones, :num_zones]\n",
    "                cost_array = np.array(f['COSTDA'])[:num_zones, :num_zones] / 100\n",
    "                toll_array = np.array(f['BTOLLDA'])[:num_zones, :num_zones] / 100 + np.array(f['VTOLLDA'])[:num_zones, :num_zones] / 100\n",
    "                p_time_array = time_array + np.divide(cost_array, hh_mean_inc.VOT_per_min.values[:,None]) + np.divide(toll_array, hh_mean_inc.VOT_per_min.values[:,None])  # broadcasting VOT values horizontally to get VOT by origin zone\n",
    "                ptt_matrices[(tod, mode)] = p_time_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transit\n",
    "waitThresh = 10 # 10 minutes per UEC\n",
    "coef_dict = {'IWAIT_S': 2, 'IWAIT_L': 1, 'XWAIT' : 2, 'WACC' : 2, 'WEGR' : 2, 'WAUX' : 2, 'CROWD' : 0} # 1.62\n",
    "\n",
    "#c_shortiWait\tShort initial wait time coefficient -- see \"waitThresh\"\t2.00 * c_ivt\n",
    "#c_longiWait\tLong initial wait time coefficient -- see \"waitThresh\"\t1.00 * c_ivt\n",
    "#c_wacc\tWalk access time coefficient\t2.00 * c_ivt\n",
    "#c_wegr\tWalk egress time coefficient\t2.00 * c_ivt\n",
    "#c_xwait Transfer wait time coefficient\t2.00 * c_ivt\n",
    "#c_waux\tWalk auxilliary time coefficient\t\t2.00 * c_ivt\n",
    "\n",
    "# short wait time: c_shortiWait*min(WLK_TRN_WLK_IWAIT[tripPeriod]/100,waitThresh)\n",
    "# long wait time: c_longiWait*max(WLK_TRN_WLK_IWAIT[tripPeriod]/100-waitThresh,0)\n",
    "# is the initial wait time reflected as a sum of both?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in glob.glob('trnskm*.omx'):\n",
    "    for tod in TODs:\n",
    "        if tod in fn:\n",
    "            with omx.open_file(fn) as f:\n",
    "                ptt = [np.array(f['IVTX']) / 100]\n",
    "                fare_array = np.array(f['FARE'])[:num_zones, :num_zones] / 100\n",
    "                mode = 'transit'\n",
    "                for OVTT in ['XWAIT','WACC','WEGR','WAUX','CROWD']:\n",
    "                    ptt.append(np.array(f[OVTT]) * coef_dict[OVTT] / 100)\n",
    "                IWAIT = coef_dict['IWAIT_S'] * np.array(f['IWAIT']) / 100 + coef_dict['IWAIT_L'] * np.clip(np.array(f['IWAIT'])/100 - waitThresh, a_min = 0, a_max = None)\n",
    "                ptt.append(IWAIT)\n",
    "                ptt_matrices[(tod, mode)] = np.add.reduce([mat[:num_zones, :num_zones] for mat in ptt]) + np.divide(fare_array, hh_mean_inc.VOT_per_min.values[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df = pd.DataFrame(0, index = df_land_use.ZONE.values, columns = [])\n",
    "all_zones_df.index.name = 'zone_ID'\n",
    "\n",
    "all_zones_pct_df = pd.DataFrame(0, index = df_land_use.ZONE.values, columns = [])\n",
    "all_zones_pct_df.index.name = 'zone_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for employment in emp_type:\n",
    "    for tod in TODs:        \n",
    "        for mode in ['highway','transit']:\n",
    "            new_key = (tod,mode)\n",
    "            if new_key in ptt_matrices:\n",
    "                for (cutoff_s, cutoff_e) in zip(cutoff_start, cutoff_end):\n",
    "                    if mode == 'transit':\n",
    "                        cutoff_s *= factor_trans_binsize\n",
    "                        cutoff_e *= factor_trans_binsize\n",
    "                        if cutoff_s > 0: \n",
    "                            cutoff_s += perc_trans_bump\n",
    "                            cutoff_e += perc_trans_bump\n",
    "                        else:\n",
    "                            cutoff_e += perc_trans_bump \n",
    "                    grp_tt = (ptt_matrices[(tod,mode)])\n",
    "                    grp_tt = ((grp_tt >= cutoff_s) & (grp_tt < cutoff_e)).astype(int)\n",
    "\n",
    "                    all_zones_df[f'{employment}_{tod}_{mode}_{int(cutoff_s)}_{int(cutoff_e)}'] = (grp_tt*df_land_use[f'{employment}'].values).sum(axis=1)\n",
    "                    all_zones_pct_df[f'{employment}_{tod}_{mode}_{int(cutoff_s)}_{int(cutoff_e)}'] = (grp_tt*df_land_use[f'{employment}'].values).sum(axis=1) / df_land_use[f'{employment}'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df.to_excel(writer,sheet_name = 'perceived_TT')\n",
    "all_zones_pct_df.to_excel(writer,sheet_name =  'perceived_TT_PCT')\n",
    "hh_mean_inc[['TAZ','mean_inc', 'income_seg', 'VOT_per_hour', 'VOT_per_min']].to_excel(writer,sheet_name = 'HH inc & VOT', index = False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
