{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessibility Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version notes\n",
    "# V4: added highway and transit perceived travel time accessibility measures, added percentage of regional employment accessible per employment category\n",
    "# V5: correct errors with transit access not being available\n",
    "# V6: add drive-access transit, combine with walk access; change access to EmpRes to reflect VOT/Income at destination\n",
    "# V7: remove drive access\n",
    "# v8: generalize -- final version\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from openpyxl import Workbook\n",
    "import openmatrix as omx\n",
    "import glob, os, sys\n",
    "\n",
    "from datetime import datetime\n",
    "current_date = datetime.now().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set year and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2015\n",
    "root_dir = r\"C:\\Users\\jgliebe\\Documents\\Projects\\BART\\Accessibilities\\variables\"\n",
    "\n",
    "# Skims\n",
    "#skim_dir = r'C:\\MTC_tmpy\\TM2\\tm2py\\examples\\Link21_3332\\skims\\accessibility'\n",
    "skim_dir = os.path.join(root_dir, \"acc_skims_sedata\", str(year))\n",
    "os.chdir(skim_dir)\n",
    "\n",
    "# Land Use\n",
    "#df_land_use = pd.read_csv(r\"C:\\MTC_tmpy\\TM2\\tm2py\\examples\\Link21_3332\\inputs\\landuse\\tazData.csv\")\n",
    "df_land_use = pd.read_csv(os.path.join(root_dir, \"acc_skims_sedata\", str(year), f\"tazdata_{year}.csv\"))\n",
    "num_zones = len(df_land_use)\n",
    "tt0_matrices = {}\n",
    "tt1_matrices = {}  # for use in orienting by hh income at destination\n",
    "\n",
    "# Households\n",
    "hh = pd.read_csv(os.path.join(root_dir, \"acc_skims_sedata\", str(year), f\"hhFile.{year}.csv\"))\n",
    "\n",
    "# Output Files\n",
    "#out_excel_fn = r'C:\\MTC_tmpy\\TM2\\tm2py\\examples\\Link21_3332\\skims\\accessibility\\acc_measures_{date}.xlsx'.format(date = current_date)\n",
    "out_excel_fn = os.path.join(root_dir, \"variables_out\", \"acc_measures_{}_{date}.xlsx\".format(year, date = current_date))\n",
    "writer = pd.ExcelWriter(out_excel_fn, engine = 'openpyxl')\n",
    "writer.book = Workbook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set time periods and employment types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODs = ['EA','AM','MD','PM','EV']\n",
    "TODs = ['AM'] #Can change later to include all TODs\n",
    "\n",
    "emp_type = ['TOTEMP','RETEMPN','HEREMPN','EMPRES']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household Income ID and VOT segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household Income ID and VOT segmentation\n",
    "segment_suffixes = [\"LowInc\", \"MedInc\", \"HighInc\", \"XHighInc\"]\n",
    "cutoffs = [0, 30000, 60000, 100000]\n",
    "inc_grp_nums = {\"LowInc\": 1, \"MedInc\": 2, \"HighInc\": 3, \"XHighInc\": 4}\n",
    "VOTs = {\"LowInc\": 6.01, \"MedInc\": 8.81, \"HighInc\": 10.44, \"XHighInc\": 12.86} # uses VOT according to mean HH income per TAZ\n",
    "hh_mean_inc = hh.groupby(['TAZ'])['HINC'].mean().reindex(df_land_use.ZONE.values).rename('mean_inc')\n",
    "hh_mean_inc = hh_mean_inc.fillna(hh.HINC.mean())\n",
    "assert len(hh_mean_inc) == len(df_land_use) and hh_mean_inc.isna().sum() == 0, 'HH mean income is incomplete'\n",
    "\n",
    "hh_mean_inc = hh_mean_inc.reset_index()\n",
    "hh_mean_inc['income_seg'] = pd.cut(hh_mean_inc['mean_inc'], right = False, bins = cutoffs + [float('inf')], labels = segment_suffixes).astype(str)\n",
    "hh_mean_inc['inc_grp_num'] = hh_mean_inc['income_seg'].map(inc_grp_nums) \n",
    "hh_mean_inc['VOT_per_hour'] = hh_mean_inc['income_seg'].map(VOTs) \n",
    "hh_mean_inc['VOT_per_min'] = hh_mean_inc['VOT_per_hour']/ 60 # values from VOTs are in $/hour, convert into $/minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_grp_num</th>\n",
       "      <th>income_seg</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>LowInc</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>MedInc</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>HighInc</td>\n",
       "      <td>1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>XHighInc</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inc_grp_num income_seg  count\n",
       "0            1     LowInc     72\n",
       "1            2     MedInc    803\n",
       "2            3    HighInc   1583\n",
       "3            4   XHighInc    874"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_mean_inc['income_seg'].head()\n",
    "hh_mean_inc.groupby(['inc_grp_num','income_seg']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set travel time bin cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# travel time in minutes\n",
    "cutoff_start = [0, 10, 20, 30, 40, 50, 60, 70]\n",
    "cutoff_end = [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "\n",
    "perc_trans_offset = 30  # offset transit cutoff ranges due to perceived walk transit times being so much longer\n",
    "factor_trans_binsize = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment to halve wait times\n",
    "HALFWAIT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Travel Time Impedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mode_groups = {'highway':{'mode':'highway','omx_name':'HWYSKM','core':['TIMEDAL','TIMEDAM','TIMEDAH','TIMEDAXH']},\n",
    "                   'walktrans':{'mode':'wtransit','omx_name':'WLK_TRN','core':'TRN_TOT_TIME'},\n",
    "                   'drivetrans':{'mode':'dtransit','omx_name':'PNR_TRN','core':'TRN_TOT_TIME'},\n",
    "                   'alltrans':{'mode':'atransit','omx_name':'','core':''},\n",
    "                   'nonmotor':{'mode':'non-motorized','omx_name':'nonmotskm','core':'DISTWALK'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate transit travel times into a single TRN_TOT_TIME core, divided by 100\n",
    "for tod in TODs:\n",
    "    for fn in glob.glob(f'*trnskm*.omx'):\n",
    "        if tod.lower() in fn.lower():\n",
    "            with omx.open_file(fn, 'a') as f:\n",
    "                # Recalc IVT to eliminate missing interchanges\n",
    "                if 'IVTX' in f.list_matrices():\n",
    "                    del f['IVTX'] \n",
    "                ivt = np.array(f['IVT'])\n",
    "                ivt1 = ivt * (ivt>0)\n",
    "                ivt0 = 999999 * (ivt==0)\n",
    "                ivtx = ivt0 + ivt1\n",
    "                f['IVTX'] = ivtx.reshape(len(f['IVT']),len(f['IVT']))\n",
    "                \n",
    "                # Experiment to halve wait times\n",
    "                if HALFWAIT:\n",
    "                    if 'IWAIT2' in f.list_matrices():\n",
    "                        del f['IWAIT2']                \n",
    "                    iwait2 = np.array(f['IWAIT'])/2.0\n",
    "                    f['IWAIT2'] = iwait2.reshape(len(f['IWAIT']),len(f['IWAIT']))\n",
    "                    if 'XWAIT2' in f.list_matrices():\n",
    "                        del f['XWAIT2'] \n",
    "                    xwait2 = np.array(f['XWAIT'])/2.0\n",
    "                    f['XWAIT2'] = xwait2.reshape(len(f['XWAIT']),len(f['XWAIT']))\n",
    "                \n",
    "                # Calculate total transit travel time\n",
    "                if 'TRN_TOT_TIME' in f.list_matrices():\n",
    "                    del f['TRN_TOT_TIME']\n",
    "                if HALFWAIT:\n",
    "                    f['TRN_TOT_TIME'] = np.add.reduce([np.array(f[mat]) \\\n",
    "                                                       for mat in ['DTIME','IVTX','IWAIT2','XWAIT2',\\\n",
    "                                                                   'WACC','WAUX','WEGR']])/ 100\n",
    "                else:\n",
    "                    f['TRN_TOT_TIME'] = np.add.reduce([np.array(f[mat]) \\\n",
    "                                                       for mat in ['DTIME','IVTX','IWAIT','XWAIT'\\\n",
    "                                                                   ,'WACC','WAUX','WEGR']])/ 100\n",
    "#                 print(f.list_matrices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highway\n",
      "walktrans\n",
      "drivetrans\n",
      "alltrans\n",
      "nonmotor\n"
     ]
    }
   ],
   "source": [
    "# Gather processed skim matrices\n",
    "for access_type in acc_mode_groups:\n",
    "    print(access_type)\n",
    "    if access_type != 'alltrans':\n",
    "        for tod in TODs:\n",
    "            fname = acc_mode_groups[access_type]['omx_name']\n",
    "            for fn in glob.glob(f'*{fname}*.omx'):\n",
    "                if access_type == 'nonmotor' or tod.lower() in fn.lower():\n",
    "                    with omx.open_file(fn) as f:\n",
    "                        mode = acc_mode_groups[access_type]['mode']\n",
    "                        if isinstance(acc_mode_groups[access_type]['core'], list):\n",
    "                            cores = acc_mode_groups[access_type]['core']\n",
    "                            tt0_matrices[(tod,mode)] = np.zeros((num_zones, num_zones))\n",
    "                            tt1_matrices[(tod,mode)] = np.zeros((num_zones, num_zones))\n",
    "                            # Select skims from correct household income group \n",
    "                            for k in range(len(cores)):\n",
    "                                core = cores[k]\n",
    "                                isIncGroup = (hh_mean_inc['inc_grp_num']==k+1)\n",
    "                                skim_array = np.array(f[core])\n",
    "                                # broadcast horizontally by origin\n",
    "                                tt0_matrices[(tod,mode)] += skim_array[:num_zones, :num_zones] * isIncGroup[:,None]\n",
    "                                # broadcast vertically by destination\n",
    "                                tt1_matrices[(tod,mode)] += skim_array[:num_zones, :num_zones] * isIncGroup[None,:]\n",
    "                        else:\n",
    "                            skim_array = np.array(f[acc_mode_groups[access_type]['core']])\n",
    "                            if acc_mode_groups[access_type]['core'] =='DISTWALK':\n",
    "                                skim_array = skim_array*20\n",
    "                            tt0_matrices[(tod,mode)] = skim_array[:num_zones, :num_zones]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the better travel time between walk-access transit and drive-access transit\n",
    "for tod in TODs:\n",
    "    fnames = [f for f in glob.glob(f'*trnskm*.omx') if tod.lower() in f.lower()]\n",
    "    ft = omx.open_file(fn, 'a')\n",
    "    for fn in fnames:\n",
    "        if acc_mode_groups['walktrans']['omx_name'] in fn:\n",
    "            fw = omx.open_file(fn, 'a')\n",
    "            if 'USE' in fw.list_matrices():\n",
    "                del fw['USE']\n",
    "        elif acc_mode_groups['drivetrans']['omx_name'] in fn:\n",
    "            fd = omx.open_file(fn, 'a')\n",
    "            if 'USE' in fd.list_matrices():\n",
    "                del fd['USE']\n",
    "        else:\n",
    "            break\n",
    "    # Compare total transit travel times\n",
    "    watt = np.array(fw['TRN_TOT_TIME'])\n",
    "    datt = np.array(fd['TRN_TOT_TIME'])\n",
    "    w1 = (watt <= datt) * 1\n",
    "    d1 = (watt > datt) * 1\n",
    "    # Create indicator cores\n",
    "    fw['USE'] = w1 = w1.reshape(len(fw['IVT']),len(fw['IVT']))\n",
    "    fd['USE'] = d1 = d1.reshape(len(fd['IVT']),len(fd['IVT']))\n",
    "    fw.close()\n",
    "    fd.close()\n",
    "    \n",
    "    # Create a blend of the best transit travel times\n",
    "    tt0_matrices[(tod,'atransit')] = tt0_matrices[(tod,'wtransit')] * w1 + tt0_matrices[(tod,'dtransit')] * d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df = pd.DataFrame(0, index = df_land_use.ZONE.values, columns = [])\n",
    "all_zones_df.index.name = 'zone_ID'\n",
    "\n",
    "all_zones_pct_df = pd.DataFrame(0, index = df_land_use.ZONE.values, columns = [])\n",
    "all_zones_pct_df.index.name = 'zone_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTEMP ('AM', 'highway')\n",
      "TOTEMP ('AM', 'wtransit')\n",
      "TOTEMP ('AM', 'non-motorized')\n",
      "RETEMPN ('AM', 'highway')\n",
      "RETEMPN ('AM', 'wtransit')\n",
      "RETEMPN ('AM', 'non-motorized')\n",
      "HEREMPN ('AM', 'highway')\n",
      "HEREMPN ('AM', 'wtransit')\n",
      "HEREMPN ('AM', 'non-motorized')\n",
      "EMPRES ('AM', 'highway')\n",
      "EMPRES ('AM', 'wtransit')\n",
      "EMPRES ('AM', 'non-motorized')\n"
     ]
    }
   ],
   "source": [
    "for employment in emp_type:\n",
    "    for tod in TODs:\n",
    "        for access_type in acc_mode_groups:\n",
    "            mode = acc_mode_groups[access_type]['mode']\n",
    "            new_key = (tod,mode)\n",
    "            if new_key in tt0_matrices and mode not in ('atransit','dtransit'): # use only walk access transit\n",
    "                print(employment, new_key)\n",
    "                for (cutoff_s, cutoff_e) in zip(cutoff_start, cutoff_end):\n",
    "                    if mode == 'dtransit':\n",
    "                        cutoff_s *= factor_dtrans_binsize\n",
    "                        cutoff_e *= factor_dtrans_binsize\n",
    "                        if cutoff_s > 0: \n",
    "                            cutoff_s += perc_dtrans_offset\n",
    "                            cutoff_e += perc_dtrans_offset\n",
    "                        else:\n",
    "                            cutoff_e += perc_dtrans_offset                      \n",
    "                    if employment == 'EMPRES' and mode == 'highway':\n",
    "                        grp_tt = tt1_matrices[(tod,mode)]\n",
    "                    else:\n",
    "                        grp_tt = tt0_matrices[(tod,mode)]\n",
    "                    grp_tt = ((grp_tt >= cutoff_s) & (grp_tt < cutoff_e)).astype(int)\n",
    "                    all_zones_df[f'{employment}_{tod}_{mode}_{int(cutoff_s)}_{int(cutoff_e)}'] = (grp_tt*df_land_use[f'{employment}'].values).sum(axis=1)\n",
    "                    all_zones_pct_df[f'{employment}_{tod}_{mode}_{int(cutoff_s)}_{int(cutoff_e)}'] = (grp_tt*df_land_use[f'{employment}'].values).sum(axis=1) / df_land_use[f'{employment}'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df.to_excel(writer,sheet_name = 'simple')\n",
    "all_zones_pct_df.to_excel(writer,sheet_name = 'simple_PCT')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceived Travel Time Impedances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessibility based on perceived time/cost\n",
    "ptt0_matrices = {} # origin-based income/vot for household accessibility to attractions\n",
    "ptt1_matrices = {} # destination-based income/vot for establishment accessibility to workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost units are cents, expressed in year 2000 dollars.\n",
    "for tod in TODs:\n",
    "    for fn in glob.glob('hwyskm*.omx'):\n",
    "        if tod in fn:\n",
    "            with omx.open_file(fn) as f:\n",
    "                mode = 'highway'\n",
    "                time_array0 = np.zeros((num_zones, num_zones))\n",
    "                cost_array0 = np.zeros((num_zones, num_zones))\n",
    "                toll_array0 = np.zeros((num_zones, num_zones))\n",
    "                time_array1 = np.zeros((num_zones, num_zones))\n",
    "                cost_array1 = np.zeros((num_zones, num_zones))\n",
    "                toll_array1 = np.zeros((num_zones, num_zones))\n",
    "                \n",
    "                for label, grp_num in inc_grp_nums.items():\n",
    "                    suffix = label[0]\n",
    "                    if suffix == 'X': suffix = 'XH'\n",
    "                    isIncGroup = (hh_mean_inc['inc_grp_num']==grp_num)\n",
    "                    \n",
    "                    time_array0 += np.array(f['TIMEDA'+suffix])[:num_zones, :num_zones] * isIncGroup[:,None]\n",
    "                    cost_array0 += np.array(f['COSTDA'+suffix])[:num_zones, :num_zones] * isIncGroup[:,None] / 100\n",
    "                    toll_array0 += np.array(f['BTOLLDA'+suffix])[:num_zones, :num_zones]  * isIncGroup[:,None] / 100 \\\n",
    "                    + np.array(f['VTOLLDA'+suffix])[:num_zones, :num_zones] * isIncGroup[:,None] / 100\n",
    "                    \n",
    "                    time_array1 += np.array(f['TIMEDA'+suffix])[:num_zones, :num_zones] * isIncGroup[None,:]\n",
    "                    cost_array1 += np.array(f['COSTDA'+suffix])[:num_zones, :num_zones] * isIncGroup[None,:] / 100\n",
    "                    toll_array1 += np.array(f['BTOLLDA'+suffix])[:num_zones, :num_zones]  * isIncGroup[None,:] / 100 \\\n",
    "                    + np.array(f['VTOLLDA'+suffix])[:num_zones, :num_zones] * isIncGroup[None,:] / 100\n",
    "                \n",
    "                # broadcasting VOT values horizontally to get VOT by origin zone\n",
    "                p0_time_array = time_array0 \\\n",
    "                + np.divide(cost_array0, hh_mean_inc.VOT_per_min.values[:,None]) \\\n",
    "                + np.divide(toll_array0, hh_mean_inc.VOT_per_min.values[:,None])  \n",
    "                ptt0_matrices[(tod, mode)] = p0_time_array\n",
    "                \n",
    "                # broadcasting VOT values vertically to get VOT by destination zone\n",
    "                p1_time_array = time_array1 \\\n",
    "                + np.divide(cost_array1, hh_mean_inc.VOT_per_min.values[None,:]) \\\n",
    "                + np.divide(toll_array1, hh_mean_inc.VOT_per_min.values[None,:])  \n",
    "                ptt1_matrices[(tod, mode)] = p1_time_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transit\n",
    "waitThresh = 10 # 10 minutes per UEC\n",
    "coef_dict = {'IWAIT_S': 2, 'IWAIT_L': 1, 'XWAIT' : 2, 'XWAIT2' : 2, 'WACC' : 2, \\\n",
    "             'WEGR' : 2, 'WAUX' : 2, 'CROWD' : 1.62, 'DTIME': 2} # \n",
    "\n",
    "#c_shortiWait\tShort initial wait time coefficient -- see \"waitThresh\"\t2.00 * c_ivt\n",
    "#c_longiWait\tLong initial wait time coefficient -- see \"waitThresh\"\t1.00 * c_ivt\n",
    "#c_wacc\tWalk access time coefficient\t2.00 * c_ivt\n",
    "#c_wegr\tWalk egress time coefficient\t2.00 * c_ivt\n",
    "#c_xwait Transfer wait time coefficient\t2.00 * c_ivt\n",
    "#c_waux\tWalk auxilliary time coefficient\t\t2.00 * c_ivt\n",
    "\n",
    "# short wait time: c_shortiWait*min(WLK_TRN_WLK_IWAIT[tripPeriod]/100,waitThresh)\n",
    "# long wait time: c_longiWait*max(WLK_TRN_WLK_IWAIT[tripPeriod]/100-waitThresh,0)\n",
    "# is the initial wait time reflected as a sum of both?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tod in TODs:\n",
    "    for fn in glob.glob('*trnskm*.omx'):\n",
    "        if tod.lower() in fn.lower():\n",
    "            with omx.open_file(fn) as f:\n",
    "                ptt = [np.array(f['IVTX']) / 100]\n",
    "                fare_array = np.array(f['FARE'])[:num_zones, :num_zones] / 100\n",
    "                if 'PNR_TRN' in fn:\n",
    "                    mode = 'dtransit'\n",
    "                if 'WLK_TRN' in fn:\n",
    "                    mode = 'wtransit'\n",
    "                if HALFWAIT:\n",
    "                    for OVTT in ['XWAIT2','WACC','WEGR','WAUX','CROWD','DTIME']:\n",
    "                        ptt.append(np.array(f[OVTT]) * coef_dict[OVTT] / 100)\n",
    "                    IWAIT = coef_dict['IWAIT_S'] * np.array(f['IWAIT2']) / 100 \\\n",
    "                    + coef_dict['IWAIT_L'] * np.clip(np.array(f['IWAIT2'])/100 - waitThresh, a_min = 0, a_max = None)\n",
    "                    ptt.append(IWAIT)\n",
    "                else:    \n",
    "                    for OVTT in ['XWAIT','WACC','WEGR','WAUX','CROWD','DTIME']:\n",
    "                        ptt.append(np.array(f[OVTT]) * coef_dict[OVTT] / 100)\n",
    "                    IWAIT = coef_dict['IWAIT_S'] * np.array(f['IWAIT']) / 100 \\\n",
    "                    + coef_dict['IWAIT_L'] * np.clip(np.array(f['IWAIT'])/100 - waitThresh, a_min = 0, a_max = None)\n",
    "                    ptt.append(IWAIT)\n",
    "                \n",
    "                # broadcasting VOT values horizontally to get VOT by origin zone\n",
    "                ptt0_matrices[(tod, mode)] = np.add.reduce([mat[:num_zones, :num_zones] for mat in ptt]) \\\n",
    "                + np.divide(fare_array, hh_mean_inc.VOT_per_min.values[:,None])\n",
    "                \n",
    "                # broadcasting VOT values vertically to get VOT by destination zone for access to workers\n",
    "                ptt1_matrices[(tod, mode)] = np.add.reduce([mat[:num_zones, :num_zones] for mat in ptt]) \\\n",
    "                + np.divide(fare_array, hh_mean_inc.VOT_per_min.values[None,:])\n",
    "        \n",
    "    # Create a blend of the best transit travel times\n",
    "    w2 = (ptt0_matrices[(tod,'wtransit')] <= ptt0_matrices[(tod,'dtransit')]) * 1\n",
    "    d2 = (ptt0_matrices[(tod,'wtransit')] > ptt0_matrices[(tod,'dtransit')]) * 1\n",
    "    \n",
    "    w3 = (ptt1_matrices[(tod,'wtransit')] <= ptt1_matrices[(tod,'dtransit')]) * 1\n",
    "    d3 = (ptt1_matrices[(tod,'wtransit')] > ptt1_matrices[(tod,'dtransit')]) * 1\n",
    "    \n",
    "    ptt0_matrices[(tod,'atransit')] = ptt0_matrices[(tod,'wtransit')] * w2 + ptt0_matrices[(tod,'dtransit')] * d2\n",
    "    ptt1_matrices[(tod,'atransit')] = ptt1_matrices[(tod,'wtransit')] * w3 + ptt1_matrices[(tod,'dtransit')] * d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5.951 pct.\n",
      " 1.021 pct.\n",
      " 6.033 pct.\n"
     ]
    }
   ],
   "source": [
    "test1 = ((w2!=w1)*1).sum()/(len(w2)*len(w1))*100\n",
    "print(\"%6.3f pct.\" % test1)\n",
    "test2 = ((w2!=w3)*1).sum()/(len(w2)*len(w3))*100\n",
    "print(\"%6.3f pct.\" % test2)\n",
    "test3 = ((w1!=w3)*1).sum()/(len(w1)*len(w3))*100\n",
    "print(\"%6.3f pct.\" % test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df = pd.DataFrame(0, index = df_land_use.ZONE.values, columns = [])\n",
    "all_zones_df.index.name = 'zone_ID'\n",
    "\n",
    "all_zones_pct_df = pd.DataFrame(0, index = df_land_use.ZONE.values, columns = [])\n",
    "all_zones_pct_df.index.name = 'zone_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for employment in emp_type:\n",
    "    if employment == 'EMPRES':\n",
    "        ptt_matrices = ptt1_matrices\n",
    "    else: \n",
    "        ptt_matrices = ptt0_matrices\n",
    "    for tod in TODs:        \n",
    "        for mode in ['highway','wtransit']:  # use only walk access transit\n",
    "            new_key = (tod,mode)\n",
    "            if new_key in ptt_matrices:\n",
    "                for (cutoff_s, cutoff_e) in zip(cutoff_start, cutoff_end):\n",
    "                    if 'transit' in mode:\n",
    "                        cutoff_s *= factor_trans_binsize\n",
    "                        cutoff_e *= factor_trans_binsize\n",
    "                        if cutoff_s > 0: \n",
    "                            cutoff_s += perc_trans_offset\n",
    "                            cutoff_e += perc_trans_offset\n",
    "                        else:\n",
    "                            cutoff_e += perc_trans_offset                              \n",
    "                    grp_tt = (ptt_matrices[(tod,mode)])\n",
    "                    grp_tt = ((grp_tt >= cutoff_s) & (grp_tt < cutoff_e)).astype(int)\n",
    "\n",
    "                    all_zones_df[f'{employment}_{tod}_{mode}_{int(cutoff_s)}_{int(cutoff_e)}'] = (grp_tt*df_land_use[f'{employment}'].values).sum(axis=1)\n",
    "                    all_zones_pct_df[f'{employment}_{tod}_{mode}_{int(cutoff_s)}_{int(cutoff_e)}'] = (grp_tt*df_land_use[f'{employment}'].values).sum(axis=1) / df_land_use[f'{employment}'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zones_df.to_excel(writer,sheet_name = 'perceived_TT')\n",
    "all_zones_pct_df.to_excel(writer,sheet_name =  'perceived_TT_PCT')\n",
    "hh_mean_inc[['TAZ','mean_inc', 'income_seg', 'VOT_per_hour', 'VOT_per_min']].to_excel(writer,sheet_name = 'HH inc & VOT', index = False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
