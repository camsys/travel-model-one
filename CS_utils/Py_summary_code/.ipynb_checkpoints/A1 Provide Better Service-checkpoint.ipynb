{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94ee55a-efd7-4d1a-9d55-7ccf3764da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmatrix as omx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from utility import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3700fa-5380-4275-b608-c1ea3e6f00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "landuse_dir = _join(model_outputs_dir, \"landuse\")\n",
    "\n",
    "#hwyskmMD = _join(params['best_path_skim_dir'], 'am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx')\n",
    "\n",
    "#transit skims - names\n",
    "#acc_egr = params['access_egress_modes']\n",
    "#transit_skim_files = []\n",
    "#for per in params['periods']:\n",
    "#    for acc in acc_egr:\n",
    "#        file_name = _join(params['best_path_skim_dir'], per+acc+'_v9_1_release11302022_bestpathresults.omx')\n",
    "#        transit_skim_files.append(file_name)\n",
    "\n",
    "transit_skim_files = [r'C:\\Users\\vyadav\\Cambridge Systematics\\PROJ 210071 BART Link21 TDLU Modeling - Documents\\Task 2 - Model Dev\\2.3 - Model Construction\\Performance Metrics\\Model Outputs\\TM2_09172022\\Best Single Path\\am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx']\n",
    "#cores - 'BOARDS', 'DDIST', 'DTIME', 'FARE', 'IVT', 'IVTCOM', 'IVTEXP', 'IVTFRY', 'IVTHVY', 'IVTLOC', 'IVTLRT',\n",
    "# 'IWAIT', 'PIVTCOM', 'PIVTEXP', 'PIVTFRY', 'PIVTHVY', 'PIVTLOC', 'PIVTLRT', 'WACC', 'WAIT', 'WAUX', 'WEGR', 'XWAIT'\n",
    "\n",
    "summary_outputs = params['summary_dir']\n",
    "\n",
    "#demand matrices for active highway and transit\n",
    "demand_matrices_dir = _join(model_outputs_dir, \"demand_matrices\")\n",
    "highway_demand_dir = _join(demand_matrices_dir, \"highway\", \"household\")\n",
    "active_demand_dir = _join(demand_matrices_dir, \"active\")\n",
    "transit_demand_dir = _join(demand_matrices_dir, \"transit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16acea5d-8446-4fcf-b136-c0f5c37080a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "\n",
    "#taz to RDM zones, super districts, county\n",
    "geo_cwks = pd.read_csv(_join(params['common_dir'], \"geographies.csv\")) #columns taz, rdm_zones, super_district, county\n",
    "\n",
    "#taz to priority population\n",
    "pp_perc = pd.read_excel(_join(params['common_dir'], \"TAZ_Tract_cwk_summary.xlsx\")) #columns = taz, pp_share \n",
    "\n",
    "#get geogrpahies and priority population in the same file\n",
    "geo_pp_cwks = pd.merge(geo_cwks, pp_perc, on = 'taz', how = 'left') \n",
    "\n",
    "#transbay od pairs\n",
    "transbay_od = pd.read_csv(_join(params['common_dir'], \"transbay_od.csv\")) #columns = transbay_o, transbay_d\n",
    "\n",
    "#non work destinations tazs\n",
    "non_work_tazs = pd.read_excel(_join(params['common_dir'], 'non_work_destinations.xlsx'))\n",
    "#non_work_tazs = list(non_work_tazs['non_wrk_taz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5608c34-81b0-4812-ac1a-c418635065ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_string(string, n):\n",
    "    return [string] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ae17da-dec9-445b-9753-1e957902960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = params['periods'] #['EA', 'AM', 'MD', 'PM', 'EV']\n",
    "acc_egg_modes = params['access_egress_modes'] #['KNR_TRN_WLK', 'PNR_TRN_WLK', 'WLK_TRN_KNR', 'WLK_TRN_PNR', 'WLK_TRN_WLK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efc68d8-1c5b-4238-9447-83e95cf002a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period:  am\n"
     ]
    },
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5F.c\", line 532, in H5Fcreate\n    unable to create file\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5VLcallback.c\", line 3282, in H5VL_file_create\n    file create failed\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5VLcallback.c\", line 3248, in H5VL__file_create\n    file create failed\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5VLnative_file.c\", line 63, in H5VL__native_file_create\n    unable to create file\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5Fint.c\", line 1858, in H5F_open\n    unable to truncate a file which is already open\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'C:\\VY-Projects\\Link21\\TM2_09172022\\demand_matrices\\transit\\rail_demand_v9_trim_AM.omx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m trn_dmnd\u001b[38;5;241m.\u001b[39mlist_matrices()\n\u001b[0;32m      6\u001b[0m rail_dmn_per \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m rail_demand \u001b[38;5;241m=\u001b[39m \u001b[43momx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransit_demand_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrail_demand_v9_trim_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.omx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m acc_egg \u001b[38;5;129;01min\u001b[39;00m acc_egg_modes:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess Egress Mode: \u001b[39m\u001b[38;5;124m\"\u001b[39m,acc_egg)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\openmatrix\\__init__.py:53\u001b[0m, in \u001b[0;36mopen_file\u001b[1;34m(filename, mode, title, root_uep, filters, shape, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_file\u001b[39m(filename, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, root_uep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m              filters\u001b[38;5;241m=\u001b[39mtables\u001b[38;5;241m.\u001b[39mFilters(complevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fletcher32\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, complib\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzlib\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     16\u001b[0m              shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    Open or create a new OMX file. New files will be created with default\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    zlib compression enabled.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m        The file object for reading and writing.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     f \u001b[38;5;241m=\u001b[39m File(filename, mode, title, root_uep, filters, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs);\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# add omx structure if file is writable\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;66;03m# version number\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\openmatrix\\File.py:14\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, f, m, t, r, f1, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f,m,t,r,f1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 14\u001b[0m     tables\u001b[38;5;241m.\u001b[39mFile\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,f,m,t,r,f1,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\tables\\file.py:750\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_g_new(filename, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;66;03m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_new\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\tables\\hdf5extension.pyx:486\u001b[0m, in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5F.c\", line 532, in H5Fcreate\n    unable to create file\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5VLcallback.c\", line 3282, in H5VL_file_create\n    file create failed\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5VLcallback.c\", line 3248, in H5VL__file_create\n    file create failed\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5VLnative_file.c\", line 63, in H5VL__native_file_create\n    unable to create file\n  File \"D:\\bld\\hdf5_split_1646412567021\\work\\src\\H5Fint.c\", line 1858, in H5F_open\n    unable to truncate a file which is already open\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'C:\\VY-Projects\\Link21\\TM2_09172022\\demand_matrices\\transit\\rail_demand_v9_trim_AM.omx'"
     ]
    }
   ],
   "source": [
    "#Creates the Rail Demand Files\n",
    "for per in period:\n",
    "    print(\"Period: \",per)\n",
    "    trn_dmnd = omx.open_file(_join(transit_demand_dir, \"trn_demand_v9_trim_\" + per.upper() + \".omx\"))\n",
    "    trn_dmnd.list_matrices()\n",
    "    rail_dmn_per = []\n",
    "    rail_demand = omx.open_file(_join(transit_demand_dir, \"rail_demand_v9_trim_\" + per.upper() + \".omx\"),'w') \n",
    "    for acc_egg in acc_egg_modes:\n",
    "        print(\"Access Egress Mode: \",acc_egg)\n",
    "        trn_dmn_acc = np.array(trn_dmnd[acc_egg])\n",
    "        trn_skm = omx.open_file(_join(skims_dir, \"trnskm\" + per.lower() + \"_\" +acc_egg.lower() + \".omx\"))\n",
    "        print(trn_skm)\n",
    "        ivthvy = np.array(trn_skm['IVTHVY'])\n",
    "        ivtcom = np.array(trn_skm['IVTCOM'])\n",
    "        ivtrail = ivthvy + ivtcom\n",
    "        ivtrail[ivtrail > 0] = 1\n",
    "        rail_dmn = trn_dmn_acc * ivtrail\n",
    "        rail_demand[acc_egg] = rail_dmn\n",
    "    \n",
    "    rail_demand.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea354bd-8767-4c80-bcfc-8aa095e3f649",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchNodeError",
     "evalue": "group ``/`` does not have a child named ``/data/WALK_TRN_WALK``",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchNodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m modes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m acc_egg \u001b[38;5;129;01min\u001b[39;00m acc_egg_modes:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#print(\"Access Egress Mode: \", acc_egg )\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     rail_trips \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mrail_dmnd\u001b[49m\u001b[43m[\u001b[49m\u001b[43macc_egg\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     16\u001b[0m     trn_trips \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(trn_dmnd[acc_egg])\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     18\u001b[0m     rail\u001b[38;5;241m.\u001b[39mappend(rail_trips)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\openmatrix\\File.py:296\u001b[0m, in \u001b[0;36mFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"Return a matrix by name, or a list of matrices by attributes\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(key):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\tables\\file.py:1600\u001b[0m, in \u001b[0;36mFile.get_node\u001b[1;34m(self, where, name, classname)\u001b[0m\n\u001b[0;32m   1598\u001b[0m     basepath \u001b[38;5;241m=\u001b[39m where\u001b[38;5;241m.\u001b[39m_v_pathname\n\u001b[0;32m   1599\u001b[0m     nodepath \u001b[38;5;241m=\u001b[39m join_path(basepath, name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1600\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[43mwhere\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_v_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1601\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(where, (\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mstr_)):\n\u001b[0;32m   1602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m where\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\tables\\file.py:1556\u001b[0m, in \u001b[0;36mFile._get_node\u001b[1;34m(self, nodepath)\u001b[0m\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nodepath \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\n\u001b[1;32m-> 1556\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_node_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munable to instantiate node ``\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m``\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m nodepath\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\tables\\file.py:417\u001b[0m, in \u001b[0;36mNodeManager.get_node\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    414\u001b[0m         node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_factory:\n\u001b[1;32m--> 417\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_node(node, key)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\tables\\group.py:1137\u001b[0m, in \u001b[0;36mRootGroup._g_load_child\u001b[1;34m(self, childname)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     childname \u001b[38;5;241m=\u001b[39m join_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_file\u001b[38;5;241m.\u001b[39mroot_uep, childname)\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# Is the node a group or a leaf?\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m node_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_g_check_has_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchildname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# Nodes that HDF5 report as H5G_UNKNOWN\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\tables\\group.py:375\u001b[0m, in \u001b[0;36mGroup._g_check_has_child\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    373\u001b[0m node_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_g_get_objinfo(name)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNoSuchNode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchNodeError(\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup ``\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m`` does not have a child named ``\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m``\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_pathname, name))\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node_type\n",
      "\u001b[1;31mNoSuchNodeError\u001b[0m: group ``/`` does not have a child named ``/data/WALK_TRN_WALK``"
     ]
    }
   ],
   "source": [
    "#create summary of tranist trips by cores and Rail trips\n",
    "final_df = []\n",
    "n = len(acc_egg_modes)\n",
    "\n",
    "for per in period:\n",
    "    #print(\"Period: \",per)\n",
    "    trn_dmnd = omx.open_file(os.path.join(transit_demand_dir, \"trn_demand_v9_trim_\" + per + \".omx\"))\n",
    "    rail_dmnd = omx.open_file(os.path.join(transit_demand_dir, \"rail_demand_v9_trim_\" + per + \".omx\"))\n",
    "    \n",
    "    rail = []\n",
    "    trn = []\n",
    "    modes = []\n",
    "    for acc_egg in acc_egg_modes:\n",
    "        #print(\"Access Egress Mode: \", acc_egg )\n",
    "        rail_trips = np.array(rail_dmnd[acc_egg]).sum()\n",
    "        trn_trips = np.array(trn_dmnd[acc_egg]).sum()\n",
    "        \n",
    "        rail.append(rail_trips)\n",
    "        trn.append(trn_trips)\n",
    "        modes.append(acc_egg)\n",
    "    \n",
    "    df = pd.DataFrame({'period': repeat_string(per, n),'modes': modes, 'transit_trips': trn, 'rail_trips': rail})\n",
    "    final_df.append(df)\n",
    "    \n",
    "transit_trips_df = pd.concat(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583db52-e706-4fa8-a223-08c3ad4d3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_trips = transit_trips_df.pivot(index = 'modes', columns = 'period', values = 'transit_trips')\n",
    "rail_trips = transit_trips_df.pivot(index = 'modes', columns = 'period', values = 'rail_trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07203e-4531-49b6-853f-e38b2d306fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistics \n",
    "\n",
    "stat_cores = ['IVTHVY', # in-vehicle travel tim\n",
    "              'WAIT',\n",
    "              'WACC',\n",
    "              'WEGR',\n",
    "              'XWAIT',\n",
    "              'DTIME'             \n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229eac32-98ae-41e9-ba21-17a25153b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = []\n",
    "modes = []\n",
    "n = len(stat_cores)\n",
    "for per in period:\n",
    "    #print(\"Period: \",per)\n",
    "    rail_dmnd = omx.open_file(os.path.join(transit_demand_dir, \"rail_demand_v9_trim_\" + per + \".omx\"))\n",
    "    \n",
    "    tt = []\n",
    "    for acc_egg in acc_egg_modes:\n",
    "       # print(\"Access Egress Mode: \",acc_egg)\n",
    "        trn_dmn_acc = np.array(rail_dmnd[acc_egg])\n",
    "        trn_skm = omx.open_file(os.path.join(skims_dir, \"trnskm\" + per.lower() +\"_\" + acc_egg.lower() + \".omx\"))\n",
    "        \n",
    "        avg_stat = []\n",
    "        for core in stat_cores:\n",
    "            m1 = np.array(trn_skm[core])\n",
    "            m2 = trn_dmn_acc\n",
    "            avg_stat_trn = np.dot(m1, m2).sum() / m2.sum()\n",
    "            avg_stat.append(avg_stat_trn)\n",
    "            \n",
    "        #print(avg_stat)\n",
    "        df = pd.DataFrame({'period': repeat_string(per, n),'modes': repeat_string(acc_egg, n), 'Cores': stat_cores, 'values': avg_stat})\n",
    "        final_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158102d1-b203-4d27-8ee7-49d87de71de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(final_df)\n",
    "core_summaries = results.pivot(index= ['period', 'modes'], columns='Cores', values='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c49ebc-e76b-4c60-959a-92c650c9efdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3b72a-05bf-473e-8742-36171eea797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(rail_trips, rail_skim, trip_core_name, skim_core_name, tod, total_trip_time=False):\n",
    "    \n",
    "    #TO DO: Change the input file\n",
    "    rail_trips = omx.open_file(os.path.join(skim_dir, \"trnskm\" + tod2 + \"_KNR_TRN_WLK.omx\")) # add time period\n",
    "    #copy cores here \n",
    "\n",
    "    trn_files = ['_KNR_TRN_WLK.omx', '_PNR_TRN_WLK.omx', 'WLK_TRN_KNR.omx', 'WLK_TRN_PNR.omx', '_WLK_TRN_WLK.omx']\n",
    "\n",
    "    \n",
    "    for file in trn_files:\n",
    "        rail_skim = omx.open_file(os.path.join(skim_dir, \"trnskm\" + tod2 + file))\n",
    "        #['BOARDS', 'DDIST', 'DTIME', 'FARE', 'IVT', 'IVTCOM', 'IVTEXP', 'IVTFRY', 'IVTHVY', 'IVTLOC', \n",
    "        #'IVTLRT', 'IWAIT', 'PIVTCOM', 'PIVTEXP', 'PIVTFRY', 'PIVTHVY', 'PIVTLOC', 'PIVTLRT', 'WACC', 'WAIT', 'WAUX', 'WEGR', 'XWAIT']\n",
    "        \n",
    "        avg_stat = []\n",
    "        skim_cores = rail_skim.list_matrices()\n",
    "        trip_cores = rail_trips.list_matrices()\n",
    "\n",
    "        if not total_trip_time:\n",
    "            #TO DO: edit this\n",
    "            tod1 = 'AM'\n",
    "            tod2 = 'am'\n",
    "            \n",
    "            if skim_core_name in skim_cores:\n",
    "                m1 = np.array(rail_skim[skim_core_name])\n",
    "                \n",
    "            else:\n",
    "                raise Exception(\"{} core in skim not found\".format(skim_core_name))\n",
    "                \n",
    "            if trip_core_name in trip_cores:\n",
    "                m2 = np.array(rail_trips[trip_core_name])\n",
    "            else:\n",
    "                raise Exception(\"{} core in trips not found\".format(trip_core_name))\n",
    "                \n",
    "            avg_stat_trn = np.dot(m1, m2).sum() / m2.sum()\n",
    "            avg_stat.append(avg_stat_trn)\n",
    "\n",
    "            print(np.dot(m1, m2).sum(), m2.sum())\n",
    "\n",
    "        else:\n",
    "            total_rail_time =  np.array(rail_trips['IVTCOM']) + np.array(rail_trips['IVTHVY'])\n",
    "\n",
    "    return avg_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8550d15-2759-4e16-8ccc-c3c0550b920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_rail_los(rail_trips, periods):\n",
    "\n",
    "    #TO DO: edits as needed\n",
    "    avg_ivtt = []\n",
    "    avg_waittime = []\n",
    "    avg_wk_acc = []\n",
    "    avg_wk_egr = []\n",
    "    avg_trnsfer = []\n",
    "    avg_per_tt = []\n",
    "\n",
    "    for prd in periods:\n",
    "        #in-vehicle travel times\n",
    "        avg_ivtt_prd = get_statistics(rail_trips, rail_skim, trip_core_name, 'IVTHVY', prd)\n",
    "        avg_ivtt.append(avg_ivtt)\n",
    "        \n",
    "        #wait times\n",
    "        avg_waittime_prd = get_statistics(rail_trips, rail_skim, trip_core_name, 'WAIT', prd)\n",
    "        avg_waittime.append(avg_waittime_prd)\n",
    "\n",
    "        #walk access times\n",
    "        avg_wk_acc_prd = get_statistics(rail_trips, rail_skim, trip_core_name, 'WACC', prd)\n",
    "        avg_wk_acc.append(avg_wk_acc_prd)\n",
    "\n",
    "        #walk egress times\n",
    "        avg_wk_egr_prd = get_statistics(rail_trips, rail_skim, trip_core_name, 'WEGR', prd)\n",
    "        avg_wk_egr.append(avg_wk_egr_prd)\n",
    "\n",
    "        #drive access times\n",
    "        avg_dr_acc_prd = get_statistics(rail_trips, rail_skim, trip_core_name, 'DTIME', prd)\n",
    "        avg_dr_acc.append(avg_dr_acc_prd)\n",
    "\n",
    "        #transfer time\n",
    "        avg_trnsfer_prd = get_statistics(rail_trips, rail_skim, trip_core_name, 'XWAIT', prd)\n",
    "        avg_trnsfer.append(avg_trnsfer_prd)\n",
    "\n",
    "        #total trip time\n",
    "        avg_per_tt_prd = get_statistics(rail_trips, rail_skim, trip_core_name, ['PIVTHVY', 'PIVTCOM'], prd, total_trip_time=True) #TO DO Change the core name\n",
    "        avg_per_tt.append(avg_per_tt_prd)\n",
    "\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:runway37] *",
   "language": "python",
   "name": "conda-env-runway37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
