{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395d5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmatrix as omx\n",
    "import os, sys, glob\n",
    "\n",
    "from dbfread import DBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40cc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\vyadav\\Cambridge Systematics\\PROJ 210071 BART Link21 TDLU Modeling - Documents\\Task 2 - Model Dev\\2.3 - Model Construction\\Nonres\\HSR trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd8a4ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = r\"C:\\Users\\vyadav\\Cambridge Systematics\\PROJ 210071 BART Link21 TDLU Modeling - Documents\\Task 2 - Model Dev\\2.3 - Model Construction\\Nonres\\HSR trips\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af99e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2dbf(df, dbf_path, my_specs=None):\n",
    "    '''\n",
    "\n",
    "\n",
    "    Convert a pandas.DataFrame into a dbf.\n",
    "    __author__  = \"Dani Arribas-Bel <darribas@asu.edu> \"\n",
    "    ...\n",
    "    Arguments\n",
    "    ---------\n",
    "    df          : DataFrame\n",
    "                  Pandas dataframe object to be entirely written out to a dbf\n",
    "    dbf_path    : str\n",
    "                  Path to the output dbf. It is also returned by the function\n",
    "    my_specs    : list\n",
    "                  List with the field_specs to use for each column.\n",
    "                  Defaults to None and applies the following scheme:\n",
    "                    * int: ('N', 14, 0)\n",
    "                    * float: ('N', 14, 14)\n",
    "                    * str: ('C', 14, 0)\n",
    "\n",
    "    from: https://github.com/GeoDaSandbox/sandbox/blob/master/pyGDsandbox/dataIO.py\n",
    "\n",
    "    Copyright (c) 2007-2011, GeoDa Center for Geospatial Analysis and Computation\n",
    "    All rights reserved.\n",
    "\n",
    "    Redistribution and use in source and binary forms, with or without\n",
    "    modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "    * Redistributions of source code must retain the above copyright notice, this\n",
    "      list of conditions and the following disclaimer.\n",
    "\n",
    "    * Redistributions in binary form must reproduce the above copyright\n",
    "      notice, this list of conditions and the following disclaimer in the\n",
    "      documentation and/or other materials provided with the distribution.\n",
    "\n",
    "    * Neither the name of the GeoDa Center for Geospatial Analysis and Computation\n",
    "      nor the names of its contributors may be used to endorse or promote products\n",
    "      derived from this software without specific prior written permission.\n",
    "\n",
    "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND\n",
    "    CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES,\n",
    "    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\n",
    "    MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "    DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR\n",
    "    CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
    "    SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n",
    "    LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF\n",
    "    USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n",
    "    ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n",
    "    LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n",
    "    ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "    POSSIBILITY OF SUCH DAMAGE.\n",
    "    '''\n",
    "\n",
    "    import libpysal.io as ps\n",
    "    import numpy as np\n",
    "    if my_specs:\n",
    "        specs = my_specs\n",
    "    else:\n",
    "        type2spec = {int: ('N', 20, 0),\n",
    "                     np.int64: ('N', 20, 0),\n",
    "                     float: ('N', 36, 15),\n",
    "                     np.float64: ('N', 36, 15),\n",
    "                     str: ('C', 14, 0)\n",
    "                     }\n",
    "        types = [type(df[i].iloc[0]) for i in df.columns]\n",
    "        specs = [type2spec[t] for t in types]\n",
    "    db = ps.open(dbf_path, 'w')\n",
    "    db.header = list(df.columns)\n",
    "    db.field_spec = specs\n",
    "    for i, row in df.T.iteritems():\n",
    "        db.write(row)\n",
    "    db.close()\n",
    "    return dbf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b06452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and validate crosswalk\n",
    "xwalk = pd.read_csv(r\"Disagg TM1.5\\TM1_to_Link21_HSRZones.csv\")\n",
    "\n",
    "# every TM1.5 and TM2 zone is accounted for\n",
    "# factors sum up to 1 for every TM1.5 zone\n",
    "\n",
    "missing_zone_IP = set(range(1, max(xwalk.IPZONE) + 1)) - set(xwalk.IPZONE)\n",
    "missing_zone_OP = set(range(1, max(xwalk.OPZONE) + 1)) - set(xwalk.OPZONE)\n",
    "assert len(missing_zone_IP) == 0, f'missing TM1.5 zones, {missing_zone_IP}'\n",
    "assert len(missing_zone_OP) == 0, f'missing TM2 zones, {missing_zone_OP}'\n",
    "\n",
    "assert (xwalk.groupby(['IPZONE'])['FACTOR'].sum().round(5).nunique() == 1 and\n",
    "        xwalk.groupby(['IPZONE'])['FACTOR'].sum().round(5).max() == 1), 'factors do not add up to one for every TM1.5 zone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1774fb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1475, 3353)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(xwalk.IPZONE), max(xwalk.OPZONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff4010eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment_suffixes = [\"LowInc\", \"MedInc\", \"HighInc\", \"XHighInc\"]\n",
    "#shares = [0.28, 0.24, 0.21, 0.27]\n",
    "in_table_regex = \"Disagg TM1.5/tripsHsr{period}_{year}.dbf\"\n",
    "out_omx_regex = os.path.join(out_dir, r\"disagg/{year}/tripsHsr{period}_{year}.dbf\")\n",
    "modes = [\"DA\",\"SR2\",\"TRANSIT\",\"WALK\"] # from tm2py model_config.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2f37706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG sum = 1599090273\n",
      "DEST sum = 1599090273\n",
      "DA sum = 0.0\n",
      "SR2 sum = 0.0\n",
      "TRANSIT sum = 0.0\n",
      "WALK sum = 0.0\n",
      "DA -  0.0 0.0\n",
      "SR2 -  0.0 0.0\n",
      "TRANSIT -  0.0 0.0\n",
      "WALK -  0.0 0.0\n",
      "writing DBF file for 2040 and EA\n",
      "ORIG sum = 1599090273\n",
      "DEST sum = 1599090273\n",
      "DA sum = 4334.540000000001\n",
      "SR2 sum = 3284.6\n",
      "TRANSIT sum = 7420.280000000004\n",
      "WALK sum = 840.9699999999998\n",
      "DA -  24959.65999999999 4334.540000062003\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['SR2_new', 'TRANSIT_new', 'WALK_new'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:33\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\runway37\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['SR2_new', 'TRANSIT_new', 'WALK_new'] not in index\""
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in ['2040', '2050']:\n",
    "    \n",
    "    if not os.path.exists(f'disagg/{year}'):\n",
    "        os.mkdir(f'disagg/{year}')\n",
    "\n",
    "    for time_period in ['EA','AM','MD','PM','EV']:\n",
    "        df = pd.DataFrame(\n",
    "            DBF(in_table_regex.format(year = year, period = time_period), load = True).records)\n",
    "        \n",
    "        print(df.columns)\n",
    "        for cols in df.columns:\n",
    "            print(f'{cols} sum =', df[cols].sum())\n",
    "\n",
    "        if 'S2' in df.columns:\n",
    "            df.rename(columns = {'S2':'SR2'}, inplace = True)\n",
    "        if 'S3' in df.columns:\n",
    "            df.rename(columns = {'S3':'SR3'}, inplace = True)\n",
    "        \n",
    "        \n",
    "        df_w_xwalk = df.merge(\n",
    "                xwalk, left_on = ['ORIG'], right_on = ['IPZONE'], how = 'left').merge(\n",
    "                xwalk, left_on = ['DEST'], right_on = ['IPZONE'], how = 'left', suffixes = ['_ORIG','_DEST'])\n",
    "\n",
    "        #OD_full_index = pd.MultiIndex.from_product([range(1,max(xwalk.OPZONE) + 1), range(1,max(xwalk.OPZONE) + 1)])\n",
    "\n",
    "        for mode in modes:\n",
    "            #print(mode, df_w_xwalk.columns)\n",
    "            df_w_xwalk[f'{mode}_new'] = df_w_xwalk[mode] * df_w_xwalk.FACTOR_ORIG * df_w_xwalk.FACTOR_DEST\n",
    "            print(f'{mode} - ', df_w_xwalk[f'{mode}'].sum(), df_w_xwalk[f'{mode}_new'].sum())\n",
    "            \n",
    "            #if df_w_xwalk[f'{mode}'].sum() != df_w_xwalk[f'{mode}_new'].sum():\n",
    "            #    break\n",
    "                \n",
    "        df_w_xwalk = df_w_xwalk[['OPZONE_ORIG', 'OPZONE_DEST', 'DA_new', 'SR2_new', 'TRANSIT_new', 'WALK_new']]\n",
    "        \n",
    "        df_w_xwalk = df_w_xwalk.rename(columns={\n",
    "            'OPZONE_ORIG' : 'ORIG',\n",
    "            'OPZONE_DEST' : 'DEST',\n",
    "            'DA_new' : 'DA',\n",
    "            'SR2_new' : 'SR2',\n",
    "            'TRANSIT_new' : 'TRANSIT',\n",
    "            'WALK_new' : 'WALK'\n",
    "        })\n",
    "        \n",
    "        print(f'writing DBF file for {year} and {time_period}')\n",
    "        df2dbf(df_w_xwalk, out_omx_regex.format(year = year, period=time_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b0c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ca156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113104c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:runway37] *",
   "language": "python",
   "name": "conda-env-runway37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
