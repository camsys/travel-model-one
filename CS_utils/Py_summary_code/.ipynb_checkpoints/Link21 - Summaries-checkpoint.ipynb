{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bc7d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmatrix as omx\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "from utility import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c1bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\VY-Projects\\Link21\\notebooks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501f731",
   "metadata": {},
   "source": [
    "#### Import config file parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90bfbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "302cddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d33dff",
   "metadata": {},
   "source": [
    "## Set the Input Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ca519e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the files directory\n",
    "model_outputs_dir = params['model_dir']\n",
    "summary_outputs = params['summary_dir']\n",
    "\n",
    "if not os.path.exists(summary_outputs):\n",
    "    os.mkdir(summary_outputs)\n",
    "\n",
    "#crosswalks\n",
    "cwks_folder = os.path.join(model_outputs_dir, \"cwks\")\n",
    "\n",
    "#Read the data\n",
    "iteration = params['iteration']\n",
    "\n",
    "mode_cat_mapping = params['mode_mapping']\n",
    "\n",
    "periods = params['periods']\n",
    "\n",
    "# skims\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "\n",
    "#landuse\n",
    "landuse_dir = _join(model_outputs_dir, \"landuse\")\n",
    "\n",
    "#demand matrices for active highway and transit\n",
    "demand_matrices_dir = _join(model_outputs_dir, \"demand_matrices\")\n",
    "highway_demand_dir = _join(demand_matrices_dir, \"highway\", \"household\")\n",
    "active_demand_dir = _join(demand_matrices_dir, \"active\")\n",
    "transit_demand_dir = _join(demand_matrices_dir, \"transit\")\n",
    "\n",
    "#transit skims - names\n",
    "acc_egr = params['access_egress_modes']\n",
    "transit_skim_files = []\n",
    "for per in periods:\n",
    "    for acc in acc_egr:\n",
    "        file_name = 'transkm'+per+acc+'.omx'\n",
    "        transit_skim_files.append(file_name)\n",
    "\n",
    "#highway skims\n",
    "highway_skim_files = ['HWYSKM'+per.upper()+'.omx' for per in periods]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d17a7",
   "metadata": {},
   "source": [
    "## Get Geographies/CWKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30957790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taz to RDM zones, super districts, county\n",
    "geo_cwks = pd.read_csv(_join(cwks, \"geographies.csv\")) #columns taz, rdm_zones, super_district, county\n",
    "\n",
    "#taz to priority population\n",
    "pp_perc = pd.read_excel(_join(cwks, \"TAZ_Tract_cwk_summary.xlsx\")) #columns = taz, pp_share \n",
    "\n",
    "#transbay od pairs\n",
    "transbay_od = pd.read_csv(_join(cwks, \"transbay_od.csv\")) #columns = transbay_o, transbay_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c300df",
   "metadata": {},
   "source": [
    "## Calculate Mode Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4325b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tourdata = prepare_tour_roster_df(model_outputs_dir, #\n",
    "        cwks_folder, # folder which has crosswalks\n",
    "        iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69014a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data inputs \n",
    "df_tours = out_tourdata.copy()\n",
    "df_tours['flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1 = df_tours.groupby(['tour_mode', 'transbay_od','tour_purpose', 'pp_share'])['flag'].count().reset_index()\n",
    "tab2 = df_tours.groupby(['tour_mode', 'start_hour'])['flag'].count().reset_index()\n",
    "tab3 = df_tours.groupby(['tour_mode', 'orig_county', 'dest_county'])['flag'].count().reset_index()\n",
    "tab4 = df_tours.groupby(['tour_mode', 'orig_super_dist', 'dest_super_dist'])['flag'].count().reset_index()\n",
    "#tab4 = df_tours.groupby(['tour_mode', 'orig_rdm_zones', 'dest_rdm_zones'])['flag'].count().reset_index()\n",
    "#tab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d45797",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(summary_outputs, 'A3.3.xlsx'), mode = 'w') as writer:\n",
    "        tab1.to_excel(writer, sheet_name='raw_data', startcol=0, index=False)\n",
    "        tab2.to_excel(writer, sheet_name='raw_data', startcol=10, index = False)\n",
    "        tab3.to_excel(writer, sheet_name='raw_data', startcol=20, index = False)\n",
    "        tab4.to_excel(writer, sheet_name='raw_data', startcol=30, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d56349",
   "metadata": {},
   "source": [
    "## Transit Ridership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35fc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tripdata['Mode_Category'] = out_tripdata['trip_mode'].map(mode_cat_mapping)\n",
    "out_tripdata_transit['Mode_Category'] = out_tripdata_transit['trip_mode'].map(mode_cat_mapping)\n",
    "out_tripdata_nontransit['Mode_Category'] = out_tripdata_nontransit['trip_mode'].map(mode_cat_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31490cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridership(out_tripdata, out_tripdata_transit, out_tripdata_nontransit, transbay_orig_taz, transbay_dest_taz, household):\n",
    "\n",
    "    # Trips by mode for all categories\n",
    "    trips_by_mode = out_tripdata.groupby('Mode_Category')['TOURID'].count().reset_index().rename(columns={'TOURID':'Total_Linked_Trips'})\n",
    "    trips_by_mode = trips_by_mode.groupby('Mode_Category')['Total_Linked_Trips'].sum().reset_index()\n",
    "    trips_by_mode['Mode_Category_percShare'] = np.round(trips_by_mode['Total_Linked_Trips']/trips_by_mode['Total_Linked_Trips'].sum(),2)\n",
    "\n",
    "\n",
    "    # Trips by mode for TransBay crossers\n",
    "    out_tripdata_transbay = out_tripdata[(out_tripdata['orig_taz'].isin(transbay_orig_taz)) & (out_tripdata['dest_taz'].isin(transbay_dest_taz)) ]\n",
    "    trips_by_mode_transbay = out_tripdata_transbay.groupby('Mode_Category')['TOURID'].count().reset_index().rename(columns={'TOURID':'Total_Linked_Trips'})\n",
    "    trips_by_mode_transbay = trips_by_mode_transbay.groupby('Mode_Category')['Total_Linked_Trips'].sum().reset_index()\n",
    "    trips_by_mode_transbay['Mode_Category_percShare'] = np.round(trips_by_mode_transbay['Total_Linked_Trips']/trips_by_mode_transbay['Total_Linked_Trips'].sum(),2)\n",
    "\n",
    "\n",
    "    # Trips by mode for Non-TransBay crossers\n",
    "    out_tripdata_nontransbay = out_tripdata[(~out_tripdata['orig_taz'].isin(transbay_orig_taz)) & (~out_tripdata['dest_taz'].isin(transbay_dest_taz))]\n",
    "    trips_by_mode_nontransbay = out_tripdata_nontransbay.groupby('Mode_Category')['TOURID'].count().reset_index().rename(columns={'TOURID':'Total_Linked_Trips'})\n",
    "    trips_by_mode_nontransbay = trips_by_mode_nontransbay.groupby('Mode_Category')['Total_Linked_Trips'].sum().reset_index()\n",
    "    trips_by_mode_nontransbay['Mode_Category_percShare'] = np.round(trips_by_mode_nontransbay['Total_Linked_Trips']/trips_by_mode_nontransbay['Total_Linked_Trips'].sum(),2)\n",
    "\n",
    "\n",
    "    # Trips by depart hour\n",
    "    trips_by_departhour = out_tripdata.groupby('depart_hour')['TOURID'].count().reset_index().rename(columns={'TOURID':'Total_Linked_Trips'})\n",
    "    trips_by_departhour['DepartHour_percShare'] = np.round(trips_by_departhour['Total_Linked_Trips']/trips_by_departhour['Total_Linked_Trips'].sum(),2)\n",
    "\n",
    "\n",
    "    # Trips by origin_purpose (transit only)\n",
    "    trips_by_orig_purpose = out_tripdata_transit.groupby('orig_purpose')['TOURID'].count().reset_index().rename(columns={'TOURID':'Total_Linked_Trips'})\n",
    "        #replacing 'work' with 'Work'\n",
    "    trips_by_orig_purpose.orig_purpose[trips_by_orig_purpose.orig_purpose=='work'] = 'Work'\n",
    "    trips_by_orig_purpose = trips_by_orig_purpose.groupby('orig_purpose')['Total_Linked_Trips'].sum().reset_index()\n",
    "    trips_by_orig_purpose['Orig_Purpose_percShare'] = np.round(trips_by_orig_purpose['Total_Linked_Trips']/trips_by_orig_purpose['Total_Linked_Trips'].sum(),2)\n",
    "    \n",
    "    # Trips by dest_purpose (transit only)\n",
    "    trips_by_dest_purpose = out_tripdata_transit.groupby('dest_purpose')['TOURID'].count().reset_index().rename(columns={'TOURID':'Total_Linked_Trips'})\n",
    "        #replacing 'work' with 'Work'\n",
    "    trips_by_dest_purpose.dest_purpose[trips_by_dest_purpose.dest_purpose=='work'] = 'Work'\n",
    "    trips_by_dest_purpose = trips_by_dest_purpose.groupby('dest_purpose')['Total_Linked_Trips'].sum().reset_index()\n",
    "    trips_by_dest_purpose['Dest_Purpose_percShare'] = np.round(trips_by_dest_purpose['Total_Linked_Trips']/trips_by_dest_purpose['Total_Linked_Trips'].sum(),2)\n",
    "\n",
    "    # Trips by tour_purpose (transit only)\n",
    "    trips_by_tour_purpose = out_tripdata_transit.groupby('tour_purpose')['TOURID'].count().reset_index().rename(columns={'TOURID':'Total_Linked_Trips'})\n",
    "    trips_by_tour_purpose['TourPurpose_percShare'] = np.round(trips_by_tour_purpose['Total_Linked_Trips']/trips_by_tour_purpose['Total_Linked_Trips'].sum(),2)\n",
    "\n",
    "\n",
    "    #Priority population and Non-priority population mode shares\n",
    "    trips_pp = out_tripdata_transit.groupby(['hh_id','Mode_Category'])['TOURID'].count().reset_index().rename(columns={'TOURID':'Total_Linked_Trips'})\n",
    "    trips_pp = trips_pp.merge(household[['hh_id','taz']], on = 'hh_id', how='left')\n",
    "    trips_pp = trips_pp.merge(priority_pop[['TAZ', '% Share PP']], left_on = 'taz', right_on = 'TAZ', how='left')\n",
    "    \n",
    "    trips_pp['Priority_Pop_trips'] = np.round(trips_pp['Total_Linked_Trips']*trips_pp['% Share PP']/100,0)\n",
    "    trips_pp['Non_Priority_Pop_trips'] = np.round(trips_pp['Total_Linked_Trips'] - trips_pp['Priority_Pop_trips'],0)\n",
    "    \n",
    "    trips_pp = trips_pp.groupby('Mode_Category')['Priority_Pop_trips','Non_Priority_Pop_trips'].sum().reset_index()\n",
    "    \n",
    "    trips_pp['Priority_Pop_trips_Share'] = np.round(trips_pp['Priority_Pop_trips']/trips_pp['Priority_Pop_trips'].sum(),2)\n",
    "    trips_pp['Non_Priority_Pop_trips_Share'] = np.round(trips_pp['Non_Priority_Pop_trips']/trips_pp['Non_Priority_Pop_trips'].sum(),2)\n",
    "\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(summary_outputs, 'A3.3.xlsx')) as writer:\n",
    "        trips_by_mode.to_excel(writer, sheet_name='A3.3.1')\n",
    "        trips_by_mode_transbay.to_excel(writer, sheet_name='A3.3.2')\n",
    "        trips_by_mode_nontransbay.to_excel(writer, sheet_name='A3.3.3')\n",
    "        trips_by_departhour.to_excel(writer, sheet_name='A3.3.4')\n",
    "        trips_by_orig_purpose.to_excel(writer, sheet_name='A3.3.5')\n",
    "        trips_by_dest_purpose.to_excel(writer, sheet_name='A3.3.6')\n",
    "        trips_by_tour_purpose.to_excel(writer, sheet_name='A3.3.7')\n",
    "        #trips_pp.to_excel(writer, sheet_name='transit_trips_pp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0854d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transit ridership\n",
    "ridership(out_tripdata, out_tripdata_transit, out_tripdata_nontransit, transbay_orig_taz, transbay_dest_taz, household)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e35ec",
   "metadata": {},
   "source": [
    "## Rail Los and linked trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15910678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_string(string, n):\n",
    "    return [string] * n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3df576",
   "metadata": {},
   "source": [
    "#### Generate rail trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aed869",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = ['EA', 'AM', 'MD', 'PM', 'EV']\n",
    "acc_egg_modes = ['KNR_TRN_WLK', 'PNR_TRN_WLK', 'WLK_TRN_KNR', 'WLK_TRN_PNR', 'WLK_TRN_WLK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae424c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the Rail Demand Files\n",
    "for per in period:\n",
    "    print(\"Period: \",per)\n",
    "    trn_dmnd = omx.open_file(os.path.join(transit_demand_dir, \"trn_demand_v9_trim_\" + per + \".omx\"))\n",
    "    \n",
    "    rail_dmn_per = []\n",
    "    rail_demand = omx.open_file(os.path.join(transit_demand_dir, \"rail_demand_v9_trim_\" + per + \".omx\"),'w') \n",
    "    for acc_egg in acc_egg_modes:\n",
    "        print(\"Access Egress Mode: \",acc_egg)\n",
    "        trn_dmn_acc = np.array(trn_dmnd[acc_egg])\n",
    "        trn_skm = omx.open_file(os.path.join(skims_dir, \"trnskm\" + per.lower() +\"_\" + acc_egg.lower() + \".omx\"))\n",
    "        ivthvy = np.array(trn_skm['IVTHVY'])\n",
    "        ivtcom = np.array(trn_skm['IVTCOM'])\n",
    "        ivtrail = ivthvy + ivtcom\n",
    "        ivtrail[ivtrail > 0] = 1\n",
    "        rail_dmn = trn_dmn_acc * ivtrail\n",
    "        rail_demand[acc_egg] = rail_dmn\n",
    "    \n",
    "    rail_demand.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aeb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create summary of tranist trips by cores and Rail trips\n",
    "final_df = []\n",
    "n = len(acc_egg_modes)\n",
    "\n",
    "for per in period:\n",
    "    #print(\"Period: \",per)\n",
    "    trn_dmnd = omx.open_file(os.path.join(transit_demand_dir, \"trn_demand_v9_trim_\" + per + \".omx\"))\n",
    "    rail_dmnd = omx.open_file(os.path.join(transit_demand_dir, \"rail_demand_v9_trim_\" + per + \".omx\"))\n",
    "    \n",
    "    rail = []\n",
    "    trn = []\n",
    "    modes = []\n",
    "    for acc_egg in acc_egg_modes:\n",
    "        #print(\"Access Egress Mode: \", acc_egg )\n",
    "        rail_trips = np.array(rail_dmnd[acc_egg]).sum()\n",
    "        trn_trips = np.array(trn_dmnd[acc_egg]).sum()\n",
    "        \n",
    "        rail.append(rail_trips)\n",
    "        trn.append(trn_trips)\n",
    "        modes.append(acc_egg)\n",
    "    \n",
    "    df = pd.DataFrame({'period': repeat_string(per, n),'modes': modes, 'transit_trips': trn, 'rail_trips': rail})\n",
    "    final_df.append(df)\n",
    "    \n",
    "transit_trips_df = pd.concat(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_trips = transit_trips_df.pivot(index = 'modes', columns = 'period', values = 'transit_trips')\n",
    "rail_trips = transit_trips_df.pivot(index = 'modes', columns = 'period', values = 'rail_trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistics \n",
    "\n",
    "stat_cores = ['IVTHVY', # in-vehicle travel tim\n",
    "              'WAIT',\n",
    "              'WACC',\n",
    "              'WEGR',\n",
    "              'XWAIT',\n",
    "              'DTIME'             \n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = []\n",
    "modes = []\n",
    "n = len(stat_cores)\n",
    "for per in period:\n",
    "    #print(\"Period: \",per)\n",
    "    rail_dmnd = omx.open_file(os.path.join(transit_demand_dir, \"rail_demand_v9_trim_\" + per + \".omx\"))\n",
    "    \n",
    "    tt = []\n",
    "    for acc_egg in acc_egg_modes:\n",
    "       # print(\"Access Egress Mode: \",acc_egg)\n",
    "        trn_dmn_acc = np.array(rail_dmnd[acc_egg])\n",
    "        trn_skm = omx.open_file(os.path.join(skims_dir, \"trnskm\" + per.lower() +\"_\" + acc_egg.lower() + \".omx\"))\n",
    "        \n",
    "        avg_stat = []\n",
    "        for core in stat_cores:\n",
    "            m1 = np.array(trn_skm[core])\n",
    "            m2 = trn_dmn_acc\n",
    "            avg_stat_trn = np.dot(m1, m2).sum() / m2.sum()\n",
    "            avg_stat.append(avg_stat_trn)\n",
    "            \n",
    "        #print(avg_stat)\n",
    "        df = pd.DataFrame({'period': repeat_string(per, n),'modes': repeat_string(acc_egg, n), 'Cores': stat_cores, 'values': avg_stat})\n",
    "        final_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c39da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(final_df)\n",
    "core_summaries = results.pivot(index= ['period', 'modes'], columns='Cores', values='values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cabd79",
   "metadata": {},
   "source": [
    "#### Calculate Perceived travel time savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Calculate Perceived travel time savings\n",
    "final_df = []\n",
    "n = len(acc_egg_modes)\n",
    "for per in period:\n",
    "    print(\"Period: \",per)\n",
    "    trn_dmnd = omx.open_file(os.path.join(transit_demand_dir, \"trn_demand_v9_trim_\" + per + \".omx\"))\n",
    "    \n",
    "    tt = []\n",
    "    modes = []\n",
    "    for acc_egg in acc_egg_modes:\n",
    "        print(\"Access Egress Mode: \",acc_egg)\n",
    "        trn_dmn_acc = np.array(trn_dmnd[acc_egg])\n",
    "        trn_skm = omx.open_file(os.path.join(skims_dir, \"trnskm\" + per.lower() +\"_\" + acc_egg.lower() + \".omx\"))\n",
    "        \n",
    "        #for Perceived travel time savings  TODO: Change IVTCOM and IVTHVY\n",
    "        travel_time = np.array(trn_skm['IVTCOM']) + np.array(trn_skm['DTIME']) + np.array(trn_skm['WACC']) + \\\n",
    "                        np.array(trn_skm['IVTHVY']) + np.array(trn_skm['WEGR']) + np.array(trn_skm['WAUX']) + \\\n",
    "                              np.array(trn_skm['XWAIT'])\n",
    "        \n",
    "        avg_tt = np.dot(travel_time, trn_dmn_acc).sum() / trn_dmn_acc.sum()                    \n",
    "        tt.append(avg_tt)\n",
    "        modes.append(acc_egg)\n",
    "        \n",
    "    df = pd.DataFrame({'period': repeat_string(per, n),'modes': modes, 'p_tt': tt})\n",
    "    final_df.append(df)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d98855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(final_df)\n",
    "perc_travel_time = results.pivot(index= ['modes'], columns='period', values='p_tt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(summary_outputs, 'PM_TRN_A1.xlsx')) as writer:\n",
    "    transit_trips.to_excel(writer, sheet_name='transit_trips')\n",
    "    rail_trips.to_excel(writer, sheet_name='rail_trips')\n",
    "    core_summaries.to_excel(writer, sheet_name='avg_skim_cores')\n",
    "    perc_travel_time.to_excel(writer, sheet_name='perceived_tt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5f65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d9f9456",
   "metadata": {},
   "source": [
    "## Connectivity \n",
    "##### 1. Jobs accessible from peopleâ€™s homes \n",
    "##### 2. Business access to potential employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaff0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwyskmMD = os.path.join(skims_dir, \"hwyskmMD.omx\")\n",
    "tazData = pd.read_csv(os.path.join(landuse_dir, \"tazdata.csv\"))\n",
    "\n",
    "mat_core = 'TIMEDAM'    #TO DO Check the Matrix core name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timedaData = convertMat2Df(hwyskmMD, 'TIMEDAM') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37bb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tazDataTotemp = tazData[[\"ZONE\", \"TOTEMP\"]]\n",
    "tazDataEmpres = tazData[[\"ZONE\", \"EMPRES\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total employment based on destination\n",
    "odData = pd.merge(timedaData, tazDataTotemp, left_on='dest', right_on='ZONE', how = 'left')\n",
    "odData['TOTEMP'] = odData['TOTEMP'].fillna(0)\n",
    "\n",
    "#employed residents based on origin\n",
    "odData = pd.merge(odData, tazDataEmpres, left_on='orig', right_on='ZONE', how = 'left')\n",
    "odData['EMPRES'] = odData['EMPRES'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90688a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "odData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ada8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "odData10 = odData[odData['TIMEDA'] <= 10]\n",
    "    \n",
    "    # ORIGIN AND TOTEMP COLUMNS\n",
    "    odData10 = odData10[[\"ORIGIN\", \"TOTEMP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timedaData = pd.DataFrame(hwyskmMD['TIMEDA'])\n",
    "odData = timedaData.stack().reset_index().set_axis('ORIGIN DESTINATION TIMEDA'.split(), axis=1)\n",
    "\n",
    "odData['ORIGIN'] = (odData['ORIGIN'] + 1)\n",
    "odData['DESTINATION'] = (odData['DESTINATION'] + 1)\n",
    "\n",
    "tazDataTotemp = tazData[[\"ZONE\", \"TOTEMP\"]]\n",
    "tazDataDestination = tazDataTotemp.rename(columns={'ZONE': 'DESTINATION'})\n",
    "\n",
    "tazDataEmpres = tazData[[\"ZONE\", \"EMPRES\"]]\n",
    "\n",
    "tazDataOrigin = tazDataEmpres.rename(columns={'ZONE': 'ORIGIN'})\n",
    "\n",
    "odData = pd.merge(odData, tazDataDestination)\n",
    "\n",
    "odData['TOTEMP'] = odData['TOTEMP'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dab780",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_thresholds = [10, 15, 30, 45, 60, ]\n",
    "\n",
    "acc_jobs = []\n",
    "acc_emp = []\n",
    "\n",
    "for threshold in time_thresholds:\n",
    "    # FILTER BY: TRIPS LESS THAN OR EQUAL TO 10 MIN\n",
    "    odData10 = odData[odData['TIMEDA'] <= 10]\n",
    "    \n",
    "    # ORIGIN AND TOTEMP COLUMNS\n",
    "    odData10 = odData10[[\"ORIGIN\", \"TOTEMP\"]]\n",
    "    \n",
    "    # GROUP BY ORIGIN ZONE: SUM TOTEMP\n",
    "    odData10 = odData10.groupby(['ORIGIN'])['TOTEMP'].sum().reset_index()\n",
    "    \n",
    "    # MERGE odData10 and tazDataOrigin\n",
    "    odData10 = pd.merge(odData10, tazDataOrigin, left_on= ['ORIGIN'], right_on =['ORIGIN'], how ='left')\n",
    "    #odData10\n",
    "\n",
    "    # PRODUCT OF TOTEMP EMPRES\n",
    "    odData10['PRODUCT'] = odData10['TOTEMP'] * odData10['EMPRES']\n",
    "    #odData10\n",
    "\n",
    "    # SUM EMPRES AND PRODUCT\n",
    "    TOTEMPsum10 = odData10['TOTEMP'].sum()\n",
    "    EMPRESsum10 = odData10['EMPRES'].sum()\n",
    "    PRODUCTsum10 = odData10['PRODUCT'].sum()\n",
    "\n",
    "    # DETERMINE AVERAGE NUMBER OF JOBS ACCESSIBLE FROM ONE'S HOME\n",
    "    ACCESSIBILITYjobs10 = PRODUCTsum10/EMPRESsum10\n",
    "    acc_jobs.append(ACCESSIBILITYjobs10)\n",
    "\n",
    "    # DETERMINE BUSINESS ACCESS TO POTENTIAL EMPLOYEES\n",
    "    ACCESSIBILITYemp10 = PRODUCTsum10/TOTEMPsum10\n",
    "    acc_emp.append(ACCESSIBILITYemp10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'time_threshold': time_thresholds, 'jobs_from_home': acc_jobs, 'emp_access' : acc_emp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814570e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef40d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dafa73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e62cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(r\"C:\\Users\\vyadav\\Cambridge Systematics\\PROJ 220073 RHETTA ETruc - Documents\\General\\3_DataAnalysis\\data\\partitions\\feb_8_15_2021\\waypoint_0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b101bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789008b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_parquet(r\"C:\\Users\\vyadav\\Cambridge Systematics\\PROJ 220073 RHETTA ETruc - Documents\\General\\3_DataAnalysis\\data\\out\\feb_8_15_2021\\waypoint_0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ba877",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['firstRec']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39ddd41",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5aef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_share(out_tourdata, transbay_orig_taz, transbay_dest_taz, summary_outputs, household):\n",
    "\n",
    "    # Tours by mode for all categories\n",
    "    tours_by_mode = out_tourdata.groupby('Mode_Category')['JTOUR_ID'].count().reset_index().rename(columns={'JTOUR_ID':'Total_Tours'})\n",
    "    tours_by_mode['Mode_Category_percShare'] = np.round(tours_by_mode['Total_Tours']/tours_by_mode['Total_Tours'].sum(),precision)\n",
    "    #tours_by_mode\n",
    "\n",
    "    # Tours by mode for TransBay crossers\n",
    "    out_tourdata_transbay = out_tourdata[(out_tourdata['orig_taz'].isin(transbay_orig_taz)) & (out_tourdata['dest_taz'].isin(transbay_dest_taz)) ]\n",
    "    tours_by_mode_transbay = out_tourdata_transbay.groupby('Mode_Category')['JTOUR_ID'].count().reset_index().rename(columns={'JTOUR_ID':'Total_Tours'})\n",
    "    tours_by_mode_transbay['Mode_Category_percShare'] = np.round(tours_by_mode_transbay['Total_Tours']/tours_by_mode_transbay['Total_Tours'].sum(),precision)\n",
    "\n",
    "    # Tours by mode for Non-TransBay crossers\n",
    "    out_tourdata_nontransbay = out_tourdata[(~out_tourdata['orig_taz'].isin(transbay_orig_taz)) & (~out_tourdata['dest_taz'].isin(transbay_dest_taz)) ]\n",
    "    tours_by_mode_nontransbay = out_tourdata_nontransbay.groupby('Mode_Category')['JTOUR_ID'].count().reset_index().rename(columns={'JTOUR_ID':'Total_Tours'})\n",
    "    tours_by_mode_nontransbay['Mode_Category_percShare'] = np.round(tours_by_mode_nontransbay['Total_Tours']/tours_by_mode_nontransbay['Total_Tours'].sum(),precision)\n",
    "\n",
    "    # Tours by depart hour\n",
    "    tours_by_departhour = out_tourdata.groupby(['start_hour','Mode_Category'])['JTOUR_ID'].count().reset_index().rename(columns={'JTOUR_ID':'Total_Tours'})\n",
    "    tours_by_departhour['Mode_Category_percShare'] = np.round(tours_by_departhour['Total_Tours']/tours_by_departhour['Total_Tours'].sum(),precision)\n",
    "\n",
    "    # Tours by tour purpose\n",
    "    tours_by_purpose = out_tourdata.groupby('tour_purpose')['JTOUR_ID'].count().reset_index().rename(columns={'JTOUR_ID':'Total_Tours'})\n",
    "    tours_by_purpose['TourPurpose_percShare'] = np.round(tours_by_purpose['Total_Tours']/tours_by_purpose['Total_Tours'].sum(),precision)\n",
    "\n",
    "    #Priority population and Non-priority population mode shares\n",
    "    tours_pp = out_tourdata.groupby(['hh_id','Mode_Category'])['JTOUR_ID'].count().reset_index().rename(columns={'JTOUR_ID':'Total_Tours'})\n",
    "    tours_pp = tours_pp.merge(household[['hh_id','taz']], on = 'hh_id', how='left')\n",
    "    tours_pp = tours_pp.merge(priority_pop[['TAZ', '% Share PP']], left_on = 'taz', right_on = 'TAZ', how='left')\n",
    "\n",
    "    tours_pp['Priority_Pop_tours'] = np.round(tours_pp['Total_Tours']*tours_pp['% Share PP']/100,0)\n",
    "    tours_pp['Non_Priority_Pop_tours'] = np.round(tours_pp['Total_Tours'] - tours_pp['Priority_Pop_tours'],0)\n",
    "    tours_pp = tours_pp.groupby('Mode_Category')['Priority_Pop_tours','Non_Priority_Pop_tours'].sum().reset_index()\n",
    "\n",
    "    tours_pp['Priority_Pop_tours_share'] = np.round(tours_pp['Priority_Pop_tours']/tours_pp['Priority_Pop_tours'].sum(),precision)\n",
    "    tours_pp['Non_Priority_Pop_tours_share'] = np.round(tours_pp['Non_Priority_Pop_tours']/tours_pp['Non_Priority_Pop_tours'].sum(),precision)\n",
    "\n",
    "    tours_pp = tours_pp[['Mode_Category','Priority_Pop_tours', 'Non_Priority_Pop_tours','Priority_Pop_tours_share', 'Non_Priority_Pop_tours_share']]\n",
    "\n",
    "\n",
    "    with pd.ExcelWriter(os.path.join(summary_outputs, 'A3.3.xlsx')) as writer:\n",
    "        trips_by_mode.to_excel(writer, sheet_name='A3.3.1')\n",
    "        trips_by_mode_transbay.to_excel(writer, sheet_name='A3.3.2')\n",
    "        trips_by_mode_nontransbay.to_excel(writer, sheet_name='A3.3.3')\n",
    "        trips_by_departhour.to_excel(writer, sheet_name='A3.3.4')\n",
    "        trips_by_orig_purpose.to_excel(writer, sheet_name='A3.3.5')\n",
    "        trips_by_dest_purpose.to_excel(writer, sheet_name='A3.3.6')\n",
    "        trips_by_tour_purpose.to_excel(writer, sheet_name='A3.3.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21cc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\vyadav\\Cambridge Systematics\\PROJ 220073 RHETTA ETruc - Documents\\General\\2_Data\\INRIX Data\\feb_8_15_2021\\trips.csv.gz\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = r\"C:\\Users\\vyadav\\Cambridge Systematics\\PROJ 220073 RHETTA ETruc - Documents\\General\\2_Data\\INRIX Data\\feb_8_15_2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ff8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = {\n",
    "    'waypoint' : pd.read_csv(os.path.join(in_dir, 'TripBulkReportWaypointsHeaders.csv')).columns.to_list() + ['NANS'],\n",
    "    'trips' : pd.read_csv(os.path.join(in_dir, 'TripBulkReportTripsHeaders.csv')).columns.to_list() + ['NANS']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc173121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = col_names['trips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d395a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:runway37] *",
   "language": "python",
   "name": "conda-env-runway37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
