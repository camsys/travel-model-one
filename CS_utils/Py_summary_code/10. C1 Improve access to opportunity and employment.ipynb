{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec4b24-c07a-4ea4-b6c8-4261766a05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmatrix as omx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from utility import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6a2cc-997e-4f1e-97b9-aa2953778948",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "landuse_dir = _join(model_outputs_dir, \"landuse\")\n",
    "\n",
    "ctramp_dir = params['ctramp_dir']\n",
    "summary_outputs = params['summary_dir']\n",
    "mat_core = params['connectivity_mat_core']\n",
    "time_thresholds = params['accessibility_thresholds']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "summary_columns = params['final_columns']\n",
    "\n",
    "preprocess_dir = _join(ctramp_dir, '_pre_process_files')\n",
    "perf_measure_columns = params['final_columns']\n",
    "period = params['periods']\n",
    "summary_dir = params['summary_dir']\n",
    "\n",
    "best_path_skim_extension = params['best_path_skim_extension']\n",
    "\n",
    "annual_transit_factor = params['annual_transit_factor']\n",
    "annual_auto_factor = params['annual_auto_factor']\n",
    "\n",
    "filename_extension = params['filename_extension']\n",
    "\n",
    "\n",
    "mat_core = params['connectivity_mat_core']\n",
    "time_thresholds = params['accessibility_thresholds']\n",
    "\n",
    "travel_time_cores = params['total_travel_time']\n",
    "time_periods = params['periods']\n",
    "acc_egr = params['access_egress_modes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09f483-7f55-40c1-8516-1dc1f034e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "\n",
    "#taz to RDM zones, super districts, county\n",
    "geo_cwks = pd.read_csv(_join(params['common_dir'], \"geographies.csv\")) #columns taz, rdm_zones, super_district, county\n",
    "\n",
    "#taz to priority population\n",
    "pp_perc = pd.read_excel(_join(params['common_dir'], \"TAZ_Tract_cwk_summary.xlsx\")) #columns = taz, pp_share \n",
    "\n",
    "#get geogrpahies and priority population in the same file\n",
    "geo_pp_cwks = pd.merge(geo_cwks, pp_perc, on = 'taz', how = 'left') \n",
    "\n",
    "#transbay od pairs\n",
    "#transbay_od = pd.read_csv(_join(params['common_dir'], \"transbay_od.csv\")) #columns = transbay_o, transbay_d\n",
    "\n",
    "#non work destinations tazs\n",
    "non_work_tazs = pd.read_excel(_join(params['common_dir'], 'non_work_destinations.xlsx'))\n",
    "#non_work_tazs = list(non_work_tazs['non_wrk_taz'])\n",
    "\n",
    "#taz data for empoyments and resindent employments\n",
    "tazData = pd.read_csv(_join(params['model_dir'], params['zone_file']))\n",
    "tazDataTotemp = tazData[[\"ZONE\", \"TOTEMP\"]]\n",
    "tazDataEmpres = tazData[[\"ZONE\", \"EMPRES\"]]\n",
    "tazDataPop = tazData[[\"ZONE\", \"TOTPOP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571bce6-378b-48e3-a157-56ff0a5d9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tod_tt = pd.read_parquet(_join(preprocess_dir, 'tod_min_actual_travel_time.parquet'))\n",
    "perc_tod_tt = pd.read_parquet(_join(preprocess_dir, 'tod_min_perceived_travel_time.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afdd597-9ce6-49b3-b8ca-4c506ab2f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_accessibile_employees(all_tod_tt, time_periods, time_thresholds, geo_pp_cwks, tt_verbose):\n",
    "\n",
    "    acc_jobs = []\n",
    "    acc_jobs_nwd = []\n",
    "    df = []\n",
    "    acc_jobs_pp = []\n",
    "    acc_jobs_rdm = []\n",
    "    acc_jobs_sd = []\n",
    "    acc_jobs_cnty = []\n",
    "    \n",
    "    #for 25 transit skims files - this includes time periods\n",
    "    for period in time_periods:\n",
    "        \n",
    "        if period in all_tod_tt.columns:\n",
    "            \n",
    "            timedaData = all_tod_tt[[period]].reset_index()\n",
    "            print(timedaData.columns)\n",
    "            #timedaData = timedaData.fillna(0)\n",
    "            timedaData[period] = timedaData[period]/100\n",
    "            \n",
    "            #employed residents based on destination\n",
    "            od_data = pd.merge(timedaData, tazDataEmpres, left_on='dest', right_on='ZONE', how = 'left')\n",
    "            od_data['EMPRES'] = od_data['EMPRES'].fillna(0)\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                #print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[period] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['EMPRES'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataTotemp, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_totemp'] = oddata_min['TOTEMP'] * oddata_min['EMPRES']\n",
    "                job_acc_min = oddata_min['wt_totemp'].sum()/oddata_min['TOTEMP'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "                \n",
    "                df_temp_region = pd.DataFrame({'Description': \"Business access to potential employees within \"+ tt_verbose + \" \"  + str(threshold) + \" minutes\",\n",
    "                                               'Population': 'Whole Population',\n",
    "                                               'Period': period,\n",
    "                                               'Geography': 'Regional total',\n",
    "                                               'Zone_ID': 'Region',\n",
    "                                               'Submetric': 'C1.2.1',\n",
    "                                               'Total_Increment': '',\n",
    "                                               'Value': job_acc_min}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "                \n",
    "                # for prioirty population\n",
    "                \"\"\"\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_empres_pp'] = oddata_min['TOTEMP'] * oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['EMPRES_pp'] = oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_empres_pp','EMPRES_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['buss_acc_emp'] = oddata_min_pp['wt_empres_pp']/oddata_min_pp['EMPRES_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'buss_acc_emp']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_nonpp['buss_acc_emp'] = oddata_min_nonpp['wt_empres']/oddata_min_nonpp['EMPRES']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'buss_acc_emp']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb['time_threshold'] = threshold\n",
    "                    oddata_min_comb['transit_file'] = transit_file_name\n",
    "                    oddata_min_comb['time'] = core\n",
    "                    acc_jobs_pp.append(oddata_min_comb)\n",
    "                \"\"\"\n",
    "                \n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_totemp','TOTEMP'].sum().reset_index()\n",
    "                    oddata_min_cnty['Value'] =  oddata_min_cnty['wt_totemp']/oddata_min_cnty['TOTEMP']\n",
    "                    oddata_min_cnty['Description'] = \"Business access to potential employees within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_cnty['Period'] = period\n",
    "                    oddata_min_cnty['Geography'] = 'County'\n",
    "                    oddata_min_cnty['Population'] = 'Whole Population'\n",
    "                    oddata_min_cnty.rename(columns={'county': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_cnty = oddata_min_cnty[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]   \n",
    "                    oddata_min_cnty['Submetric'] = 'C1.2.2'\n",
    "                    oddata_min_cnty['Total_Increment'] = ''\n",
    "                    acc_jobs_cnty.append(oddata_min_cnty)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_totemp','TOTEMP'].sum().reset_index()\n",
    "                    oddata_min_rdm['Value'] =  oddata_min_rdm['wt_totemp']/oddata_min_rdm['TOTEMP']\n",
    "                    oddata_min_rdm['Description'] = \"Business access to potential employees within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_rdm['Period'] = period\n",
    "                    oddata_min_rdm['Geography'] = 'RDM'\n",
    "                    oddata_min_rdm['Population'] = 'Whole Population'\n",
    "                    oddata_min_rdm.rename(columns={'rdm_zones' : 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_rdm = oddata_min_rdm[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_rdm['Submetric'] = 'C1.2.3'\n",
    "                    oddata_min_rdm['Total_Increment'] = ''\n",
    "                    acc_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_totemp', 'TOTEMP'].sum().reset_index()\n",
    "                    oddata_min_sd['Value'] =  oddata_min_sd['wt_totemp']/oddata_min_sd['TOTEMP']\n",
    "                    oddata_min_sd['Description'] = \"Business access to potential employees within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_sd['Period'] = period\n",
    "                    oddata_min_sd['Population'] = 'Whole Population'\n",
    "                    oddata_min_sd['Geography'] = 'Superdistrict'\n",
    "                    oddata_min_sd.rename(columns={'super_district': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_sd = oddata_min_sd[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_sd['Submetric'] = 'C1.2.4'\n",
    "                    oddata_min_sd['Total_Increment'] = ''\n",
    "                    acc_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "\n",
    "                    \n",
    "        else:\n",
    "            print(f'{period} travel time doesn\\'t exist.')\n",
    "            \n",
    "    df_region = pd.concat(df).reset_index(drop=True)\n",
    "    #df_pp = pd.concat(acc_jobs_pp).reset_index(drop=True)\n",
    "    df_rdm = pd.concat(acc_jobs_rdm).reset_index(drop=True)\n",
    "    df_sd = pd.concat(acc_jobs_sd).reset_index(drop=True)\n",
    "    df_cnty = pd.concat(acc_jobs_cnty).reset_index(drop=True)\n",
    "    \n",
    "    return df_region, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decimals = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1455992-1bad-40fc-b560-f1d302e9428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region_act, df_rdm_act, df_sd_act, df_cnty_act = business_accessibile_employees(all_tod_tt, time_periods, \n",
    "                                                                   time_thresholds, geo_pp_cwks, \"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df_act = pd.concat([df_region_act, df_rdm_act, df_sd_act, df_cnty_act], ignore_index=True)\n",
    "                        \n",
    "comb_df_act['Concept_ID'] = concept_id\n",
    "comb_df_act['Metric_ID'] = 'C1.2'\n",
    "comb_df_act['Metric_name'] = 'Accessibility to workforce from employment opportunities - actual travel time'\n",
    "comb_df_act['Origin_zone'] = ''\n",
    "comb_df_act['Dest_zone'] = ''\n",
    "comb_df_act['Purpose'] = ''\n",
    "comb_df_act['Units'] = 'Employees'\n",
    "comb_df_act['Value'] = comb_df_act['Value'].apply(lambda x: round(x, decimals))\n",
    "comb_df_act['Income'] = ''\n",
    "comb_df_act['Mode'] = ''\n",
    "\n",
    "comb_df_act = comb_df_act[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d048a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_medtric_ids = comb_df_act['Submetric'].unique()\n",
    "for mids in unique_medtric_ids:\n",
    "    metric_name = '_accessibility_to_workforce_actual_time_'\n",
    "    dfs = comb_df_act.loc[comb_df_act['Submetric']==mids]\n",
    "    #print(dfs.columns)\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    dfs = dfs[perf_measure_columns]\n",
    "    file_name = mids\n",
    "    geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "    dfs.to_csv(_join(summary_dir, file_name + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Value'].sum(), metric_name)\n",
    "\n",
    "comb_df_act.to_csv(_join(summary_dir, 'C1.2' + '_accessibility_to_workforce_actual_time_' + concept_id + '_region' + filename_extension + '.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region_perc, df_rdm_perc, df_sd_perc, df_cnty_perc = business_accessibile_employees(perc_tod_tt, time_periods, \n",
    "                                                                   time_thresholds, geo_pp_cwks, \"perceived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc82501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comb_df_perc = pd.concat([df_region_perc, df_rdm_perc, df_sd_perc, df_cnty_perc], ignore_index=True)\n",
    "\n",
    "comb_df_perc['Concept_ID'] = concept_id\n",
    "comb_df_perc['Metric_ID'] = 'C1.2'\n",
    "comb_df_perc['Metric_name'] = 'Accessibility to workforce from employment opportunities - perceived travel time'\n",
    "comb_df_perc['Origin_zone'] = ''\n",
    "comb_df_perc['Dest_zone'] = ''\n",
    "comb_df_perc['Purpose'] = ''\n",
    "comb_df_perc['Units'] = 'Employees'\n",
    "comb_df_perc['Value'] = comb_df_perc['Value'].apply(lambda x: round(x, decimals))\n",
    "comb_df_perc['Income'] = ''\n",
    "comb_df_perc['Mode'] = ''\n",
    "\n",
    "comb_df_perc = comb_df_perc[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_medtric_ids = comb_df_perc['Submetric'].unique()\n",
    "for mids in unique_medtric_ids:\n",
    "    metric_name = '_accessibility_to_workforce_perceived_time_'\n",
    "    dfs = comb_df_perc.loc[comb_df_perc['Submetric']==mids]\n",
    "    #print(dfs.columns)\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    dfs = dfs[perf_measure_columns]\n",
    "    file_name = dfs['Submetric'][0]\n",
    "    geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "    dfs.to_csv(_join(summary_dir, file_name + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Value'].sum())\n",
    "\n",
    "comb_df_perc.to_csv(_join(summary_dir, 'C1.2' + '_accessibility_to_workforce_perceived_time_' + concept_id + '_region' + filename_extension + '.csv'), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
