{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmatrix as omx\n",
    "import random\n",
    "import yaml\n",
    "import geopandas as gpd\n",
    "\n",
    "from utility import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -v \"openpyxl==3.1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bd7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "\n",
    "# paths\n",
    "ctramp_dir = params['ctramp_dir']\n",
    "summary_outputs = params['summary_dir']\n",
    "concept_id = params['concept_id']\n",
    "model_dir = params['model_dir']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "perf_measure_columns = params['final_columns']\n",
    "transit_data = params['transit_output_data']\n",
    "preprocess_dir = _join(ctramp_dir, '_pre_process_files')\n",
    "\n",
    "output_summary = _join(model_dir, 'output_summaries')\n",
    "transit_dashboard = _join(preprocess_dir, 'transit_dashboard')\n",
    "\n",
    "filename_extension = params['filename_extension']\n",
    "\n",
    "if not os.path.exists(transit_dashboard):\n",
    "    os.makedirs(transit_dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_period = {'AM' : 1, 'MD' : 2, 'PM': 3, 'EV': 4, 'EA': 5}\n",
    "\n",
    "agency_mapping = {'BART' : 1, 'Caltrain': 2, 'Amtrak': 3, 'Valley Link': 4, 'ACE': 5}\n",
    "\n",
    "#rail_agency = [36,38,39,43,44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5450a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_cwk = pd.read_excel(_join(transit_data, 'Link21 emme_tlines.2050_Baseline_R2_Run4.xlsx'), sheet_name=\"Dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e64fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_cwk['Agency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_cwk = line_cwk[['ID', 'MODE', '#time_peri', 'Agency']]\n",
    "line_cwk.columns = ['line', 'mode', 'time_period', 'agency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_cwk['agency'] = line_cwk['agency'].map(agency_mapping)\n",
    "line_cwk['scenario'] = concept_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117684e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_agency = list(line_cwk['agency'].unique())\n",
    "rail_agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted = 0\n",
    "\n",
    "if adjusted:\n",
    "    segment_volume = _join(transit_data, \"adjusted\")\n",
    "else:\n",
    "    segment_volume = _join(transit_data)\n",
    "\n",
    "print(segment_volume)\n",
    "\n",
    "\n",
    "segment_transfers = _join(output_summary)\n",
    "print(segment_transfers)\n",
    "\n",
    "\n",
    "segmentfiles = [f for f in os.listdir(segment_volume) if f.startswith('Segment')]\n",
    "segmentfiles_transfers = [f for f in os.listdir(segment_transfers) if f.startswith('transit_segment')]\n",
    "\n",
    "all_segments = []\n",
    "for file in segmentfiles:\n",
    "    print(file)\n",
    "    segment = pd.read_csv(_join(segment_volume, file))\n",
    "    segment.columns = segment.columns.str.lower()\n",
    "    segment = segment.rename(columns={'estperiodcapacity': 'periodcapacity'})\n",
    "    segment = segment[~segment['line'].astype(str).str.startswith(('pnr'))]\n",
    "    segment = segment[['line', 'segment', 'volume', 'board', 'alight', 'totalcapacity', 'periodcapacity', 'stop']]\n",
    "    segment[['i_station', 'j_station']] = segment['segment'].str.split(\"-\", expand=True)\n",
    "    all_segments.append(segment)\n",
    "\n",
    "all_trnfrs = []\n",
    "for file in segmentfiles_transfers:\n",
    "    print(file)\n",
    "    trnfrs = segment = pd.read_csv(_join(segment_transfers, file))\n",
    "    trnfrs.columns = segment.columns.str.lower()\n",
    "    trnfrs = trnfrs[~trnfrs['line'].astype(str).str.startswith(('pnr'))]\n",
    "    trnfrs = trnfrs.rename(columns={'line':'seg_id'})\n",
    "\n",
    "    trnfrs = trnfrs.groupby(['seg_id'])['direct_transfer_board_ptw', \n",
    "                     'direct_transfer_board_wtp',\n",
    "                     'direct_transfer_board_ktw', \n",
    "                     'direct_transfer_board_wtk',\n",
    "                     'direct_transfer_board_wtw', \n",
    "                     'auxiliary_transfer_board_ptw', \n",
    "                     'auxiliary_transfer_board_wtp', \n",
    "                     'auxiliary_transfer_board_ktw', \n",
    "                     'auxiliary_transfer_board_wtk',\n",
    "                     'auxiliary_transfer_board_wtw'].sum()\n",
    "\n",
    "    trnfrs['transfers'] = trnfrs.sum(axis=1)\n",
    "    trnfrs = trnfrs[['transfers']].reset_index()\n",
    "\n",
    "    all_trnfrs.append(trnfrs)\n",
    "\n",
    "all_trnfrs = pd.concat(all_trnfrs, ignore_index=True)\n",
    "all_trnfrs['scenario'] = concept_id\n",
    "\n",
    "all_trnfrs = all_trnfrs[['seg_id', 'scenario' ,'transfers']]\n",
    "\n",
    "all_segments = pd.concat(all_segments, ignore_index=True)  \n",
    "all_segments = pd.merge(all_segments, line_cwk, on=['line'], how='left')\n",
    "all_segments =  all_segments[all_segments['agency'].isin(rail_agency)]\n",
    "all_segments['time_period'] = all_segments['time_period'].map(time_period)\n",
    "all_segments['crowding'] = all_segments['volume'] /all_segments['periodcapacity']\n",
    "\n",
    "all_segments['volume'] = all_segments['volume'].round()\n",
    "all_segments['board'] = all_segments['board'].round()\n",
    "all_segments['alight'] = all_segments['alight'].round()\n",
    "\n",
    "all_segments['seg_id'] = [str(x)+'-'+str(y)+'-'+str(z) for x,y,z in zip(all_segments['line'], \n",
    "                                                                        all_segments['i_station'], \n",
    "                                                                        all_segments['j_station'])]\n",
    "\n",
    "\n",
    "print(all_segments.columns)\n",
    "all_segments = all_segments.drop(columns= ['segment'])\n",
    "print(all_trnfrs.columns)\n",
    "all_segments = pd.merge(all_segments, all_trnfrs, on=['seg_id', 'scenario'], how='left')\n",
    "\n",
    "#all_segments = all_segments.dropna()\n",
    "all_segments['direction'] = np.where(all_segments['line'].str.contains(\"d0\"), 0, 1)\n",
    "\n",
    "dtype = {#'i_station' : 'int64',\n",
    "         #'j_station' : 'int64',\n",
    "         'volume' : 'int32',\n",
    "         'board' : 'int32',\n",
    "         'alight' : 'int32',\n",
    "         'totalcapacity': 'float32',\n",
    "         'periodcapacity': 'float32',\n",
    "         'headway': 'float32',\n",
    "         'time_period': 'int16',\n",
    "         'agency': 'int16',\n",
    "         'agency_mode': 'int16',\n",
    "         'scenario' : 'int16',\n",
    "         'crowding' : 'float32',\n",
    "         'stop':'int64',\n",
    "         'direction': 'int16'\n",
    "}\n",
    "#all_segments = all_segments.astype(dtype)\n",
    "#segment_final = pd.concat([segment_final, all_segments], ignore_index=False)\n",
    "#transfer_final = pd.concat([transfer_final, all_trnfrs], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b895f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30399f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# add shapefiles \n",
    "\n",
    "print(f'reading transit segments file')\n",
    "seg_shp = gpd.read_file(_join(transit_data, 'emme_tsegs.shp'))\n",
    "seg_shp = seg_shp[['SEG_ID', 'SEG_NUM', 'geometry']]\n",
    "seg_shp.columns = seg_shp.columns.str.lower()\n",
    "#seg_shp = seg_shp.to_crs(\"4326\")\n",
    "seg_shp.columns = ['seg_id', 'seg_num', 'geometry']\n",
    "\n",
    "#merge with segment geometry\n",
    "seg_final = pd.merge(seg_shp, all_segments, on='seg_id', how='right')\n",
    "seg_final['scenario'] = concept_id\n",
    "\n",
    "map_ids = list(seg_final['stop'].unique())\n",
    "\n",
    "print(f'reading transit nodes file')\n",
    "node_shp = gpd.read_file(_join(transit_data, 'emme_nodes.shp'))\n",
    "node_shp = node_shp[['ID', 'geometry']]\n",
    "node_shp.columns = node_shp.columns.str.lower()\n",
    "#node_shp = node_shp.to_crs(\"4326\")\n",
    "node_shp['scenario'] = concept_id\n",
    "node_shp = node_shp[node_shp['id'].isin(map_ids)]\n",
    "\n",
    "print(\"Writing segment file\")\n",
    "seg_final['seg_ij'] = seg_final['i_station'] + '_' + seg_final['j_station']\n",
    "seg_geo = seg_final[['seg_ij', 'agency', 'time_period', 'scenario', 'geometry']]\n",
    "attrs = ['seg_ij', 'agency', 'time_period', 'scenario']\n",
    "seg_geo_shp = seg_geo.dissolve(by=attrs, as_index=False)\n",
    "seg_geo_shp = seg_geo_shp[['seg_ij', 'scenario', 'geometry']]\n",
    "seg_geo_shp = seg_geo_shp.groupby(['seg_ij', 'scenario']).first().reset_index()\n",
    "\n",
    "print(\"Writing node file\")\n",
    "if adjusted:\n",
    "    seg_geo_shp.to_file(_join(transit_dashboard, \"adjusted\", 'tdb_segments_' + concept_id + '.shp'))\n",
    "    node_shp.to_file(_join(transit_dashboard, \"adjusted\", 'tdb_node_' + concept_id +  '.shp'))\n",
    "else:\n",
    "    seg_geo_shp.to_file(_join(transit_dashboard, 'tdb_segments_' + concept_id + '.shp'))\n",
    "    node_shp.to_file(_join(transit_dashboard, 'tdb_node_' + concept_id +  '.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_geo_tdb = all_segments.copy()\n",
    "seg_geo_tdb['id'] = seg_geo_tdb['i_station'] + '_' + seg_geo_tdb['j_station']\n",
    "\n",
    "seg_tdb = seg_geo_tdb[['i_station', 'j_station', 'agency', 'time_period', 'direction', 'stop',\n",
    "                       'volume', 'periodcapacity', 'scenario', 'board', 'alight', 'transfers']]\n",
    "seg_tdb1 = seg_tdb.drop_duplicates()\n",
    "print(len(seg_tdb), len(seg_tdb1))\n",
    "\n",
    "seg_tdb1 = seg_tdb1.rename(columns={'i_station': 'i_stop', 'j_station': 'j_stop'})\n",
    "seg_tdb1['seg_ij'] = seg_tdb1['i_stop'] + '_' + seg_tdb1['j_stop']\n",
    "\n",
    "#seg_tdb1.to_parquet(_join(transit_dashboard, \"transit_ridership_results_\" + concept_id + \".parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_tdb = seg_tdb1.groupby(['i_stop', 'j_stop', 'seg_ij', \n",
    "                 'agency', 'time_period','scenario'])['volume', 'periodcapacity'].sum().reset_index()\n",
    "\n",
    "seg_tdb['i_stop'] = seg_tdb['i_stop'].astype('int64')\n",
    "seg_tdb['j_stop'] = seg_tdb['j_stop'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527035da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stops dashboard\n",
    "stops = seg_tdb1.groupby(['stop', 'agency', 'time_period', \n",
    "            'scenario'])['alight', 'board', 'transfers'].sum().reset_index()\n",
    "\n",
    "stops['stop'] = stops['stop'].round()\n",
    "stops['stop'] = stops['stop'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c1a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_tdb_results = seg_tdb.merge(stops, left_on=['i_stop', 'agency', 'time_period', 'scenario'], \n",
    "                right_on=['stop', 'agency', 'time_period', 'scenario'], how='left')\n",
    "\n",
    "seg_tdb_results['perc_transfers'] = np.where(seg_tdb_results['board']>0, \n",
    "                                             seg_tdb_results['transfers']/ seg_tdb_results['board'], 0)\n",
    "\n",
    "seg_tdb_results['direction']=1\n",
    "seg_tdb_results['stop'] = seg_tdb_results['stop'].fillna(999999)\n",
    "seg_tdb_results['stop'] = seg_tdb_results['stop'].astype(\"int64\")\n",
    "\n",
    "seg_tdb_results['crowding'] = seg_tdb_results['volume']/seg_tdb_results['periodcapacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c72c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adjusted:\n",
    "    seg_tdb_results.to_parquet(_join(transit_dashboard, \"adjusted\", \"transit_ridership_results_\" + concept_id + \".parquet\"))\n",
    "    stops.to_parquet(_join(transit_dashboard, \"adjusted\", \"transit_ridership_comparison_\" + concept_id + \".parquet\"))\n",
    "else:\n",
    "    seg_tdb_results.to_parquet(_join(transit_dashboard, \"transit_ridership_results_\" + concept_id + \".parquet\"))\n",
    "    stops.to_parquet(_join(transit_dashboard, \"transit_ridership_comparison_\" + concept_id + \".parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_period_map = {1: 'AM', 2: 'MD', 3:'PM', 4:'EV', 5:'EA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarise total boardings and lightings by station ids, agency \n",
    "stops['time_period'] = stops['time_period'].map(time_period_map)\n",
    "seg_tdb['time_period'] = seg_tdb['time_period'].map(time_period_map)\n",
    "\n",
    "trn_stn_br = stops.groupby(['stop', 'time_period'])['board'].sum().reset_index()\n",
    "trn_stn_br = trn_stn_br.loc[trn_stn_br['board']>0]\n",
    "trn_stn_br = trn_stn_br.rename(columns = {'Zone_ID': 'stop'})\n",
    "\n",
    "trn_stn_al = stops.groupby(['stop', 'time_period'])['alight'].sum().reset_index()\n",
    "trn_stn_al = trn_stn_al.loc[trn_stn_al['alight']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stn_br = trn_stn_br.rename(columns={'stop' : 'Zone_ID', \n",
    "                                       'board' : 'Value',\n",
    "                                       'time_period': 'Period'})\n",
    "\n",
    "trn_stn_br['Concept_ID'] = concept_id\n",
    "trn_stn_br['Metric_ID'] = 'A3.2'\n",
    "trn_stn_br['Metric_name'] = 'Transit Ridership'\n",
    "trn_stn_br['Submetric'] = 'A3.2.1'\n",
    "trn_stn_br['Description'] =  'Boardings at only rail stations. Zone ID represents the station nodes'\n",
    "trn_stn_br['Population'] = 'Whole Population'\n",
    "trn_stn_br['Geography'] = 'Regional'\n",
    "trn_stn_br['Origin_zone'] = ''\n",
    "trn_stn_br['Dest_zone'] = ''\n",
    "trn_stn_br['Purpose'] = ''\n",
    "trn_stn_br['Mode'] = ''\n",
    "trn_stn_br['Income'] = ''\n",
    "trn_stn_br['Units'] = 'Boardings'\n",
    "trn_stn_br['Total_Increment'] = ''\n",
    "\n",
    "trn_stn_br = trn_stn_br[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34776a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stn_al = trn_stn_al.rename(columns={'stop' : 'Zone_ID', \n",
    "                                       'alight' : 'Value',\n",
    "                                       'time_period': 'Period'})\n",
    "trn_stn_al['Concept_ID'] = concept_id\n",
    "trn_stn_al['Metric_ID'] = 'A3.2'\n",
    "trn_stn_al['Metric_name'] = 'Transit Ridership'\n",
    "trn_stn_al['Submetric'] = 'A3.2.2'\n",
    "trn_stn_al['Description'] =  'Alightings at only rail stations. Zone ID represents the station nodes'\n",
    "trn_stn_al['Population'] = 'Whole Population'\n",
    "trn_stn_al['Geography'] = 'Regional'\n",
    "trn_stn_al['Origin_zone'] = ''\n",
    "trn_stn_al['Dest_zone'] = ''\n",
    "trn_stn_al['Purpose'] = ''\n",
    "trn_stn_al['Mode'] = ''\n",
    "trn_stn_al['Income'] = ''\n",
    "trn_stn_al['Units'] = 'Alightings'\n",
    "trn_stn_al['Total_Increment'] = ''\n",
    "\n",
    "trn_stn_al = trn_stn_al[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seg = seg_tdb.groupby(['i_stop', 'j_stop', 'time_period'])['volume'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8063c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seg = trn_seg.loc[trn_seg['volume']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seg = trn_seg.rename(columns={'i_stop' : 'Origin_zone', \n",
    "                                     'j_stop' : 'Dest_zone',\n",
    "                                     'volume' : 'Value',\n",
    "                                     'time_period': 'Period'})\n",
    "trn_seg['Concept_ID'] = concept_id\n",
    "trn_seg['Metric_ID'] = 'A3.2'\n",
    "trn_seg['Metric_name'] = 'Transit Ridership'\n",
    "trn_seg['Submetric'] = 'A3.2.3'\n",
    "trn_seg['Description'] =  'Flows between origin and destination stations'\n",
    "trn_seg['Population'] = 'Whole Population'\n",
    "trn_seg['Geography'] = 'Regional'\n",
    "trn_seg['Purpose'] = ''\n",
    "trn_seg['Units'] = ''\n",
    "trn_seg['Mode'] = ''\n",
    "trn_seg['Income'] = ''\n",
    "trn_seg['Zone_ID'] = ''\n",
    "trn_seg['Total_Increment'] = ''\n",
    "trn_seg = trn_seg[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stn_br.to_csv(_join(summary_outputs, 'A3.2.1' + '_weekday_transit_boardings_' + \n",
    "                        concept_id + '_region' + filename_extension + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stn_al.to_csv(_join(summary_outputs, 'A3.2.2' + '_weekday_transit_alightings_' + \n",
    "                        concept_id + '_region' + filename_extension + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seg.to_csv(_join(summary_outputs, 'A3.2.3' + '_weekday_transit_segment_volumes_' + \n",
    "                     concept_id + '_region' + filename_extension + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e207336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stn_br_annual = trn_stn_br.copy()\n",
    "trn_stn_br_annual['Value'] = trn_stn_br_annual['Value'] * params['annual_transit_factor']\n",
    "trn_stn_br_annual['Submetric'] = 'A3.2.4'\n",
    "\n",
    "trn_stn_al_annual = trn_stn_al.copy()\n",
    "trn_stn_al_annual['Value'] = trn_stn_al_annual['Value'] * params['annual_transit_factor']\n",
    "trn_stn_al_annual['Submetric'] = 'A3.2.5'\n",
    "\n",
    "trn_seg_annual = trn_stn_br.copy()\n",
    "trn_seg_annual['Value'] = trn_seg_annual['Value'] * params['annual_transit_factor']\n",
    "trn_seg_annual['Submetric'] = 'A3.2.6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stn_br_annual.to_csv(_join(summary_outputs, 'A3.2.4' + '_annual_transit_boardings_' + \n",
    "                        concept_id + '_region' + filename_extension + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_stn_al_annual.to_csv(_join(summary_outputs, 'A3.2.5' + '_annual_transit_alightings_' + \n",
    "                        concept_id + '_region' + filename_extension + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472937be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seg_annual.to_csv(_join(summary_outputs, 'A3.2.6' + '_annual_transit_segment_volumes_' + \n",
    "                     concept_id + '_region' + filename_extension + '.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
