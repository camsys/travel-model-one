{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371adeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmatrix as omx\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "from utility import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67170c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e3a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "summary_outputs = params['summary_dir']\n",
    "concept_id = params['concept_id']\n",
    "ctramp_dir = params['ctramp_dir']\n",
    "iteration = params['iteration']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "time_period_mapping = params['time_periods_mapping']\n",
    "link21_purp_mapping = params['purpose_mapping']\n",
    "mode_cat_mapping = params['mode_mapping']\n",
    "time_periods = params['periods']\n",
    "acc_egg_modes = params['access_egress_modes']\n",
    "\n",
    "preprocess_dir = _join(ctramp_dir, '_pre_process_files')\n",
    "perf_measure_columns = params['final_columns']\n",
    "summary_dir = params['summary_dir']\n",
    "\n",
    "demand_matrices_dir = _join(model_outputs_dir, \"demand_matrices\")\n",
    "transit_demand_dir = _join(demand_matrices_dir, \"transit\")\n",
    "transit_skims_dir = _join(skims_dir, \"transit\")\n",
    "best_path_skim_dir = params['best_path_skim_dir']\n",
    "\n",
    "annual_transit_factor = params['annual_transit_factor']\n",
    "annual_auto_factor = params['annual_auto_factor']\n",
    "\n",
    "filename_extension = params['filename_extension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beca882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trips = pd.read_parquet(_join(preprocess_dir, 'trip_roster.parquet'))\n",
    "# df_trips = pd.read_parquet(_join(preprocess_dir, 'trip_roster_baseline_for_A1.10_crowding.parquet'))\n",
    "df_base_cwd_skim = pd.read_parquet(_join(preprocess_dir, 'A1.10_baseline_connected_cwd_skim.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c56401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\MTC_tmpy\\\\TM2_2050Baseline_R2_Run4\\\\tm2py\\\\examples\\\\Link21_3332\\\\skims\\\\transit'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transit_skims_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20d6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = df_trips.loc[df_trips['trip_mode'].isin([6,7,8])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70edec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period:  am\n",
      "Access Egress Mode:  WLK_TRN_WLK\n",
      "Access Egress Mode:  KNR_TRN_WLK\n",
      "Access Egress Mode:  PNR_TRN_WLK\n",
      "Access Egress Mode:  WLK_TRN_PNR\n",
      "Access Egress Mode:  WLK_TRN_KNR\n",
      "Period:  md\n",
      "Access Egress Mode:  WLK_TRN_WLK\n",
      "Access Egress Mode:  KNR_TRN_WLK\n",
      "Access Egress Mode:  PNR_TRN_WLK\n",
      "Access Egress Mode:  WLK_TRN_PNR\n",
      "Access Egress Mode:  WLK_TRN_KNR\n",
      "Period:  pm\n",
      "Access Egress Mode:  WLK_TRN_WLK\n",
      "Access Egress Mode:  KNR_TRN_WLK\n",
      "Access Egress Mode:  PNR_TRN_WLK\n",
      "Access Egress Mode:  WLK_TRN_PNR\n",
      "Access Egress Mode:  WLK_TRN_KNR\n",
      "Period:  ev\n",
      "Access Egress Mode:  WLK_TRN_WLK\n",
      "Access Egress Mode:  KNR_TRN_WLK\n",
      "Access Egress Mode:  PNR_TRN_WLK\n",
      "Access Egress Mode:  WLK_TRN_PNR\n",
      "Access Egress Mode:  WLK_TRN_KNR\n",
      "Period:  ea\n",
      "Access Egress Mode:  WLK_TRN_WLK\n",
      "Access Egress Mode:  KNR_TRN_WLK\n",
      "Access Egress Mode:  PNR_TRN_WLK\n",
      "Access Egress Mode:  WLK_TRN_PNR\n",
      "Access Egress Mode:  WLK_TRN_KNR\n"
     ]
    }
   ],
   "source": [
    "create_rail_crowding_od_pairs(preprocess_dir, transit_skims_dir, time_periods, acc_egg_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c343b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing - AM\n",
      "Walk, transit, walk.\n",
      "Park-n-ride, transit, walk.\n",
      "Walk, transit, Park-n-ride.\n",
      "Kiss-n-ride, transit, walk.\n",
      "Walk, transit, Kiss-n-ride.\n",
      "Concatinating crowding skims for the connected ODs of the period.\n",
      "Concatinating the three rail trip dataframes of the period.\n",
      "Processing - MD\n",
      "Walk, transit, walk.\n",
      "Park-n-ride, transit, walk.\n",
      "Walk, transit, Park-n-ride.\n",
      "Kiss-n-ride, transit, walk.\n",
      "Walk, transit, Kiss-n-ride.\n",
      "Concatinating crowding skims for the connected ODs of the period.\n",
      "Concatinating the three rail trip dataframes of the period.\n",
      "Processing - PM\n",
      "Walk, transit, walk.\n",
      "Park-n-ride, transit, walk.\n",
      "Walk, transit, Park-n-ride.\n",
      "Kiss-n-ride, transit, walk.\n",
      "Walk, transit, Kiss-n-ride.\n",
      "Concatinating crowding skims for the connected ODs of the period.\n",
      "Concatinating the three rail trip dataframes of the period.\n",
      "Processing - EV\n",
      "Walk, transit, walk.\n",
      "Park-n-ride, transit, walk.\n",
      "Walk, transit, Park-n-ride.\n",
      "Kiss-n-ride, transit, walk.\n",
      "Walk, transit, Kiss-n-ride.\n",
      "Concatinating crowding skims for the connected ODs of the period.\n",
      "Concatinating the three rail trip dataframes of the period.\n",
      "Processing - EA\n",
      "Walk, transit, walk.\n",
      "Park-n-ride, transit, walk.\n",
      "Walk, transit, Park-n-ride.\n",
      "Kiss-n-ride, transit, walk.\n",
      "Walk, transit, Kiss-n-ride.\n",
      "Concatinating crowding skims for the connected ODs of the period.\n",
      "Concatinating the three rail trip dataframes of the period.\n"
     ]
    }
   ],
   "source": [
    "df_connected_cwd_skim = []\n",
    "df_rail_trips = []\n",
    "\n",
    "for period in time_periods:\n",
    "    print(f'Processing - {period.upper()}')\n",
    "    \n",
    "    # Read in which ODs have either nonzero IVTHVY or IVTCOM. The matrix below contains 0s and 1s.\n",
    "    df_od_pr = omx.open_file(_join(preprocess_dir, \"rail_od_v9_trim_\" + period.upper() + \".omx\"))\n",
    "    \n",
    "    # Read in crowding times between ODs (already multiplied by 1.62). Disconnected ODs have a 0 value.\n",
    "    df_od_cwd = omx.open_file(_join(preprocess_dir, \"rail_crowding_od_v9_trim_\" + period.upper() + \".omx\"))\n",
    "    df_od_cwd_base = df_base_cwd_skim.loc[df_base_cwd_skim['period']==period]\n",
    "    \n",
    "    # Read in transit trips of this period.\n",
    "    df_trn_pd = df_trn[df_trn['Period'] == period]\n",
    "    \n",
    "    # Walk, transit, walk.\n",
    "    print('Walk, transit, walk.')\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_WLK')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]    \n",
    "    # df_connected_wlk = df_rail_od.copy()\n",
    "    \n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_WLK', cols =['orig', 'dest', 'crowd'])    \n",
    "    df_rail_cwd = df_rail_cwd.merge(df_rail_od, on=['orig', 'dest'], how ='inner')    \n",
    "    df_rail_cwd['period'] = period\n",
    "    df_rail_cwd['mode'] = 'WLK_TRN_WLK'\n",
    "    df_connected_cwd_skim_wlk = df_rail_cwd.copy()    \n",
    "    df_baseline_skim = df_od_cwd_base.loc[(df_od_cwd_base['mode']=='WLK_TRN_WLK')]    \n",
    "    df_rail_cwd = df_rail_cwd.merge(df_baseline_skim, on=['orig', 'dest'], how='inner')\n",
    "    \n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'WALK_TRANSIT']\n",
    "    df_trn_wlk = df_trn_acc.merge(df_rail_cwd,\n",
    "                          left_on =['orig_taz', 'dest_taz'], \n",
    "                          right_on=['orig', 'dest'], \n",
    "                          how ='inner')    \n",
    "    # print(df_trn_wlk.columns)\n",
    "    \n",
    "    \n",
    "    # PNR Transit\n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'PNR_TRANSIT']\n",
    "    \n",
    "    print('Park-n-ride, transit, walk.')\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'PNR_TRN_WLK')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]    \n",
    "    # df_connected_pnr_inbnd = df_rail_od.copy()\n",
    "    \n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'PNR_TRN_WLK', cols =['orig', 'dest', 'crowd'])\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_rail_od, on=['orig', 'dest'], how ='inner')\n",
    "    df_rail_cwd['period'] = period\n",
    "    df_rail_cwd['mode'] = 'PNR_TRN_WLK'\n",
    "    df_connected_cwd_skim_pnr_inbnd = df_rail_cwd.copy()\n",
    "    df_baseline_skim = df_od_cwd_base.loc[(df_od_cwd_base['mode']=='PNR_TRN_WLK')]\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_baseline_skim, on=['orig', 'dest'], how='inner')\n",
    "    \n",
    "    df_trn_acc_inbnd = df_trn_acc[df_trn_acc['inbound'] == 1]  # Going to work\n",
    "    df_trn_pnr_inbnd = df_trn_acc_inbnd.merge(df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')    \n",
    "    \n",
    "    print('Walk, transit, Park-n-ride.')\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_PNR')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    # df_connected_pnr_outbnd = df_rail_od.copy()\n",
    "    \n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_PNR', cols =['orig', 'dest', 'crowd'])\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_rail_od, on=['orig', 'dest'], how ='inner')\n",
    "    df_rail_cwd['period'] = period\n",
    "    df_rail_cwd['mode'] = 'WLK_TRN_PNR'\n",
    "    df_connected_cwd_skim_pnr_outbnd = df_rail_cwd.copy()\n",
    "    df_baseline_skim = df_od_cwd_base.loc[(df_od_cwd_base['mode']=='WLK_TRN_PNR')]\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_baseline_skim, on=['orig', 'dest'], how='inner')\n",
    "    \n",
    "    df_trn_acc_outbnd = df_trn_acc[df_trn_acc['inbound'] != 1]  # Returning home\n",
    "    df_trn_pnr_outbnd = df_trn_acc_outbnd.merge(df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    df_connected_cwd_skim_pnr = pd.concat([df_connected_cwd_skim_pnr_inbnd, df_connected_cwd_skim_pnr_outbnd],\n",
    "                                          ignore_index=True)\n",
    "    df_trn_pnr = pd.concat([df_trn_pnr_inbnd, df_trn_pnr_outbnd], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # KNR Transit\n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'KNR_TRANSIT']\n",
    "    \n",
    "    print('Kiss-n-ride, transit, walk.')\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'KNR_TRN_WLK')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    # df_connected_knr_inbnd = df_rail_od.copy()\n",
    "    \n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'KNR_TRN_WLK', cols =['orig', 'dest', 'crowd'])\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_rail_od, on=['orig', 'dest'], how ='inner')   \n",
    "    df_rail_cwd['period'] = period\n",
    "    df_rail_cwd['mode'] = 'KNR_TRN_WLK'\n",
    "    df_connected_cwd_skim_knr_inbnd = df_rail_cwd.copy()\n",
    "    df_baseline_skim = df_od_cwd_base.loc[(df_od_cwd_base['mode']=='KNR_TRN_WLK')]\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_baseline_skim, on=['orig', 'dest'], how='inner')\n",
    "    \n",
    "    df_trn_acc_inbnd = df_trn_acc[df_trn_acc['inbound'] == 1]  # Going to work\n",
    "    df_trn_knr_inbnd = df_trn_acc_inbnd.merge(df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')    \n",
    "    \n",
    "    print('Walk, transit, Kiss-n-ride.')\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_KNR')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]    \n",
    "    # df_connected_knr_outbnd = df_rail_od.copy()\n",
    "    \n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_KNR', cols =['orig', 'dest', 'crowd'])\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_rail_od, on=['orig', 'dest'], how ='inner')\n",
    "    df_rail_cwd['period'] = period\n",
    "    df_rail_cwd['mode'] = 'WLK_TRN_KNR'\n",
    "    df_connected_cwd_skim_knr_outbnd = df_rail_cwd.copy()\n",
    "    df_baseline_skim = df_od_cwd_base.loc[(df_od_cwd_base['mode']=='WLK_TRN_KNR')]\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_baseline_skim, on=['orig', 'dest'], how='inner')\n",
    "    \n",
    "    df_trn_acc_outbnd = df_trn_acc[df_trn_acc['inbound'] != 1]  # Returning home\n",
    "    df_trn_knr_outbnd = df_trn_acc_outbnd.merge(df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    df_connected_cwd_skim_knr = pd.concat([df_connected_cwd_skim_knr_inbnd, df_connected_cwd_skim_knr_outbnd],\n",
    "                                          ignore_index=True)\n",
    "    df_trn_knr = pd.concat([df_trn_knr_inbnd, df_trn_knr_outbnd], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Now, concatinate the three connected-by-rail skim dataframes.\n",
    "    print('Concatinating crowding skims for the connected ODs of the period.')\n",
    "    df_period_connected_cwd_skim = pd.concat([df_connected_cwd_skim_wlk,\n",
    "                                              df_connected_cwd_skim_pnr,\n",
    "                                              df_connected_cwd_skim_knr],\n",
    "                                             ignore_index=True)\n",
    "    df_period_connected_cwd_skim.drop(columns=['rail_od'], inplace=True)\n",
    "    df_connected_cwd_skim.append(df_period_connected_cwd_skim)    \n",
    "    \n",
    "    # Now, concatinate the three rail trip dataframes.\n",
    "    print('Concatinating the three rail trip dataframes of the period.')\n",
    "    df_period_trips = pd.concat([df_trn_wlk, df_trn_pnr, df_trn_knr], ignore_index=True)\n",
    "    df_rail_trips.append(df_period_trips)\n",
    "\n",
    "df_connected_cwd_skim = pd.concat(df_connected_cwd_skim)\n",
    "df_trn_rail = pd.concat(df_rail_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ab8f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>dest</th>\n",
       "      <th>crowd</th>\n",
       "      <th>period</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>130.655365</td>\n",
       "      <td>am</td>\n",
       "      <td>WLK_TRN_WLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>130.655365</td>\n",
       "      <td>am</td>\n",
       "      <td>WLK_TRN_WLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>130.655365</td>\n",
       "      <td>am</td>\n",
       "      <td>WLK_TRN_WLK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   orig dest       crowd period         mode\n",
       "0   267    1  130.655365     am  WLK_TRN_WLK\n",
       "1   268    1  130.655365     am  WLK_TRN_WLK\n",
       "2   269    1  130.655365     am  WLK_TRN_WLK"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_connected_cwd_skim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c6e3f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total connected ODs, averaged over all periods and modes: 8,291,456\n"
     ]
    }
   ],
   "source": [
    "x = int(round(len(df_connected_cwd_skim) / (5 * 5), 0))\n",
    "# Note: Five TODs and five modes\n",
    "print(f'Total connected ODs, averaged over all periods and modes: {x:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34cad08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average crowding time, including all ODs, periods, and modes, and not weighted by any trip: 4.074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2.072864e+08\n",
       "mean     4.074413e+02\n",
       "std      7.011472e+02\n",
       "min      0.000000e+00\n",
       "25%      1.607397e+01\n",
       "50%      8.575587e+01\n",
       "75%      5.151603e+02\n",
       "max      9.038510e+03\n",
       "Name: crowd, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_connected_cwd_skim = df_connected_cwd_skim.merge(df_od_cwd_base, on=['orig', 'dest', 'period', 'mode'], how='inner')\n",
    "print(f\"{int(round(len(df_connected_cwd_skim) / (5 * 5), 0)):,}\")\n",
    "\n",
    "# Note: There are ODs connected by rail with zero crowding time because there aren't many passengers between those ODs.\n",
    "x = df_connected_cwd_skim.crowd.describe()\n",
    "print(f\"Average crowding time, including all ODs, periods, and modes, and not weighted by any trip: {x['mean']/100:.3f}\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6dc55f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hh_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>orig_purpose</th>\n",
       "      <th>dest_purpose</th>\n",
       "      <th>orig_taz</th>\n",
       "      <th>dest_taz</th>\n",
       "      <th>depart_hour</th>\n",
       "      <th>trip_mode</th>\n",
       "      <th>sampleRate</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>trips</th>\n",
       "      <th>transbay_od</th>\n",
       "      <th>orig_rdm_zones</th>\n",
       "      <th>orig_super_dist</th>\n",
       "      <th>orig_county</th>\n",
       "      <th>dest_rdm_zones</th>\n",
       "      <th>dest_super_dist</th>\n",
       "      <th>dest_county</th>\n",
       "      <th>home_zone</th>\n",
       "      <th>income</th>\n",
       "      <th>Income</th>\n",
       "      <th>pp_share</th>\n",
       "      <th>link21_trip_purp</th>\n",
       "      <th>Period</th>\n",
       "      <th>Mode</th>\n",
       "      <th>orig</th>\n",
       "      <th>dest</th>\n",
       "      <th>crowd</th>\n",
       "      <th>rail_od</th>\n",
       "      <th>period</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1789254</td>\n",
       "      <td>4338265.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Work</td>\n",
       "      <td>atwork</td>\n",
       "      <td>2216</td>\n",
       "      <td>2291</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alameda_22</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>Alameda_03</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>256047</td>\n",
       "      <td>100k+</td>\n",
       "      <td>100.0</td>\n",
       "      <td>work</td>\n",
       "      <td>am</td>\n",
       "      <td>WALK_TRANSIT</td>\n",
       "      <td>2216</td>\n",
       "      <td>2291</td>\n",
       "      <td>114.13353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>am</td>\n",
       "      <td>WLK_TRN_WLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592815</td>\n",
       "      <td>1342412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>escort</td>\n",
       "      <td>work</td>\n",
       "      <td>2216</td>\n",
       "      <td>2291</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alameda_22</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>Alameda_03</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1869</td>\n",
       "      <td>121941</td>\n",
       "      <td>100k+</td>\n",
       "      <td>100.0</td>\n",
       "      <td>work</td>\n",
       "      <td>am</td>\n",
       "      <td>WALK_TRANSIT</td>\n",
       "      <td>2216</td>\n",
       "      <td>2291</td>\n",
       "      <td>114.13353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>am</td>\n",
       "      <td>WLK_TRN_WLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>334043</td>\n",
       "      <td>646224.0</td>\n",
       "      <td>0</td>\n",
       "      <td>work</td>\n",
       "      <td>work</td>\n",
       "      <td>2216</td>\n",
       "      <td>2291</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alameda_22</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>Alameda_03</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1992</td>\n",
       "      <td>33405</td>\n",
       "      <td>30k_to_60k</td>\n",
       "      <td>100.0</td>\n",
       "      <td>work</td>\n",
       "      <td>am</td>\n",
       "      <td>WALK_TRANSIT</td>\n",
       "      <td>2216</td>\n",
       "      <td>2291</td>\n",
       "      <td>114.13353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>am</td>\n",
       "      <td>WLK_TRN_WLK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hh_id  person_id  inbound orig_purpose dest_purpose  orig_taz dest_taz  \\\n",
       "0  1789254  4338265.0        0         Work       atwork      2216     2291   \n",
       "1   592815  1342412.0        0       escort         work      2216     2291   \n",
       "2   334043   646224.0        0         work         work      2216     2291   \n",
       "\n",
       "   depart_hour  trip_mode  sampleRate trip_type  trips  transbay_od  \\\n",
       "0            7          6         1.0       INM    1.0          0.0   \n",
       "1            6          6         1.0       INM    1.0          0.0   \n",
       "2            8          6         1.0       INM    1.0          0.0   \n",
       "\n",
       "  orig_rdm_zones  orig_super_dist  orig_county dest_rdm_zones  \\\n",
       "0     Alameda_22               18            4     Alameda_03   \n",
       "1     Alameda_22               18            4     Alameda_03   \n",
       "2     Alameda_22               18            4     Alameda_03   \n",
       "\n",
       "   dest_super_dist  dest_county  home_zone  income      Income  pp_share  \\\n",
       "0               19            4          9  256047       100k+     100.0   \n",
       "1               19            4       1869  121941       100k+     100.0   \n",
       "2               19            4       1992   33405  30k_to_60k     100.0   \n",
       "\n",
       "  link21_trip_purp Period          Mode  orig  dest      crowd  rail_od  \\\n",
       "0             work     am  WALK_TRANSIT  2216  2291  114.13353      1.0   \n",
       "1             work     am  WALK_TRANSIT  2216  2291  114.13353      1.0   \n",
       "2             work     am  WALK_TRANSIT  2216  2291  114.13353      1.0   \n",
       "\n",
       "  period         mode  \n",
       "0     am  WLK_TRN_WLK  \n",
       "1     am  WLK_TRN_WLK  \n",
       "2     am  WLK_TRN_WLK  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn_rail.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37ea4784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of transit trips: 1,226,291.0\n"
     ]
    }
   ],
   "source": [
    "# To get total transit trips of a concept scenario, use the baseline script! Do not use this cell.\n",
    "# x = df_trn_rail.trips.sum()\n",
    "# print(f'Total number of transit trips: {x:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a2e6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn_rail['crowd_trips'] = df_trn_rail['trips'] * df_trn_rail['crowd'] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53822a61",
   "metadata": {},
   "source": [
    "df_trn_rail['pp_trips'] = df_trn_rail['trips'] * df_trn_rail['pp_share'] / 100\n",
    "df_trn_rail['crowd_pp_trips'] = df_trn_rail['pp_trips'] * df_trn_rail['crowd'] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da704e42",
   "metadata": {},
   "source": [
    "df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "                                      summary_column='crowd_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value':'crowd_trips'})\n",
    "\n",
    "\n",
    "#df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "#                                      summary_column='trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value':'trips'})\n",
    "\n",
    "\n",
    "#region_value = pd.merge(df_temp1, df_temp2, on = ['Period', 'Income'], how='left')\n",
    "#region_value['Value'] = region_value['crowd_trips'] / region_value['trips']\n",
    "\n",
    "region_value = df_temp1 \n",
    "region_value = region_value[['Period', 'Income', 'Value']]\n",
    "\n",
    "#regional value\n",
    "#region_value = df_trn_rail.groupby(['Period'])['trips'].mean().reset_index()\n",
    "#region_value = region_value.rename(columns={'trips': 'Value'})\n",
    "region_value['Concept_ID'] = concept_id\n",
    "region_value['Metric_ID'] = 'A1.10'\n",
    "region_value['Metric_name'] = 'Crowding (Region)'\n",
    "region_value['Submetric'] = 'A1.10.1'\n",
    "region_value['Description'] = 'Regional crowding'\n",
    "region_value['Population'] = 'Whole Population'\n",
    "region_value['Geography'] = 'Regional'\n",
    "region_value['Origin_zone'] = ''\n",
    "region_value['Dest_zone'] = ''\n",
    "region_value['Purpose'] = ''\n",
    "region_value['Mode'] = ''\n",
    "#region_value['Income'] = ''\n",
    "region_value['Zone_ID'] = ''\n",
    "region_value['Units'] = 'minutes'\n",
    "region_value['Total_Increment'] = ''\n",
    "region_value = region_value[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b2ba1",
   "metadata": {},
   "source": [
    "# summarise for prioirty population\n",
    "#regional value\n",
    "\n",
    "df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "                                      summary_column='crowd_pp_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value':'crowd_pp_trips'}) # BC team is interested in total value instead of mean\n",
    "\n",
    "\n",
    "#df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "#                                      summary_column='pp_trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value':'pp_trips'})\n",
    "\n",
    "\n",
    "#pp_region_value = pd.merge(df_temp1, df_temp2, on = ['Period', 'Income'], how='left')\n",
    "#pp_region_value['Value'] = pp_region_value['crowd_pp_trips'] / pp_region_value['pp_trips']\n",
    "pp_region_value = df_temp1\n",
    "pp_region_value = pp_region_value[['Period', 'Income', 'Value']]\n",
    "\n",
    "#region_value = df_trn_rail.groupby(['Period'])['pp_trips'].mean().reset_index()\n",
    "#region_value = region_value.rename(columns={'pp_trips': 'Value'})\n",
    "pp_region_value['Concept_ID'] = concept_id\n",
    "pp_region_value['Metric_ID'] = 'A1.10'\n",
    "pp_region_value['Metric_name'] = 'Crowding (Region)'\n",
    "pp_region_value['Submetric'] = 'A1.10.2'\n",
    "pp_region_value['Description'] = 'Rgional crowding'\n",
    "pp_region_value['Population'] = 'Prioirty Population'\n",
    "pp_region_value['Geography'] = 'Regional'\n",
    "pp_region_value['Origin_zone'] = ''\n",
    "pp_region_value['Dest_zone'] = ''\n",
    "pp_region_value['Purpose'] = ''\n",
    "pp_region_value['Mode'] = ''\n",
    "#pp_region_value['Income'] = ''\n",
    "pp_region_value['Zone_ID'] = ''\n",
    "pp_region_value['Units'] = 'minutes'\n",
    "pp_region_value['Total_Increment'] = ''\n",
    "pp_region_value = pp_region_value[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e068a",
   "metadata": {},
   "source": [
    "#df_rdm = df_tours.groupby(['orig_rdm_zones', 'dest_rdm_zones', 'Mode', 'Period', 'tour_purpose'])['tours'].sum().reset_index()\n",
    "\n",
    "df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                      summary_column='crowd_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value': 'trips'})\n",
    "\n",
    "#df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "#                                      summary_column='crowd_trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value': 'crowd_trips'})\n",
    "\n",
    "\n",
    "#df_rdm = df_temp1.merge(df_temp2, on = ['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], how = 'left')\n",
    "#df_rdm['Value'] = df_rdm['crowd_trips'] /  df_rdm['trips']\n",
    "\n",
    "df_rdm = df_temp1\n",
    "\n",
    "df_rdm = df_rdm.rename(columns={ \n",
    "                                'orig_rdm_zones' : 'Origin_zone',\n",
    "                                'dest_rdm_zones' : 'Dest_zone'})\n",
    "df_rdm = df_rdm[['Origin_zone', 'Dest_zone', 'Period', 'Income', 'Value']]\n",
    "\n",
    "df_rdm['Concept_ID'] = concept_id\n",
    "df_rdm['Metric_ID'] = 'A1.10'\n",
    "df_rdm['Metric_name'] = 'Crowding (Region)'\n",
    "df_rdm['Submetric'] = 'A1.10.3'\n",
    "df_rdm['Description'] = 'Crowding between RDM zones'\n",
    "df_rdm['Population'] = 'Whole Population'\n",
    "df_rdm['Geography'] = 'RDM'\n",
    "df_rdm['Zone_ID'] = ''\n",
    "df_rdm['Purpose'] = ''\n",
    "df_rdm['Mode'] = ''\n",
    "#df_rdm['Income'] = ''\n",
    "df_rdm['Units'] = 'minutes'\n",
    "df_rdm['Total_Increment'] = ''\n",
    "df_rdm = df_rdm[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9daa4",
   "metadata": {},
   "source": [
    "#df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "#                                      summary_column='pp_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value': 'pp_trips'})\n",
    "\n",
    "df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                      summary_column='crowd_pp_trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value': 'crowd_pp_trips'})\n",
    "\n",
    "\n",
    "#df_rdm_pp = df_temp1.merge(df_temp2, on = ['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], how = 'left')\n",
    "\n",
    "df_rdm_pp = df_temp2\n",
    "#df_rdm_pp = df_rdm_pp.loc[df_rdm_pp['pp_trips']>0]\n",
    "\n",
    "#df_rdm_pp['Value'] = df_rdm_pp['crowd_pp_trips'] /  df_rdm_pp['pp_trips']\n",
    "\n",
    "\n",
    "df_rdm_pp = df_rdm_pp.rename(columns={ \n",
    "                                'orig_rdm_zones' : 'Origin_zone',\n",
    "                                'dest_rdm_zones' : 'Dest_zone'})\n",
    "df_rdm_pp = df_rdm_pp[['Origin_zone', 'Dest_zone', 'Period', 'Income' ,'Value']]\n",
    "\n",
    "df_rdm_pp['Concept_ID'] = concept_id\n",
    "df_rdm_pp['Metric_ID'] = 'A1.10'\n",
    "df_rdm_pp['Metric_name'] = 'Crowding (Region)'\n",
    "df_rdm_pp['Submetric'] = 'A1.10.4'\n",
    "df_rdm_pp['Description'] = 'Crowding between RDM zones'\n",
    "df_rdm_pp['Population'] = 'Prioirty Population'\n",
    "df_rdm_pp['Geography'] = 'RDM'\n",
    "df_rdm_pp['Zone_ID'] = ''\n",
    "df_rdm_pp['Purpose'] = ''\n",
    "df_rdm_pp['Mode'] = ''\n",
    "#df_rdm_pp['Income'] = ''\n",
    "df_rdm_pp['Units'] = 'minutes'\n",
    "df_rdm_pp['Total_Increment'] = ''\n",
    "df_rdm_pp = df_rdm_pp[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03c3bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period'], \n",
    "                                      summary_column='crowd_trips')\n",
    "df_temp1 = df_temp1.rename(columns={'Value':'crowd_trips'})\n",
    "\n",
    "\n",
    "df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period'], \n",
    "                                     summary_column='trips')\n",
    "df_temp2 = df_temp2.rename(columns={'Value':'trips'})\n",
    "\n",
    "\n",
    "region_value2 = pd.merge(df_temp1, df_temp2, on = ['Period'], how='left')\n",
    "region_value2['Value'] = region_value2['crowd_trips'] / region_value2['trips']\n",
    "\n",
    "region_value2 = region_value2[['Period', 'Value']]\n",
    "\n",
    "#regional value\n",
    "#region_value = df_trn_rail.groupby(['Period'])['trips'].mean().reset_index()\n",
    "#region_value = region_value.rename(columns={'trips': 'Value'})\n",
    "region_value2['Concept_ID'] = concept_id\n",
    "region_value2['Metric_ID'] = 'A1.10'\n",
    "region_value2['Metric_name'] = 'Crowding (Region)'\n",
    "region_value2['Submetric'] = 'A1.10.5'\n",
    "region_value2['Description'] = 'Regional crowding'\n",
    "region_value2['Population'] = 'Whole Population'\n",
    "region_value2['Geography'] = 'Regional'\n",
    "region_value2['Origin_zone'] = ''\n",
    "region_value2['Dest_zone'] = ''\n",
    "region_value2['Purpose'] = ''\n",
    "region_value2['Mode'] = ''\n",
    "region_value2['Income'] = ''\n",
    "region_value2['Zone_ID'] = ''\n",
    "region_value2['Units'] = 'minutes'\n",
    "region_value2['Total_Increment'] = ''\n",
    "region_value2 = region_value2[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82f2b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 A1.10.5 Crowding (Region)\n"
     ]
    }
   ],
   "source": [
    "# all_dfs = [region_value, pp_region_value, df_rdm, df_rdm_pp, region_value2]\n",
    "all_dfs = [region_value2]\n",
    "\n",
    "for dfs in all_dfs:\n",
    "    metric_name = '_regional_crowding_'\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    dfs = dfs[perf_measure_columns]\n",
    "    file_name = dfs['Submetric'][0]\n",
    "    geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "    dfs.to_csv(_join(summary_dir, file_name + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Metric_name'][0])\n",
    "    \n",
    "# combined_df = pd.concat([region_value, pp_region_value, df_rdm, df_rdm_pp]).reset_index(drop=True)\n",
    "combined_df = region_value2.reset_index(drop=True)\n",
    "combined_df.to_csv(_join(summary_dir, 'A10.1' + '_regional_crowding_' + concept_id + '_region' +filename_extension+'.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f840ba",
   "metadata": {},
   "source": [
    "#county \n",
    "county_df_temp = df_trn_rail.groupby(['orig_county', 'dest_county', 'Period'])['trips'].mean().reset_index()\n",
    "county_df_temp = county_df_temp.rename(columns={'trips': 'Value',\n",
    "                                               'orig_county': 'Origin_zone',\n",
    "                                               'dest_county': 'Dest_zone'})\n",
    "county_df_temp['Concept_ID'] = concept_id\n",
    "county_df_temp['Metric_ID'] = 'A1.9'\n",
    "county_df_temp['Metric_name'] = 'Crowding (Region)'\n",
    "county_df_temp['Submetric'] = 'A1.9.2'\n",
    "county_df_temp['Description'] = 'Crowding level between origin and destination county'\n",
    "county_df_temp['Population'] = 'Whole Population'\n",
    "county_df_temp['Geography'] = 'County'\n",
    "county_df_temp['Zone_ID'] = ''\n",
    "#df_cnty['Origin_zone'] = ''\n",
    "#df_cnty['Dest_zone'] = ''\n",
    "county_df_temp['Units'] = 'minutes'\n",
    "county_df_temp['Total_Increment'] = ''\n",
    "\n",
    "\n",
    "#super district\n",
    "sd_df_temp = df_trn_rail.groupby(['orig_super_dist', 'dest_super_dist', 'Period'])['trips'].mean().reset_index()\n",
    "sd_df_temp = sd_df_temp.rename(columns={'trips': 'Value',\n",
    "                                        'orig_super_dist': 'Origin_zone',\n",
    "                                        'dest_super_dist': 'Dest_zone'})\n",
    "sd_df_temp['Concept_ID'] = concept_id\n",
    "sd_df_temp['Metric_ID'] = 'A1.9'\n",
    "sd_df_temp['Metric_name'] = 'Crowding (Region)'\n",
    "sd_df_temp['Submetric'] = 'A1.9.3'\n",
    "sd_df_temp['Description'] = 'Regional crowding level'\n",
    "sd_df_temp['Population'] = 'Whole Population'\n",
    "sd_df_temp['Geography'] = 'Super district'\n",
    "sd_df_temp['Zone_ID'] = ''\n",
    "#df_cnty['Origin_zone'] = ''\n",
    "#df_cnty['Dest_zone'] = ''\n",
    "sd_df_temp['Units'] = 'minutes'\n",
    "sd_df_temp['Total_Increment'] = ''\n",
    "\n",
    "\n",
    "#RDM Zones\n",
    "rdm_df_temp = df_trn_rail.groupby(['orig_rdm_zones', 'dest_rdm_zones', 'Period'])['trips'].mean().reset_index()\n",
    "rdm_df_temp = rdm_df_temp.rename(columns={'trips': 'Value',\n",
    "                                        'orig_rdm_zones': 'Origin_zone',\n",
    "                                        'dest_rdm_zones': 'Dest_zone'})\n",
    "rdm_df_temp['Concept_ID'] = concept_id\n",
    "rdm_df_temp['Metric_ID'] = 'A1.9'\n",
    "rdm_df_temp['Metric_name'] = 'Crowding (Region)'\n",
    "rdm_df_temp['Submetric'] = 'A1.9.4'\n",
    "rdm_df_temp['Description'] = 'Regional crowding level'\n",
    "rdm_df_temp['Population'] = 'Whole Population'\n",
    "rdm_df_temp['Geography'] = 'RDM'\n",
    "rdm_df_temp['Zone_ID'] = ''\n",
    "#df_cnty['Origin_zone'] = ''\n",
    "#df_cnty['Dest_zone'] = ''\n",
    "rdm_df_temp['Units'] = 'minutes'\n",
    "rdm_df_temp['Total_Increment'] = ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# transbay region\n",
    "tb_value = df_trn_rail[df_trn_rail['transbay_od']==1]\n",
    "tb_value = tb_value.groupby(['Period'])['trips'].mean().reset_index()\n",
    "\n",
    "tb_value['Concept_ID'] = concept_id\n",
    "tb_value['Metric_ID'] = 'A1.9'\n",
    "tb_value['Metric_name'] = 'Crowding (Region)'\n",
    "tb_value['Submetric'] = 'A1.9.5'\n",
    "tb_value['Description'] = 'regional crowding level'\n",
    "tb_value['Population'] = 'Whole Population'\n",
    "tb_value['Geography'] = 'Transbay'\n",
    "tb_value['Zone_ID'] = ''\n",
    "tb_value['Origin_zone'] = ''\n",
    "tb_value['Dest_zone'] = ''\n",
    "tb_value['Units'] = 'minutes'\n",
    "tb_value['Total_Increment'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf6bef",
   "metadata": {},
   "source": [
    "df_rail_trips = []\n",
    "\n",
    "for period in time_periods:\n",
    "    print(f'processing - {period.upper()}')\n",
    "    \n",
    "    # Read in which ODs have either nonzero IVTHVY or IVTCOM. The matrix below contains 0s and 1s.\n",
    "    df_od_pr = omx.open_file(_join(preprocess_dir, \"rail_od_v9_trim_\" + period.upper() + \".omx\"))\n",
    "    \n",
    "    # Read in crowding times between ODs (already multiplied by 1.62). Disconnected ODs have a 0 value.\n",
    "    df_od_cwd = omx.open_file(_join(preprocess_dir, \"rail_crowding_od_v9_trim_\" + period.upper() + \".omx\"))\n",
    "    \n",
    "    # Read in transit trips of this period.\n",
    "    df_trn_pd = df_trn[df_trn['Period'] == period]\n",
    "    \n",
    "    #walk transit\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_WLK')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]        \n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_WLK', cols =['orig', 'dest', 'crowd'])\n",
    "    df_rail_cwd = df_rail_cwd.merge(df_rail_od, on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'WALK_TRANSIT']\n",
    "    df_trn_wlk = pd.merge(df_trn_acc, df_rail_od, \n",
    "                          left_on =['orig_taz', 'dest_taz'], \n",
    "                          right_on=['orig', 'dest'], \n",
    "                          how ='inner')\n",
    "    df_trn_wlk = pd.merge(df_trn_wlk, df_rail_cwd,\n",
    "                          left_on =['orig_taz', 'dest_taz'], \n",
    "                          right_on=['orig', 'dest'], \n",
    "                          how ='inner')\n",
    "    #print(df_trn_wlk.columns)\n",
    "    \n",
    "    # PNR Transit\n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'PNR_TRANSIT']\n",
    "    df_trn_acc_inbnd = df_trn_acc[df_trn_acc['inbound'] == 1] # returning home\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_PNR')\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_PNR', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_pnr_inb = pd.merge(df_trn_acc_inbnd, df_rail_od, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    #del df_trn_pnr_inb['orig']\n",
    "    #del df_trn_pnr_inb['dest']\n",
    "    \n",
    "    df_trn_pnr_inb = pd.merge(df_trn_pnr_inb, df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    #print(df_trn_pnr_inb.columns)\n",
    "    \n",
    "    df_trn_acc_outbnd = df_trn_acc[df_trn_acc['inbound'] != 1] # returning home\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'PNR_TRN_WLK')\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'PNR_TRN_WLK', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_pnr_outbnd = pd.merge(df_trn_acc_outbnd, df_rail_od, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    #del \n",
    "    df_trn_pnr_outbnd = pd.merge(df_trn_pnr_outbnd, df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    #print(df_trn_pnr_outbnd.columns)\n",
    "\n",
    "    df_trn_pnr = pd.concat([df_trn_pnr_inb, df_trn_pnr_outbnd], ignore_index=True)\n",
    "    \n",
    "    # KNR Transit\n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'KNR_TRANSIT']\n",
    "    df_trn_acc_inbnd = df_trn_acc[df_trn_acc['inbound'] == 1] # returning home\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_KNR', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_KNR')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_knr_inb = pd.merge(df_trn_acc_inbnd, df_rail_od, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    df_trn_knr_inb = pd.merge(df_trn_knr_inb, df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "\n",
    "    df_trn_acc_outbnd = df_trn_acc[df_trn_acc['inbound'] != 1] # returning home\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'KNR_TRN_WLK')\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'KNR_TRN_WLK', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_knr_outbnd = pd.merge(df_trn_acc_outbnd, df_rail_od, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    df_trn_knr_outbnd = pd.merge(df_trn_knr_outbnd, df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_trn_knr = pd.concat([df_trn_knr_inb, df_trn_knr_outbnd], ignore_index=True)\n",
    "    \n",
    "    df_trn_rail = pd.concat([df_trn_wlk, df_trn_pnr, df_trn_knr], ignore_index=True)\n",
    "    df_rail_trips.append(df_trn_rail)\n",
    "\n",
    "df_trn_rail = pd.concat(df_rail_trips)\n",
    "print(df_trn_rail.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b356f54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing - AM\n",
      "Walk, transit, walk.\n",
      "Processing - MD\n",
      "Walk, transit, walk.\n",
      "Processing - PM\n",
      "Walk, transit, walk.\n",
      "Processing - EV\n",
      "Walk, transit, walk.\n",
      "Processing - EA\n",
      "Walk, transit, walk.\n"
     ]
    }
   ],
   "source": [
    "df_connected_cwd_skim = []\n",
    "df_all_trips = []\n",
    "\n",
    "for period in time_periods:\n",
    "    print(f'Processing - {period.upper()}')\n",
    "    \n",
    "    # Read in which ODs have either nonzero IVTHVY or IVTCOM. The matrix below contains 0s and 1s.\n",
    "    df_od_pr = omx.open_file(_join(preprocess_dir, \"rail_od_v9_trim_\" + period.upper() + \".omx\"))\n",
    "    \n",
    "    # Read in crowding times between ODs (already multiplied by 1.62). Disconnected ODs have a 0 value.\n",
    "    df_od_cwd = omx.open_file(_join(preprocess_dir, \"rail_crowding_od_v9_trim_\" + period.upper() + \".omx\"))\n",
    "    df_od_cwd_base = df_base_cwd_skim.loc[df_base_cwd_skim['period']==period]\n",
    "    \n",
    "    # Read in transit trips of this period.\n",
    "    df_trips_pd = df_trips[df_trips['Period'] == period]\n",
    "    \n",
    "    # Only for walk, transit, walk.    \n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_WLK')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]        \n",
    "    \n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_WLK', cols =['orig', 'dest', 'crowd'])    \n",
    "    df_rail_cwd = df_rail_cwd.merge(df_rail_od, on=['orig', 'dest'], how ='inner')    \n",
    "    df_rail_cwd['period'] = period\n",
    "    df_connected_cwd_skim_wlk = df_rail_cwd.copy()    \n",
    "    df_baseline_skim = df_od_cwd_base.loc[(df_od_cwd_base['mode']=='WLK_TRN_WLK')]    \n",
    "    df_rail_cwd = df_rail_cwd.merge(df_baseline_skim, on=['orig', 'dest'], how='inner')\n",
    "\n",
    "    df_trips_wlk = df_trips_pd.merge(df_rail_cwd,\n",
    "                          left_on =['orig_taz', 'dest_taz'], \n",
    "                          right_on=['orig', 'dest'], \n",
    "                          how ='inner')        \n",
    "  \n",
    "    \n",
    "    df_connected_cwd_skim_wlk.drop(columns=['rail_od'], inplace=True)\n",
    "    df_connected_cwd_skim.append(df_connected_cwd_skim_wlk)    \n",
    "    \n",
    "    df_all_trips.append(df_trips_wlk)\n",
    "\n",
    "df_connected_cwd_skim = pd.concat(df_connected_cwd_skim)\n",
    "df_all_trips = pd.concat(df_all_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4a811c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hh_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>orig_purpose</th>\n",
       "      <th>dest_purpose</th>\n",
       "      <th>orig_taz</th>\n",
       "      <th>dest_taz</th>\n",
       "      <th>depart_hour</th>\n",
       "      <th>trip_mode</th>\n",
       "      <th>sampleRate</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>trips</th>\n",
       "      <th>transbay_od</th>\n",
       "      <th>orig_rdm_zones</th>\n",
       "      <th>orig_super_dist</th>\n",
       "      <th>orig_county</th>\n",
       "      <th>dest_rdm_zones</th>\n",
       "      <th>dest_super_dist</th>\n",
       "      <th>dest_county</th>\n",
       "      <th>home_zone</th>\n",
       "      <th>income</th>\n",
       "      <th>Income</th>\n",
       "      <th>pp_share</th>\n",
       "      <th>link21_trip_purp</th>\n",
       "      <th>Period</th>\n",
       "      <th>Mode</th>\n",
       "      <th>orig</th>\n",
       "      <th>dest</th>\n",
       "      <th>crowd</th>\n",
       "      <th>rail_od</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2158751</td>\n",
       "      <td>5014996.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Work</td>\n",
       "      <td>atwork</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>San Mateo_32</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Santa Clara_23</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>117090</td>\n",
       "      <td>100k+</td>\n",
       "      <td>0.0</td>\n",
       "      <td>work</td>\n",
       "      <td>am</td>\n",
       "      <td>Auto_SOV</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>19.337141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2366600</td>\n",
       "      <td>5621180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>escort</td>\n",
       "      <td>work</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>San Mateo_32</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Santa Clara_23</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>648</td>\n",
       "      <td>112510</td>\n",
       "      <td>100k+</td>\n",
       "      <td>0.0</td>\n",
       "      <td>work</td>\n",
       "      <td>am</td>\n",
       "      <td>Auto_SOV</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>19.337141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2503773</td>\n",
       "      <td>5953500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>escort</td>\n",
       "      <td>work</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>San Mateo_32</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Santa Clara_23</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>745</td>\n",
       "      <td>32775</td>\n",
       "      <td>30k_to_60k</td>\n",
       "      <td>0.0</td>\n",
       "      <td>work</td>\n",
       "      <td>am</td>\n",
       "      <td>Auto_2Person</td>\n",
       "      <td>865</td>\n",
       "      <td>1155</td>\n",
       "      <td>19.337141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hh_id  person_id  inbound orig_purpose dest_purpose  orig_taz dest_taz  \\\n",
       "0  2158751  5014996.0        0         Work       atwork       865     1155   \n",
       "1  2366600  5621180.0        0       escort         work       865     1155   \n",
       "2  2503773  5953500.0        0       escort         work       865     1155   \n",
       "\n",
       "   depart_hour  trip_mode  sampleRate trip_type  trips  transbay_od  \\\n",
       "0            9          1         1.0       INM    1.0          0.0   \n",
       "1            6          1         1.0       INM    1.0          0.0   \n",
       "2            8          2         1.0       INM    1.0          0.0   \n",
       "\n",
       "  orig_rdm_zones  orig_super_dist  orig_county  dest_rdm_zones  \\\n",
       "0   San Mateo_32                7            2  Santa Clara_23   \n",
       "1   San Mateo_32                7            2  Santa Clara_23   \n",
       "2   San Mateo_32                7            2  Santa Clara_23   \n",
       "\n",
       "   dest_super_dist  dest_county  home_zone  income      Income  pp_share  \\\n",
       "0               10            3          1  117090       100k+       0.0   \n",
       "1               10            3        648  112510       100k+       0.0   \n",
       "2               10            3        745   32775  30k_to_60k       0.0   \n",
       "\n",
       "  link21_trip_purp Period          Mode  orig  dest      crowd  rail_od period  \n",
       "0             work     am      Auto_SOV   865  1155  19.337141      1.0     am  \n",
       "1             work     am      Auto_SOV   865  1155  19.337141      1.0     am  \n",
       "2             work     am  Auto_2Person   865  1155  19.337141      1.0     am  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_trips.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e388951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trips: 5,188,967.0\n"
     ]
    }
   ],
   "source": [
    "# To get total transit trips of a concept scenario, use the baseline script! Do not use this cell.\n",
    "# x = df_all_trips.trips.sum()\n",
    "# print(f'Total number of trips: {x:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74d6a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_trips['crowd_trips'] = df_all_trips['trips'] * df_all_trips['crowd'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c19853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = summarize_all_combinations(df_all_trips, groupby_columns=['Period'], \n",
    "                                      summary_column='crowd_trips')\n",
    "df_temp1 = df_temp1.rename(columns={'Value':'crowd_trips'})\n",
    "\n",
    "\n",
    "df_temp2 = summarize_all_combinations(df_all_trips, groupby_columns=['Period'], \n",
    "                                     summary_column='trips')\n",
    "df_temp2 = df_temp2.rename(columns={'Value':'trips'})\n",
    "\n",
    "\n",
    "region_value2 = pd.merge(df_temp1, df_temp2, on = ['Period'], how='left')\n",
    "region_value2['Value'] = region_value2['crowd_trips'] / region_value2['trips']\n",
    "\n",
    "region_value2 = region_value2[['Period', 'Value']]\n",
    "\n",
    "region_value2['Concept_ID'] = concept_id\n",
    "region_value2['Metric_ID'] = 'A1.10'\n",
    "region_value2['Metric_name'] = 'Crowding (Region)'\n",
    "region_value2['Submetric'] = 'A1.10.5'\n",
    "region_value2['Description'] = 'Regional crowding'\n",
    "region_value2['Population'] = 'Whole Population'\n",
    "region_value2['Geography'] = 'Regional'\n",
    "region_value2['Origin_zone'] = ''\n",
    "region_value2['Dest_zone'] = ''\n",
    "region_value2['Purpose'] = ''\n",
    "region_value2['Mode'] = ''\n",
    "region_value2['Income'] = ''\n",
    "region_value2['Zone_ID'] = ''\n",
    "region_value2['Units'] = 'minutes'\n",
    "region_value2['Total_Increment'] = ''\n",
    "region_value2 = region_value2[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6143010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 A1.10.5 Crowding (Region)\n"
     ]
    }
   ],
   "source": [
    "# all_dfs = [region_value, pp_region_value, df_rdm, df_rdm_pp, region_value2]\n",
    "all_dfs = [region_value2]\n",
    "\n",
    "for dfs in all_dfs:\n",
    "    metric_name = '_regional_crowding_'\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    dfs = dfs[perf_measure_columns]\n",
    "    file_name = dfs['Submetric'][0]\n",
    "    geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "    dfs.to_csv(_join(summary_dir, file_name + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Metric_name'][0])\n",
    "    \n",
    "# combined_df = pd.concat([region_value, pp_region_value, df_rdm, df_rdm_pp]).reset_index(drop=True)\n",
    "combined_df = region_value2.reset_index(drop=True)\n",
    "combined_df.to_csv(_join(summary_dir, 'A10.1' + '_regional_crowding_' + concept_id + '_region' +filename_extension+'_all_trips.csv'), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
