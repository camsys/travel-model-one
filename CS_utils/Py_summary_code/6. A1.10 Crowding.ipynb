{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371adeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmatrix as omx\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "from utility import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "summary_outputs = params['summary_dir']\n",
    "concept_id = params['concept_id']\n",
    "ctramp_dir = params['ctramp_dir']\n",
    "iteration = params['iteration']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "time_period_mapping = params['time_periods_mapping']\n",
    "link21_purp_mapping = params['purpose_mapping']\n",
    "mode_cat_mapping = params['mode_mapping']\n",
    "time_periods = params['periods']\n",
    "acc_egg_modes = params['access_egress_modes']\n",
    "period = params['periods']\n",
    "\n",
    "preprocess_dir = _join(ctramp_dir, '_pre_process_files')\n",
    "perf_measure_columns = params['final_columns']\n",
    "summary_dir = params['summary_dir']\n",
    "\n",
    "demand_matrices_dir = _join(model_outputs_dir, \"demand_matrices\")\n",
    "transit_demand_dir = _join(demand_matrices_dir, \"transit\")\n",
    "transit_skims_dir = _join(skims_dir, \"transit\")\n",
    "best_path_skim_dir = params['best_path_skim_dir']\n",
    "\n",
    "annual_transit_factor = params['annual_transit_factor']\n",
    "annual_auto_factor = params['annual_auto_factor']\n",
    "\n",
    "filename_extension = params['filename_extension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips = pd.read_parquet(_join(preprocess_dir, 'trip_roster.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_skims_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = df_trips.loc[df_trips['trip_mode'].isin([6,7,8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rail_crowding_od_pairs(preprocess_dir, transit_skims_dir, period, acc_egg_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c343b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = []\n",
    "\n",
    "for period in time_periods:\n",
    "    print(f'processing - {period}')\n",
    "    \n",
    "    df_od_pr = omx.open_file(_join(preprocess_dir, \"rail_od_v9_trim_\" + period.upper() + \".omx\"))\n",
    "    df_od_cwd = omx.open_file(_join(preprocess_dir, \"rail_crowding_od_v9_trim_\" + period.upper() + \".omx\"))\n",
    "    df_trn_pd = df_trn[df_trn['Period'] == period]\n",
    "    \n",
    "    #walk transit\n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'WALK_TRANSIT']\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_WLK')\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_WLK', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_wlk = pd.merge(df_trn_acc, df_rail_od, \n",
    "                          left_on =['orig_taz', 'dest_taz'], \n",
    "                          right_on=['orig', 'dest'], \n",
    "                          how ='inner')\n",
    "    df_trn_wlk = pd.merge(df_trn_wlk, df_rail_cwd,\n",
    "                          left_on =['orig_taz', 'dest_taz'], \n",
    "                          right_on=['orig', 'dest'], \n",
    "                          how ='inner')\n",
    "    #print(df_trn_wlk.columns)\n",
    "    \n",
    "    # PNR Transit\n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'PNR_TRANSIT']\n",
    "    df_trn_acc_inbnd = df_trn_acc[df_trn_acc['inbound'] == 1] # returning home\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_PNR')\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_PNR', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_pnr_inb = pd.merge(df_trn_acc_inbnd, df_rail_od, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    #del df_trn_pnr_inb['orig']\n",
    "    #del df_trn_pnr_inb['dest']\n",
    "    \n",
    "    df_trn_pnr_inb = pd.merge(df_trn_pnr_inb, df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    #print(df_trn_pnr_inb.columns)\n",
    "    \n",
    "    df_trn_acc_outbnd = df_trn_acc[df_trn_acc['inbound'] != 1] # returning home\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'PNR_TRN_WLK')\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'PNR_TRN_WLK', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_pnr_outbnd = pd.merge(df_trn_acc_outbnd, df_rail_od, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    #del \n",
    "    df_trn_pnr_outbnd = pd.merge(df_trn_pnr_outbnd, df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    \n",
    "    #print(df_trn_pnr_outbnd.columns)\n",
    "\n",
    "    df_trn_pnr = pd.concat([df_trn_pnr_inb, df_trn_pnr_outbnd], ignore_index=True)\n",
    "    \n",
    "    # KNR Transit\n",
    "    df_trn_acc = df_trn_pd[df_trn_pd['Mode'] == 'KNR_TRANSIT']\n",
    "    df_trn_acc_inbnd = df_trn_acc[df_trn_acc['inbound'] == 1] # returning home\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'WLK_TRN_KNR', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'WLK_TRN_KNR')\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_knr_inb = pd.merge(df_trn_acc_inbnd, df_rail_od, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    df_trn_knr_inb = pd.merge(df_trn_knr_inb, df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "\n",
    "    df_trn_acc_outbnd = df_trn_acc[df_trn_acc['inbound'] != 1] # returning home\n",
    "    df_rail_od = skim_core_to_df(df_od_pr, 'KNR_TRN_WLK')\n",
    "    df_rail_cwd = skim_core_to_df(df_od_cwd, 'KNR_TRN_WLK', cols =['orig', 'dest', 'crowd']) # add walk access/egress\n",
    "    df_rail_od = df_rail_od[df_rail_od['rail_od'] > 0]\n",
    "    df_trn_knr_outbnd = pd.merge(df_trn_acc_outbnd, df_rail_od, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "    df_trn_knr_outbnd = pd.merge(df_trn_knr_outbnd, df_rail_cwd, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_trn_knr = pd.concat([df_trn_knr_inb, df_trn_knr_outbnd], ignore_index=True)\n",
    "    \n",
    "    df_trn_rail = pd.concat([df_trn_wlk, df_trn_pnr, df_trn_knr], ignore_index=True)\n",
    "    df_temp.append(df_trn_rail)\n",
    "\n",
    "df_trn_rail = pd.concat(df_temp)\n",
    "print(df_trn_rail.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn_rail['crowd_trips'] = df_trn_rail['trips']*df_trn_rail['crowd']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfdd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn_rail['pp_trips'] = df_trn_rail['trips']*df_trn_rail['pp_share']/100\n",
    "df_trn_rail['crowd_pp_trips'] = df_trn_rail['pp_trips']*df_trn_rail['crowd']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced85c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "                                      summary_column='crowd_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value':'crowd_trips'})\n",
    "\n",
    "\n",
    "#df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "#                                      summary_column='trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value':'trips'})\n",
    "\n",
    "\n",
    "#region_value = pd.merge(df_temp1, df_temp2, on = ['Period', 'Income'], how='left')\n",
    "#region_value['Value'] = region_value['crowd_trips'] / region_value['trips']\n",
    "\n",
    "region_value = df_temp1 \n",
    "region_value = region_value[['Period', 'Income', 'Value']]\n",
    "\n",
    "#regional value\n",
    "#region_value = df_trn_rail.groupby(['Period'])['trips'].mean().reset_index()\n",
    "#region_value = region_value.rename(columns={'trips': 'Value'})\n",
    "region_value['Concept_ID'] = concept_id\n",
    "region_value['Metric_ID'] = 'A1.10'\n",
    "region_value['Metric_name'] = 'Crowding (Region)'\n",
    "region_value['Submetric'] = 'A1.10.1'\n",
    "region_value['Description'] = 'Regional crowding'\n",
    "region_value['Population'] = 'Whole Population'\n",
    "region_value['Geography'] = 'Regional'\n",
    "region_value['Origin_zone'] = ''\n",
    "region_value['Dest_zone'] = ''\n",
    "region_value['Purpose'] = ''\n",
    "region_value['Mode'] = ''\n",
    "#region_value['Income'] = ''\n",
    "region_value['Zone_ID'] = ''\n",
    "region_value['Units'] = 'minutes'\n",
    "region_value['Total_Increment'] = ''\n",
    "region_value = region_value[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa792e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df1.to_csv(_join(summary_dir, \"A1.10.1_regional_crowding_\" + concept_id + '_region' + filename_extension + \".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63457d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise for prioirty population\n",
    "#regional value\n",
    "\n",
    "df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "                                      summary_column='crowd_pp_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value':'crowd_pp_trips'}) # BC team is interested in total value instead of mean\n",
    "\n",
    "\n",
    "#df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "#                                      summary_column='pp_trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value':'pp_trips'})\n",
    "\n",
    "\n",
    "#pp_region_value = pd.merge(df_temp1, df_temp2, on = ['Period', 'Income'], how='left')\n",
    "#pp_region_value['Value'] = pp_region_value['crowd_pp_trips'] / pp_region_value['pp_trips']\n",
    "pp_region_value = df_temp1\n",
    "pp_region_value = pp_region_value[['Period', 'Income', 'Value']]\n",
    "\n",
    "#region_value = df_trn_rail.groupby(['Period'])['pp_trips'].mean().reset_index()\n",
    "#region_value = region_value.rename(columns={'pp_trips': 'Value'})\n",
    "pp_region_value['Concept_ID'] = concept_id\n",
    "pp_region_value['Metric_ID'] = 'A1.10'\n",
    "pp_region_value['Metric_name'] = 'Crowding (Region)'\n",
    "pp_region_value['Submetric'] = 'A1.10.2'\n",
    "pp_region_value['Description'] = 'Rgional crowding'\n",
    "pp_region_value['Population'] = 'Prioirty Population'\n",
    "pp_region_value['Geography'] = 'Regional'\n",
    "pp_region_value['Origin_zone'] = ''\n",
    "pp_region_value['Dest_zone'] = ''\n",
    "pp_region_value['Purpose'] = ''\n",
    "pp_region_value['Mode'] = ''\n",
    "#pp_region_value['Income'] = ''\n",
    "pp_region_value['Zone_ID'] = ''\n",
    "pp_region_value['Units'] = 'minutes'\n",
    "pp_region_value['Total_Increment'] = ''\n",
    "pp_region_value = pp_region_value[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fd5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_rdm = df_tours.groupby(['orig_rdm_zones', 'dest_rdm_zones', 'Mode', 'Period', 'tour_purpose'])['tours'].sum().reset_index()\n",
    "\n",
    "df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                      summary_column='crowd_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value': 'trips'})\n",
    "\n",
    "#df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "#                                      summary_column='crowd_trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value': 'crowd_trips'})\n",
    "\n",
    "\n",
    "#df_rdm = df_temp1.merge(df_temp2, on = ['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], how = 'left')\n",
    "#df_rdm['Value'] = df_rdm['crowd_trips'] /  df_rdm['trips']\n",
    "\n",
    "df_rdm = df_temp1\n",
    "\n",
    "df_rdm = df_rdm.rename(columns={ \n",
    "                                'orig_rdm_zones' : 'Origin_zone',\n",
    "                                'dest_rdm_zones' : 'Dest_zone'})\n",
    "df_rdm = df_rdm[['Origin_zone', 'Dest_zone', 'Period', 'Income', 'Value']]\n",
    "\n",
    "df_rdm['Concept_ID'] = concept_id\n",
    "df_rdm['Metric_ID'] = 'A1.10'\n",
    "df_rdm['Metric_name'] = 'Crowding (Region)'\n",
    "df_rdm['Submetric'] = 'A1.10.3'\n",
    "df_rdm['Description'] = 'Crowding between RDM zones'\n",
    "df_rdm['Population'] = 'Whole Population'\n",
    "df_rdm['Geography'] = 'RDM'\n",
    "df_rdm['Zone_ID'] = ''\n",
    "df_rdm['Purpose'] = ''\n",
    "df_rdm['Mode'] = ''\n",
    "#df_rdm['Income'] = ''\n",
    "df_rdm['Units'] = 'minutes'\n",
    "df_rdm['Total_Increment'] = ''\n",
    "df_rdm = df_rdm[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "#                                      summary_column='pp_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value': 'pp_trips'})\n",
    "\n",
    "df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                      summary_column='crowd_pp_trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value': 'crowd_pp_trips'})\n",
    "\n",
    "\n",
    "#df_rdm_pp = df_temp1.merge(df_temp2, on = ['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], how = 'left')\n",
    "\n",
    "df_rdm_pp = df_temp2\n",
    "#df_rdm_pp = df_rdm_pp.loc[df_rdm_pp['pp_trips']>0]\n",
    "\n",
    "#df_rdm_pp['Value'] = df_rdm_pp['crowd_pp_trips'] /  df_rdm_pp['pp_trips']\n",
    "\n",
    "\n",
    "df_rdm_pp = df_rdm_pp.rename(columns={ \n",
    "                                'orig_rdm_zones' : 'Origin_zone',\n",
    "                                'dest_rdm_zones' : 'Dest_zone'})\n",
    "df_rdm_pp = df_rdm_pp[['Origin_zone', 'Dest_zone', 'Period', 'Income' ,'Value']]\n",
    "\n",
    "df_rdm_pp['Concept_ID'] = concept_id\n",
    "df_rdm_pp['Metric_ID'] = 'A1.10'\n",
    "df_rdm_pp['Metric_name'] = 'Crowding (Region)'\n",
    "df_rdm_pp['Submetric'] = 'A1.10.4'\n",
    "df_rdm_pp['Description'] = 'Crowding between RDM zones'\n",
    "df_rdm_pp['Population'] = 'Prioirty Population'\n",
    "df_rdm_pp['Geography'] = 'RDM'\n",
    "df_rdm_pp['Zone_ID'] = ''\n",
    "df_rdm_pp['Purpose'] = ''\n",
    "df_rdm_pp['Mode'] = ''\n",
    "#df_rdm_pp['Income'] = ''\n",
    "df_rdm_pp['Units'] = 'minutes'\n",
    "df_rdm_pp['Total_Increment'] = ''\n",
    "df_rdm_pp = df_rdm_pp[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period'], \n",
    "                                      summary_column='crowd_trips')\n",
    "#df_temp1 = df_temp1.rename(columns={'Value':'crowd_trips'})\n",
    "\n",
    "\n",
    "#df_temp2 = summarize_all_combinations(df_trn_rail, groupby_columns=['Period', 'Income'], \n",
    "#                                      summary_column='trips')\n",
    "#df_temp2 = df_temp2.rename(columns={'Value':'trips'})\n",
    "\n",
    "\n",
    "#region_value = pd.merge(df_temp1, df_temp2, on = ['Period', 'Income'], how='left')\n",
    "#region_value['Value'] = region_value['crowd_trips'] / region_value['trips']\n",
    "\n",
    "region_value2 = df_temp1 \n",
    "region_value2 = region_value2[['Period', 'Value']]\n",
    "\n",
    "#regional value\n",
    "#region_value = df_trn_rail.groupby(['Period'])['trips'].mean().reset_index()\n",
    "#region_value = region_value.rename(columns={'trips': 'Value'})\n",
    "region_value2['Concept_ID'] = concept_id\n",
    "region_value2['Metric_ID'] = 'A1.10'\n",
    "region_value2['Metric_name'] = 'Crowding (Region)'\n",
    "region_value2['Submetric'] = 'A1.10.5'\n",
    "region_value2['Description'] = 'Regional crowding'\n",
    "region_value2['Population'] = 'Whole Population'\n",
    "region_value2['Geography'] = 'Regional'\n",
    "region_value2['Origin_zone'] = ''\n",
    "region_value2['Dest_zone'] = ''\n",
    "region_value2['Purpose'] = ''\n",
    "region_value2['Mode'] = ''\n",
    "region_value2['Income'] = ''\n",
    "region_value2['Zone_ID'] = ''\n",
    "region_value2['Units'] = 'minutes'\n",
    "region_value2['Total_Increment'] = ''\n",
    "region_value2 = region_value2[perf_measure_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = [region_value, pp_region_value, df_rdm, df_rdm_pp, region_value2]\n",
    "\n",
    "for dfs in all_dfs:\n",
    "    metric_name = '_regional_crowding_'\n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    dfs = dfs[perf_measure_columns]\n",
    "    file_name = dfs['Submetric'][0]\n",
    "    geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "    dfs.to_csv(_join(summary_dir, file_name + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Metric_name'][0])\n",
    "    \n",
    "combined_df = pd.concat([region_value, pp_region_value, df_rdm, df_rdm_pp]).reset_index(drop=True)\n",
    "combined_df.to_csv(_join(summary_dir, 'A10.1' + '_regional_crowding_' + concept_id + '_region' +filename_extension+'.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_value['Value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f8ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4f840ba",
   "metadata": {},
   "source": [
    "#county \n",
    "county_df_temp = df_trn_rail.groupby(['orig_county', 'dest_county', 'Period'])['trips'].mean().reset_index()\n",
    "county_df_temp = county_df_temp.rename(columns={'trips': 'Value',\n",
    "                                               'orig_county': 'Origin_zone',\n",
    "                                               'dest_county': 'Dest_zone'})\n",
    "county_df_temp['Concept_ID'] = concept_id\n",
    "county_df_temp['Metric_ID'] = 'A1.9'\n",
    "county_df_temp['Metric_name'] = 'Crowding (Region)'\n",
    "county_df_temp['Submetric'] = 'A1.9.2'\n",
    "county_df_temp['Description'] = 'Crowding level between origin and destination county'\n",
    "county_df_temp['Population'] = 'Whole Population'\n",
    "county_df_temp['Geography'] = 'County'\n",
    "county_df_temp['Zone_ID'] = ''\n",
    "#df_cnty['Origin_zone'] = ''\n",
    "#df_cnty['Dest_zone'] = ''\n",
    "county_df_temp['Units'] = 'minutes'\n",
    "county_df_temp['Total_Increment'] = ''\n",
    "\n",
    "\n",
    "#super district\n",
    "sd_df_temp = df_trn_rail.groupby(['orig_super_dist', 'dest_super_dist', 'Period'])['trips'].mean().reset_index()\n",
    "sd_df_temp = sd_df_temp.rename(columns={'trips': 'Value',\n",
    "                                        'orig_super_dist': 'Origin_zone',\n",
    "                                        'dest_super_dist': 'Dest_zone'})\n",
    "sd_df_temp['Concept_ID'] = concept_id\n",
    "sd_df_temp['Metric_ID'] = 'A1.9'\n",
    "sd_df_temp['Metric_name'] = 'Crowding (Region)'\n",
    "sd_df_temp['Submetric'] = 'A1.9.3'\n",
    "sd_df_temp['Description'] = 'Regional crowding level'\n",
    "sd_df_temp['Population'] = 'Whole Population'\n",
    "sd_df_temp['Geography'] = 'Super district'\n",
    "sd_df_temp['Zone_ID'] = ''\n",
    "#df_cnty['Origin_zone'] = ''\n",
    "#df_cnty['Dest_zone'] = ''\n",
    "sd_df_temp['Units'] = 'minutes'\n",
    "sd_df_temp['Total_Increment'] = ''\n",
    "\n",
    "\n",
    "#RDM Zones\n",
    "rdm_df_temp = df_trn_rail.groupby(['orig_rdm_zones', 'dest_rdm_zones', 'Period'])['trips'].mean().reset_index()\n",
    "rdm_df_temp = rdm_df_temp.rename(columns={'trips': 'Value',\n",
    "                                        'orig_rdm_zones': 'Origin_zone',\n",
    "                                        'dest_rdm_zones': 'Dest_zone'})\n",
    "rdm_df_temp['Concept_ID'] = concept_id\n",
    "rdm_df_temp['Metric_ID'] = 'A1.9'\n",
    "rdm_df_temp['Metric_name'] = 'Crowding (Region)'\n",
    "rdm_df_temp['Submetric'] = 'A1.9.4'\n",
    "rdm_df_temp['Description'] = 'Regional crowding level'\n",
    "rdm_df_temp['Population'] = 'Whole Population'\n",
    "rdm_df_temp['Geography'] = 'RDM'\n",
    "rdm_df_temp['Zone_ID'] = ''\n",
    "#df_cnty['Origin_zone'] = ''\n",
    "#df_cnty['Dest_zone'] = ''\n",
    "rdm_df_temp['Units'] = 'minutes'\n",
    "rdm_df_temp['Total_Increment'] = ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# transbay region\n",
    "tb_value = df_trn_rail[df_trn_rail['transbay_od']==1]\n",
    "tb_value = tb_value.groupby(['Period'])['trips'].mean().reset_index()\n",
    "\n",
    "tb_value['Concept_ID'] = concept_id\n",
    "tb_value['Metric_ID'] = 'A1.9'\n",
    "tb_value['Metric_name'] = 'Crowding (Region)'\n",
    "tb_value['Submetric'] = 'A1.9.5'\n",
    "tb_value['Description'] = 'regional crowding level'\n",
    "tb_value['Population'] = 'Whole Population'\n",
    "tb_value['Geography'] = 'Transbay'\n",
    "tb_value['Zone_ID'] = ''\n",
    "tb_value['Origin_zone'] = ''\n",
    "tb_value['Dest_zone'] = ''\n",
    "tb_value['Units'] = 'minutes'\n",
    "tb_value['Total_Increment'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d47f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051bd642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
