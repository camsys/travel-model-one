{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ee4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmatrix as omx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from utility import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7689f-a667-4cfb-a2fc-88d8b851e3fe",
   "metadata": {},
   "source": [
    "#### Details\n",
    "Jobs accessible from people's homes : \n",
    "    count of jobs accessible to each zone within isochrone thresholds (both actual and perceived). Weighted average by workforce in origin zone.\n",
    "    PP metric: yes\n",
    "    Multi or Single path : Single\n",
    "    Modes : rail inclusive (Does this mean only rail OD pairs (IVTHWY + IVTCOM > 0) ?)\n",
    "    Purpose split: No\n",
    "    Period splits: Yes, average weekday and annual\n",
    "    Geography: region, zone origin and destination (RDM, Super district, county) : Just the origin zone ?   \n",
    "    \n",
    "Non-work destinations accessible from people's homes\n",
    "    count of Non-work-destinations accessible to each zone within isochrone thresholds (both actual and perceived). Weighted average by population in origin zone.\n",
    "    PP metric: yes\n",
    "    Multi or Single path : Single\n",
    "    Modes : rail inclusive (Does this mean only rail OD pairs (IVTHWY + IVTCOM > 0) ?)\n",
    "    Purpose split: No\n",
    "    Period splits: Yes, average weekday and annual\n",
    "    Geography: region, zone origin and destination (RDM, Super district, county) : Just the origin zone ?       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "797c354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "#landuse_dir = _join(model_outputs_dir, params['zone_file'])\n",
    "\n",
    "#hwyskmMD = _join(params['best_path_skim_dir'], 'am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx')\n",
    "\n",
    "#transit skims - names\n",
    "#acc_egr = params['access_egress_modes']\n",
    "#transit_skim_files = []\n",
    "#for per in params['periods']:\n",
    "#    for acc in acc_egr:\n",
    "#        file_name = _join(params['best_path_skim_dir'], per+'_'+acc+'_v9_1_release11302022_bestpathresults.omx')\n",
    "#        transit_skim_files.append(file_name)\n",
    "\n",
    "#transit_skim_files = [r'C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx']\n",
    "#cores - 'BOARDS', 'DDIST', 'DTIME', 'FARE', 'IVT', 'IVTCOM', 'IVTEXP', 'IVTFRY', 'IVTHVY', 'IVTLOC', 'IVTLRT',\n",
    "# 'IWAIT', 'PIVTCOM', 'PIVTEXP', 'PIVTFRY', 'PIVTHVY', 'PIVTLOC', 'PIVTLRT', 'WACC', 'WAIT', 'WAUX', 'WEGR', 'XWAIT'\n",
    "\n",
    "ctramp_dir = params['ctramp_dir']\n",
    "actual_tt_cores = params['total_travel_time']\n",
    "perceived_tt_cores = params['perceived_travel_time']\n",
    "time_periods = params['periods']\n",
    "acc_egr = params['access_egress_modes']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "summary_columns = params['final_columns']\n",
    "\n",
    "preprocess_dir = _join(ctramp_dir, '_pre_process_files')\n",
    "perf_measure_columns = params['final_columns']\n",
    "period = params['periods']\n",
    "summary_dir = params['summary_dir']\n",
    "\n",
    "best_path_skim_extension = params['best_path_skim_extension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b58c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skm = omx.open_file(transit_skim_files[4])\n",
    "#print(transit_skim_files[4])\n",
    "#df = skm.list_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439c930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skm.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c5e1226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOARDS', 'DDIST', 'DTIME', 'FARE', 'IVT', 'IVTCOM', 'IVTEXP', 'IVTFRY', 'IVTHVY', 'IVTLOC', 'IVTLRT', 'IWAIT', 'PIVTCOM', 'PIVTEXP', 'PIVTFRY', 'PIVTHVY', 'PIVTLOC', 'PIVTLRT', 'WACC', 'WAIT', 'WAUX', 'WEGR', 'XWAIT']\n"
     ]
    }
   ],
   "source": [
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ddd5e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'md', 'pm', 'ev', 'ea']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db833cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WLK_TRN_WLK', 'KNR_TRN_WLK', 'PNR_TRN_WLK', 'WLK_TRN_PNR', 'WLK_TRN_KNR']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_egr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0939a700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\am_WLK_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\am_KNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\am_PNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\am_WLK_TRN_PNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\am_WLK_TRN_KNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\md_WLK_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\md_KNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\md_PNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\md_WLK_TRN_PNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\md_WLK_TRN_KNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\pm_WLK_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\pm_KNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\pm_PNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\pm_WLK_TRN_PNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\pm_WLK_TRN_KNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ev_WLK_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ev_KNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ev_PNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ev_WLK_TRN_PNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ev_WLK_TRN_KNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ea_WLK_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ea_KNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ea_PNR_TRN_WLK_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ea_WLK_TRN_PNR_TM2_Run03.omx\n",
      "C:\\MTC_tmpy\\TM2_Run03\\calibration_3332\\SinglePath_TM2_Run03_Baseline\\ea_WLK_TRN_KNR_TM2_Run03.omx\n",
      "Wall time: 16min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# find the best path with lowest travel time for each time period\n",
    "\n",
    "perc_tod_tt = []\n",
    "all_tod_tt = []\n",
    "for per in time_periods:\n",
    "    \n",
    "    perc_df = []\n",
    "    tt_df = []\n",
    "    for acc in acc_egr:\n",
    "        file_name = _join(params['best_path_skim_dir'], per+'_'+acc+ best_path_skim_extension+'.omx')\n",
    "        if os.path.exists(file_name):\n",
    "            print(file_name)\n",
    "            skim = omx.open_file(file_name)\n",
    "            \n",
    "            # empty matrix \n",
    "            actl_mat_core = np.zeros(skim.shape())\n",
    "            percvd_mat_core = np.zeros(skim.shape())\n",
    "            \n",
    "            # iterate over all cores to get total travel time\n",
    "            for core in actual_tt_cores:\n",
    "                actl_mat_core = actl_mat_core + np.array(skim[core])\n",
    "                #print(mat_core.sum())\n",
    "                \n",
    "            for core in perceived_tt_cores:\n",
    "                percvd_mat_core = percvd_mat_core + np.array(skim[core])\n",
    "\n",
    "            df = pd.DataFrame(actl_mat_core)\n",
    "            df = pd.melt(df.reset_index(), id_vars='index', value_vars=df.columns)\n",
    "            df['index'] = df['index'] + 1\n",
    "            df['variable'] = df['variable'] + 1\n",
    "            df.columns = ['orig', 'dest', 'tt']\n",
    "            df['acc_egr'] = acc\n",
    "            tt_df.append(df)\n",
    "            \n",
    "            df = pd.DataFrame(percvd_mat_core)\n",
    "            df = pd.melt(df.reset_index(), id_vars='index', value_vars=df.columns)\n",
    "            df['index'] = df['index'] + 1\n",
    "            df['variable'] = df['variable'] + 1\n",
    "            df.columns = ['orig', 'dest', 'tt']\n",
    "            df['acc_egr'] = acc\n",
    "            perc_df.append(df)\n",
    "            \n",
    "        else:\n",
    "            print(f'{file_name} doesn\\'t exist')\n",
    "    \n",
    "    if len(tt_df)>0:\n",
    "        df_temp = pd.concat(tt_df)\n",
    "        df_temp = pd.pivot(df_temp, index=['orig', 'dest'], columns = ['acc_egr'], values = 'tt').reset_index()\n",
    "        df_temp['min_tt'] = df_temp[acc_egr][df_temp[acc_egr] > 0].min(axis=1)\n",
    "        df_temp = df_temp[['orig', 'dest', 'min_tt']]\n",
    "        df_temp['tp'] = per\n",
    "        all_tod_tt.append(df_temp)\n",
    "        \n",
    "    if len(perc_df)>0:\n",
    "        df_temp = pd.concat(perc_df)\n",
    "        df_temp = pd.pivot(df_temp, index=['orig', 'dest'], columns = ['acc_egr'], values = 'tt').reset_index()\n",
    "        df_temp['min_tt'] = df_temp[acc_egr][df_temp[acc_egr] > 0].min(axis=1)\n",
    "        df_temp = df_temp[['orig', 'dest', 'min_tt']]\n",
    "        df_temp['tp'] = per\n",
    "        perc_tod_tt.append(df_temp)\n",
    "    \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "all_tod_tt = pd.concat(all_tod_tt)\n",
    "all_tod_tt = pd.pivot(all_tod_tt, index=['orig', 'dest'], columns = ['tp'], values = 'min_tt')  \n",
    "\n",
    "\n",
    "perc_tod_tt = pd.concat(perc_tod_tt)\n",
    "perc_tod_tt = pd.pivot(perc_tod_tt, index=['orig', 'dest'], columns = ['tp'], values = 'min_tt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102c965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tod_tt.to_parquet(_join(preprocess_dir, 'tod_min_actual_travel_time.parquet'))\n",
    "perc_tod_tt.to_parquet(_join(preprocess_dir, 'tod_min_perceived_travel_time.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdeeaa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>am</th>\n",
       "      <th>ea</th>\n",
       "      <th>ev</th>\n",
       "      <th>md</th>\n",
       "      <th>pm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orig</th>\n",
       "      <th>dest</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7999.0</td>\n",
       "      <td>7629.0</td>\n",
       "      <td>6868.0</td>\n",
       "      <td>5315.0</td>\n",
       "      <td>5075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6538.0</td>\n",
       "      <td>5932.0</td>\n",
       "      <td>6253.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>5602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5626.0</td>\n",
       "      <td>6186.0</td>\n",
       "      <td>5768.0</td>\n",
       "      <td>5377.0</td>\n",
       "      <td>5192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5152.0</td>\n",
       "      <td>5045.0</td>\n",
       "      <td>5422.0</td>\n",
       "      <td>5034.0</td>\n",
       "      <td>4914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3332</th>\n",
       "      <th>3328</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>26842.0</td>\n",
       "      <td>17573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>27934.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>29789.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11102224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tp              am       ea      ev      md       pm\n",
       "orig dest                                           \n",
       "1    1         NaN      NaN     NaN     NaN      NaN\n",
       "     2      7999.0   7629.0  6868.0  5315.0   5075.0\n",
       "     3      6538.0   5932.0  6253.0  5880.0   5602.0\n",
       "     4      5626.0   6186.0  5768.0  5377.0   5192.0\n",
       "     5      5152.0   5045.0  5422.0  5034.0   4914.0\n",
       "...            ...      ...     ...     ...      ...\n",
       "3332 3328      NaN      NaN     NaN     NaN      NaN\n",
       "     3329  26842.0  17573.0     NaN     NaN  16286.0\n",
       "     3330  27934.0      NaN     NaN     NaN  17356.0\n",
       "     3331  29789.0      NaN     NaN     NaN  19211.0\n",
       "     3332      NaN      NaN     NaN     NaN      NaN\n",
       "\n",
       "[11102224 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_tod_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4584e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "\n",
    "#taz to RDM zones, super districts, county\n",
    "geo_cwks = pd.read_csv(_join(params['common_dir'], \"geographies.csv\")) #columns taz, rdm_zones, super_district, county\n",
    "\n",
    "#taz to priority population\n",
    "pp_perc = pd.read_excel(_join(params['common_dir'], \"TAZ_Tract_cwk_summary.xlsx\")) #columns = taz, pp_share \n",
    "\n",
    "#get geogrpahies and priority population in the same file\n",
    "geo_pp_cwks = pd.merge(geo_cwks, pp_perc, on = 'taz', how = 'left') \n",
    "\n",
    "#transbay od pairs\n",
    "transbay_od = pd.read_csv(_join(params['common_dir'], \"transbay_od.csv\")) #columns = transbay_o, transbay_d\n",
    "\n",
    "#non work destinations tazs\n",
    "non_work_tazs = pd.read_excel(_join(params['common_dir'], 'non_work_destinations.xlsx'))\n",
    "#non_work_tazs = list(non_work_tazs['non_wrk_taz'])\n",
    "\n",
    "#taz data for empoyments and resindent employments\n",
    "tazData = pd.read_csv(_join(params['model_dir'], params['zone_file']))\n",
    "tazDataTotemp = tazData[[\"ZONE\", \"TOTEMP\"]]\n",
    "tazDataEmpres = tazData[[\"ZONE\", \"EMPRES\"]]\n",
    "tazDataPop = tazData[[\"ZONE\", \"TOTPOP\"]]\n",
    "\n",
    "#mat_core = params['connectivity_mat_core']\n",
    "time_thresholds = params['accessibility_thresholds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e8ff43-e803-4a22-acf3-3d1f45dfa6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ck = omx.open_file(transit_skim_files[0])\n",
    "#ck.list_matrices()\n",
    "\n",
    "all_tod_tt = pd.read_parquet(_join(preprocess_dir, 'tod_min_actual_travel_time.parquet'))\n",
    "perc_tod_tt = pd.read_parquet(_join(preprocess_dir, 'tod_min_perceived_travel_time.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9130d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_jobs(all_tod_tt, time_periods, time_thresholds, geo_pp_cwks, tt_verbose):\n",
    "\n",
    "    acc_jobs = []\n",
    "    acc_jobs_nwd = []\n",
    "    df = []\n",
    "    acc_jobs_pp = []\n",
    "    acc_jobs_rdm = []\n",
    "    acc_jobs_sd = []\n",
    "    acc_jobs_cnty = []\n",
    "    \n",
    "    for period in time_periods:\n",
    "        \n",
    "        if period in all_tod_tt.columns:\n",
    "            timedaData = all_tod_tt[[period]].reset_index()\n",
    "            print(timedaData.columns)\n",
    "            timedaData = timedaData.fillna(0)\n",
    "            timedaData[period] = timedaData[period]/100\n",
    "\n",
    "            #total employment based on destination\n",
    "            od_data = pd.merge(timedaData, tazDataTotemp, left_on='dest', right_on='ZONE', how = 'left')\n",
    "            print(od_data.columns)\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                # print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[period] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['TOTEMP'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataEmpres, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_empres'] = oddata_min['TOTEMP'] * oddata_min['EMPRES']\n",
    "                job_acc_min = oddata_min['wt_empres'].sum()/oddata_min['EMPRES'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "\n",
    "                df_temp_region = pd.DataFrame({'Description': \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\",\n",
    "                                               'Population': 'Whole Population',\n",
    "                                               'Period': period,\n",
    "                                               'Geography': 'Regional total',\n",
    "                                               'Zone_ID': 'Region',\n",
    "                                               'Submetric': 'B1.1.1',\n",
    "                                               'Total_Increment': '',\n",
    "                                               'Value': job_acc_min}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "\n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_empres_pp'] = oddata_min['TOTEMP'] * oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['EMPRES_pp'] = oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_empres_pp','EMPRES_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['Value'] = oddata_min_pp['wt_empres_pp']/oddata_min_pp['EMPRES_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_nonpp['Value'] = oddata_min_nonpp['wt_empres']/oddata_min_nonpp['EMPRES']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb = oddata_min_comb.loc[oddata_min_comb['priority_population'] == 1]\n",
    "                    oddata_min_comb = oddata_min_comb.drop(columns=['priority_population'])\n",
    "                    oddata_min_comb['Description'] = \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_comb['Period'] = period\n",
    "                    oddata_min_comb['Population'] = 'Priority population'\n",
    "                    oddata_min_comb['Geography'] = 'Regional total'\n",
    "                    oddata_min_comb['Zone_ID'] = 'Region'\n",
    "                    oddata_min_comb = oddata_min_comb[['Description', 'Population', 'Period', \n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_comb['Submetric'] = 'B1.1.2'\n",
    "                    oddata_min_comb['Total_Increment'] = ''\n",
    "                    acc_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_rdm['Value'] =  oddata_min_rdm['wt_empres']/oddata_min_rdm['EMPRES']\n",
    "                    oddata_min_rdm['Description'] = \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_rdm['Period'] = period\n",
    "                    oddata_min_rdm['Geography'] = 'RDM'\n",
    "                    oddata_min_rdm['Population'] = 'Whole Population'\n",
    "                    oddata_min_rdm.rename(columns={'rdm_zones' : 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_rdm = oddata_min_rdm[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_rdm['Submetric'] = 'B1.1.3'\n",
    "                    oddata_min_rdm['Total_Increment'] = ''\n",
    "                    acc_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_sd['Value'] =  oddata_min_sd['wt_empres']/oddata_min_sd['EMPRES']\n",
    "                    oddata_min_sd['Description'] = \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_sd['Period'] = period\n",
    "                    oddata_min_sd['Population'] = 'Whole Population'\n",
    "                    oddata_min_sd['Geography'] = 'Superdistrict'\n",
    "                    oddata_min_sd.rename(columns={'super_district': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_sd = oddata_min_sd[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_sd['Submetric'] = 'B1.1.4'\n",
    "                    oddata_min_sd['Total_Increment'] = ''\n",
    "                    acc_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_cnty['Value'] =  oddata_min_cnty['wt_empres']/oddata_min_cnty['EMPRES']\n",
    "                    oddata_min_cnty['Description'] = \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_cnty['Period'] = period\n",
    "                    oddata_min_cnty['Geography'] = 'County'\n",
    "                    oddata_min_cnty['Population'] = 'Whole Population'\n",
    "                    oddata_min_cnty.rename(columns={'county': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_cnty = oddata_min_cnty[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]   \n",
    "                    oddata_min_cnty['Submetric'] = 'B1.1.5'\n",
    "                    oddata_min_cnty['Total_Increment'] = ''\n",
    "                    acc_jobs_cnty.append(oddata_min_cnty)\n",
    "                        \n",
    "        else:\n",
    "            print(f'{period} travel time doesn\\'t exist.')\n",
    "            \n",
    "    df_region = pd.concat(df).reset_index(drop=True)\n",
    "    df_pp = pd.concat(acc_jobs_pp).reset_index(drop=True)\n",
    "    df_rdm = pd.concat(acc_jobs_rdm).reset_index(drop=True)\n",
    "    df_sd = pd.concat(acc_jobs_sd).reset_index(drop=True)\n",
    "    df_cnty = pd.concat(acc_jobs_cnty).reset_index(drop=True)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b0d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decimals = 0  \n",
    "#df['column'] = df['column'].apply(lambda x: round(x, decimals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef40d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig', 'dest', 'am'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'am', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "Index(['orig', 'dest', 'md'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'md', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "Index(['orig', 'dest', 'pm'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'pm', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "Index(['orig', 'dest', 'ev'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'ev', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "Index(['orig', 'dest', 'ea'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'ea', 'ZONE', 'TOTEMP'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_accessibility_jobs(all_tod_tt, time_periods, time_thresholds, \n",
    "                                                                  geo_pp_cwks, \"actual\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.1'\n",
    "comb_df['Metric_name'] = 'Jobs accessible from peoples’ homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Jobs'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_act = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a10c0d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig', 'dest', 'am'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'am', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "Index(['orig', 'dest', 'md'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'md', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "Index(['orig', 'dest', 'pm'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'pm', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "Index(['orig', 'dest', 'ev'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'ev', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "Index(['orig', 'dest', 'ea'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'ea', 'ZONE', 'TOTEMP'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_accessibility_jobs(perc_tod_tt, time_periods, time_thresholds, \n",
    "                                                                  geo_pp_cwks, \"perceived\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.1'\n",
    "comb_df['Metric_name'] = 'Jobs accessible from peoples’ homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Jobs'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_perc = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cbb0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df_acc = pd.concat([comb_df_act, comb_df_perc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3224c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept_ID</th>\n",
       "      <th>Metric_ID</th>\n",
       "      <th>Metric_name</th>\n",
       "      <th>Submetric</th>\n",
       "      <th>Description</th>\n",
       "      <th>Population</th>\n",
       "      <th>Period</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Zone_ID</th>\n",
       "      <th>Origin_zone</th>\n",
       "      <th>Dest_zone</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Total_Increment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 30 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>189799.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 45 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>316326.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 60 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>561489.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1359446.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 30 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>md</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>264806.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>ea</td>\n",
       "      <td>County</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>839086.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11716</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>ea</td>\n",
       "      <td>County</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>933546.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11717</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>ea</td>\n",
       "      <td>County</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1943769.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11718</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>ea</td>\n",
       "      <td>County</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1991824.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11719</th>\n",
       "      <td>BaseYear2050</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>ea</td>\n",
       "      <td>County</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2173780.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11720 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Concept_ID Metric_ID                          Metric_name Submetric  \\\n",
       "0      BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "1      BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "2      BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "3      BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "4      BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "...             ...       ...                                  ...       ...   \n",
       "11715  BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "11716  BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "11717  BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "11718  BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "11719  BaseYear2050      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "\n",
       "                                       Description        Population Period  \\\n",
       "0         Jobs accessible within actual 30 minutes  Whole Population     am   \n",
       "1         Jobs accessible within actual 45 minutes  Whole Population     am   \n",
       "2         Jobs accessible within actual 60 minutes  Whole Population     am   \n",
       "3         Jobs accessible within actual 90 minutes  Whole Population     am   \n",
       "4         Jobs accessible within actual 30 minutes  Whole Population     md   \n",
       "...                                            ...               ...    ...   \n",
       "11715  Jobs accessible within perceived 90 minutes  Whole Population     ea   \n",
       "11716  Jobs accessible within perceived 90 minutes  Whole Population     ea   \n",
       "11717  Jobs accessible within perceived 90 minutes  Whole Population     ea   \n",
       "11718  Jobs accessible within perceived 90 minutes  Whole Population     ea   \n",
       "11719  Jobs accessible within perceived 90 minutes  Whole Population     ea   \n",
       "\n",
       "            Geography     Zone_ID Origin_zone Dest_zone Purpose      Value  \\\n",
       "0      Regional total  Megaregion                                 189799.0   \n",
       "1      Regional total  Megaregion                                 316326.0   \n",
       "2      Regional total  Megaregion                                 561489.0   \n",
       "3      Regional total  Megaregion                                1359446.0   \n",
       "4      Regional total  Megaregion                                 264806.0   \n",
       "...               ...         ...         ...       ...     ...        ...   \n",
       "11715          County           5                                 839086.0   \n",
       "11716          County           6                                 933546.0   \n",
       "11717          County           7                                1943769.0   \n",
       "11718          County           8                                1991824.0   \n",
       "11719          County           9                                2173780.0   \n",
       "\n",
       "      Units Total_Increment  \n",
       "0      Jobs           Total  \n",
       "1      Jobs           Total  \n",
       "2      Jobs           Total  \n",
       "3      Jobs           Total  \n",
       "4      Jobs           Total  \n",
       "...     ...             ...  \n",
       "11715  Jobs       Increment  \n",
       "11716  Jobs       Increment  \n",
       "11717  Jobs       Increment  \n",
       "11718  Jobs       Increment  \n",
       "11719  Jobs       Increment  \n",
       "\n",
       "[11720 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd75f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_work_destionations(all_tod_tt, time_periods, time_thresholds, geo_pp_cwks, non_work_dest_tazs, tt_verbose):\n",
    "\n",
    "    acc_jobs = []\n",
    "    df = []\n",
    "    nwd_acc_min = []\n",
    "    nwd_jobs_pp = []\n",
    "    nwd_jobs_rdm = []\n",
    "    nwd_jobs_sd = []\n",
    "    nwd_jobs_cnty = []\n",
    "    \n",
    "    for period in time_periods:\n",
    "        \n",
    "        if period in all_tod_tt.columns:\n",
    "\n",
    "            timedaData = all_tod_tt[[period]].reset_index()\n",
    "            print(timedaData.columns)\n",
    "            timedaData = timedaData.fillna(0)\n",
    "            timedaData = timedaData.loc[timedaData[period]>0]\n",
    "            timedaData[period] = timedaData[period]/100\n",
    "\n",
    "            #total non work destinations based on destination\n",
    "            od_data = pd.merge(timedaData, non_work_dest_tazs, left_on='dest', right_on='taz', how = 'inner')\n",
    "            od_data.isna().sum()\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                # print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[period] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['non_work_dest'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataPop, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_pop'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP']\n",
    "                nwd_acc_min = oddata_min['wt_pop'].sum()/oddata_min['non_work_dest'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "\n",
    "                df_temp_region = pd.DataFrame({'Description': \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\",\n",
    "                                               'Population': 'Whole Population',\n",
    "                                               'Period': period,\n",
    "                                               'Geography': 'Regional total',\n",
    "                                               'Zone_ID': 'Region',\n",
    "                                               'Submetric': 'B1.3.1',\n",
    "                                               'Total_Increment': '',\n",
    "                                               'Value': nwd_acc_min}, index=[0])\n",
    "                \n",
    "                \n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "\n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_pop_pp'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['pop_pp'] = oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_pop_pp','pop_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['Value'] = oddata_min_pp['wt_pop_pp']/oddata_min_pp['pop_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_nonpp['Value'] = oddata_min_nonpp['wt_pop']/oddata_min_nonpp['TOTPOP']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb = oddata_min_comb.loc[oddata_min_comb['priority_population'] == 1]\n",
    "                    oddata_min_comb = oddata_min_comb.drop(columns=['priority_population'])\n",
    "                    oddata_min_comb['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_comb['Period'] = period\n",
    "                    oddata_min_comb['Population'] = 'Priority population'\n",
    "                    oddata_min_comb['Geography'] = 'Regional total'\n",
    "                    oddata_min_comb['Zone_ID'] = 'Region'\n",
    "                    oddata_min_comb = oddata_min_comb[['Description', 'Population', 'Period', \n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_comb['Submetric'] = 'B1.3.2'\n",
    "                    oddata_min_comb['Total_Increment'] = ''\n",
    "                    nwd_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_rdm['Value'] =  oddata_min_rdm['wt_pop']/oddata_min_rdm['TOTPOP']\n",
    "                    oddata_min_rdm['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_rdm['Period'] = period\n",
    "                    oddata_min_rdm['Geography'] = 'RDM'\n",
    "                    oddata_min_rdm['Population'] = 'Whole Population'\n",
    "                    oddata_min_rdm.rename(columns={'rdm_zones' : 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_rdm = oddata_min_rdm[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_rdm['Submetric'] = 'B1.3.3'\n",
    "                    oddata_min_rdm['Total_Increment'] = ''\n",
    "                    nwd_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_sd['Value'] =  oddata_min_sd['wt_pop']/oddata_min_sd['TOTPOP']\n",
    "                    oddata_min_sd['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_sd['Period'] = period\n",
    "                    oddata_min_sd['Population'] = 'Whole Population'\n",
    "                    oddata_min_sd['Geography'] = 'Superdistrict'\n",
    "                    oddata_min_sd.rename(columns={'super_district': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_sd = oddata_min_sd[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_sd['Submetric'] = 'B1.3.4'\n",
    "                    oddata_min_sd['Total_Increment'] = ''\n",
    "                    nwd_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_cnty['Value'] =  oddata_min_cnty['wt_pop']/oddata_min_cnty['TOTPOP']\n",
    "                    oddata_min_cnty['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_cnty['Period'] = period\n",
    "                    oddata_min_cnty['Geography'] = 'County'\n",
    "                    oddata_min_cnty['Population'] = 'Whole Population'\n",
    "                    oddata_min_cnty.rename(columns={'county': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_cnty = oddata_min_cnty[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]   \n",
    "                    oddata_min_cnty['Submetric'] = 'B1.3.5'\n",
    "                    oddata_min_cnty['Total_Increment'] = ''\n",
    "                    nwd_jobs_cnty.append(oddata_min_cnty)\n",
    "                        \n",
    "        else:\n",
    "            print(f'{period} travel time doesn\\'t exist.')\n",
    "            \n",
    "    df_region = pd.concat(df).reset_index(drop=True)\n",
    "    df_pp = pd.concat(nwd_jobs_pp).reset_index(drop=True)\n",
    "    df_rdm = pd.concat(nwd_jobs_rdm).reset_index(drop=True)\n",
    "    df_sd = pd.concat(nwd_jobs_sd).reset_index(drop=True)\n",
    "    df_cnty = pd.concat(nwd_jobs_cnty).reset_index(drop=True)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ace19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig', 'dest', 'am'], dtype='object', name='tp')\n",
      "md travel time doesn't exist.\n",
      "pm travel time doesn't exist.\n",
      "ev travel time doesn't exist.\n",
      "ea travel time doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_non_work_destionations(all_tod_tt, time_periods, time_thresholds,\n",
    "                                                                      geo_pp_cwks, non_work_tazs, \"actual\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.3'\n",
    "comb_df['Metric_name'] = 'Non-work destinations accessible from people\\'s homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Destinations'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_nwd_act = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a7c865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig', 'dest', 'am'], dtype='object', name='tp')\n",
      "md travel time doesn't exist.\n",
      "pm travel time doesn't exist.\n",
      "ev travel time doesn't exist.\n",
      "ea travel time doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_non_work_destionations(perc_tod_tt, time_periods, time_thresholds,\n",
    "                                                                      geo_pp_cwks, non_work_tazs, \"perceived\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.3'\n",
    "comb_df['Metric_name'] = 'Non-work destinations accessible from people\\'s homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Destinations'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_nwd_perc = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3087a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df_nwd = pd.concat([comb_df_nwd_act, comb_df_nwd_perc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d87b8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comb_df = pd.concat([comb_df_acc, comb_df_nwd], ignore_index=True)\n",
    "#comb_df = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5282af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.ExcelWriter(os.path.join(summary_outputs, 'concept-BY15.xlsx'), engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "#    comb_df_acc.to_excel(writer, sheet_name='B1.1', startcol=0, index=False)\n",
    "#    comb_df_nwd.to_excel(writer, sheet_name='B1.3', startcol=0, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5fe1f",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d55e183",
   "metadata": {},
   "source": [
    "def get_accessibility_jobs(transit_skim_files, mat_core, geo_pp_cwks, non_work_dest_tazs):\n",
    "\n",
    "    acc_jobs = []\n",
    "    acc_jobs_nwd = []\n",
    "    df = []\n",
    "    acc_jobs_pp = []\n",
    "    acc_jobs_rdm = []\n",
    "    acc_jobs_sd = []\n",
    "    acc_jobs_cnty = []\n",
    "    \n",
    "    #for 25 transit skims files - this includes time periods\n",
    "    for transit_file in transit_skim_files:\n",
    "        \n",
    "        transit_file_name = os.path.split(transit_file)[-1]\n",
    "        \n",
    "        for core in mat_core:\n",
    "            # od data from skims\n",
    "            timedaData = convertMat2Df(transit_file, core)\n",
    "            timedaData = timedaData.loc[timedaData[core]>0]\n",
    "            timedaData[core] = timedaData[core]/100\n",
    "              \n",
    "            #total employment based on destination\n",
    "            od_data = pd.merge(timedaData, tazDataTotemp, left_on='dest', right_on='ZONE', how = 'left')\n",
    "            od_data.columns\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[core] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['TOTEMP'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataEmpres, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_empres'] = oddata_min['TOTEMP'] * oddata_min['EMPRES']\n",
    "                job_acc_min = oddata_min['wt_empres'].sum()/oddata_min['EMPRES'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "                \n",
    "                df_temp_region = pd.DataFrame({'transit_file': os.path.split(transit_file)[-1], 'time_threshold': threshold, 'jobs_from_home': job_acc_min, 'time': core}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "                \n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_empres_pp'] = oddata_min['TOTEMP'] * oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['EMPRES_pp'] = oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_empres_pp','EMPRES_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['jobs_from_home'] = oddata_min_pp['wt_empres_pp']/oddata_min_pp['EMPRES_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'jobs_from_home']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_nonpp['jobs_from_home'] = oddata_min_nonpp['wt_empres']/oddata_min_nonpp['EMPRES']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'jobs_from_home']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb['time_threshold'] = threshold\n",
    "                    oddata_min_comb['transit_file'] = transit_file_name\n",
    "                    oddata_min_comb['time'] = core\n",
    "                    acc_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_rdm['jobs_from_home'] =  oddata_min_rdm['wt_empres']/oddata_min_rdm['EMPRES']\n",
    "                    oddata_min_rdm['time_threshold'] = threshold\n",
    "                    oddata_min_rdm['transit_file'] = transit_file_name\n",
    "                    oddata_min_rdm['time'] = core\n",
    "                    oddata_min_rdm = oddata_min_rdm[['rdm_zones', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_sd['jobs_from_home'] =  oddata_min_sd['wt_empres']/oddata_min_sd['EMPRES']\n",
    "                    oddata_min_sd['time_threshold'] = threshold\n",
    "                    oddata_min_sd['transit_file'] = transit_file_name\n",
    "                    oddata_min_sd['time'] = core\n",
    "                    oddata_min_sd = oddata_min_sd[['super_district', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_cnty['jobs_from_home'] =  oddata_min_cnty['wt_empres']/oddata_min_cnty['EMPRES']\n",
    "                    oddata_min_cnty['time_threshold'] = threshold\n",
    "                    oddata_min_cnty['transit_file'] = transit_file_name\n",
    "                    oddata_min_cnty['time'] = core\n",
    "                    oddata_min_cnty = oddata_min_cnty[['county', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_cnty.append(oddata_min_cnty)\n",
    "            \n",
    "    df_region = pd.concat(df)\n",
    "    df_pp = pd.concat(acc_jobs_pp)\n",
    "    df_rdm = pd.concat(acc_jobs_rdm)\n",
    "    df_sd = pd.concat(acc_jobs_sd)\n",
    "    df_cnty = pd.concat(acc_jobs_cnty)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a58c34",
   "metadata": {},
   "source": [
    "def get_non_work_destionations(transit_skim_files, mat_core, geo_pp_cwks, non_work_dest_tazs):\n",
    "\n",
    "    acc_jobs = []\n",
    "    nwd_jobs_nwd = []\n",
    "    df = []\n",
    "    nwd_jobs_pp = []\n",
    "    nwd_jobs_rdm = []\n",
    "    nwd_jobs_sd = []\n",
    "    nwd_jobs_cnty = []\n",
    "    \n",
    "    \n",
    "    #for 25 transit skims files - this includes time periods\n",
    "    for transit_file in transit_skim_files:\n",
    "        \n",
    "        transit_file_name = os.path.split(transit_file)[-1]\n",
    "        \n",
    "        for core in mat_core:\n",
    "            # od data from skims\n",
    "            timedaData = convertMat2Df(transit_file, core)\n",
    "            timedaData = timedaData.loc[timedaData[core]>0]\n",
    "            timedaData[core] = timedaData[core]/100\n",
    "\n",
    "            #total non work destinations based on destination\n",
    "            od_data = pd.merge(timedaData, non_work_dest_tazs, left_on='dest', right_on='taz', how = 'inner')\n",
    "            od_data.isna().sum()\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[core] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['non_work_dest'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataPop, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_pop'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP']\n",
    "                nwd_acc_min = oddata_min['wt_pop'].sum()/oddata_min['non_work_dest'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "                \n",
    "                df_temp_region = pd.DataFrame({'transit_file': os.path.split(transit_file)[-1], 'time_threshold': threshold, 'nwd_from_home': nwd_acc_min, 'time': core}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "                \n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_pop_pp'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['pop_pp'] = oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_pop_pp','pop_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['nwd_from_home'] = oddata_min_pp['wt_pop_pp']/oddata_min_pp['pop_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'nwd_from_home']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_nonpp['nwd_from_home'] = oddata_min_nonpp['wt_pop']/oddata_min_nonpp['TOTPOP']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'nwd_from_home']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb['time_threshold'] = threshold\n",
    "                    oddata_min_comb['transit_file'] = transit_file_name\n",
    "                    oddata_min_comb['time'] = core\n",
    "                    nwd_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_rdm['nwd_from_home'] =  oddata_min_rdm['wt_pop']/oddata_min_rdm['TOTPOP']\n",
    "                    oddata_min_rdm['time_threshold'] = threshold\n",
    "                    oddata_min_rdm['transit_file'] = transit_file_name\n",
    "                    oddata_min_rdm['time'] = core\n",
    "                    oddata_min_rdm = oddata_min_rdm[['rdm_zones', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_sd['nwd_from_home'] =  oddata_min_sd['wt_pop']/oddata_min_sd['TOTPOP']\n",
    "                    oddata_min_sd['time_threshold'] = threshold\n",
    "                    oddata_min_sd['transit_file'] = transit_file_name\n",
    "                    oddata_min_sd['time'] = core\n",
    "                    oddata_min_sd = oddata_min_sd[['super_district', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_cnty['nwd_from_home'] =  oddata_min_cnty['wt_pop']/oddata_min_cnty['TOTPOP']\n",
    "                    oddata_min_cnty['time_threshold'] = threshold\n",
    "                    oddata_min_cnty['transit_file'] = transit_file_name\n",
    "                    oddata_min_cnty['time'] = core\n",
    "                    oddata_min_cnty = oddata_min_cnty[['county', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_cnty.append(oddata_min_cnty)\n",
    "            \n",
    "    df_region = pd.concat(df)\n",
    "    df_pp = pd.concat(nwd_jobs_pp)\n",
    "    df_rdm = pd.concat(nwd_jobs_rdm)\n",
    "    df_sd = pd.concat(nwd_jobs_sd)\n",
    "    df_cnty = pd.concat(nwd_jobs_cnty)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
