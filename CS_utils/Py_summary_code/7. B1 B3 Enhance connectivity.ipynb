{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmatrix as omx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from utility import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7689f-a667-4cfb-a2fc-88d8b851e3fe",
   "metadata": {},
   "source": [
    "#### Details\n",
    "Jobs accessible from people's homes : \n",
    "    count of jobs accessible to each zone within isochrone thresholds (both actual and perceived). Weighted average by workforce in origin zone.\n",
    "    PP metric: yes\n",
    "    Multi or Single path : Single\n",
    "    Modes : rail inclusive (Does this mean only rail OD pairs (IVTHWY + IVTCOM > 0) ?)\n",
    "    Purpose split: No\n",
    "    Period splits: Yes, average weekday and annual\n",
    "    Geography: region, zone origin and destination (RDM, Super district, county) : Just the origin zone ?   \n",
    "    \n",
    "Non-work destinations accessible from people's homes\n",
    "    count of Non-work-destinations accessible to each zone within isochrone thresholds (both actual and perceived). Weighted average by population in origin zone.\n",
    "    PP metric: yes\n",
    "    Multi or Single path : Single\n",
    "    Modes : rail inclusive (Does this mean only rail OD pairs (IVTHWY + IVTCOM > 0) ?)\n",
    "    Purpose split: No\n",
    "    Period splits: Yes, average weekday and annual\n",
    "    Geography: region, zone origin and destination (RDM, Super district, county) : Just the origin zone ?       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "797c354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "#landuse_dir = _join(model_outputs_dir, params['zone_file'])\n",
    "\n",
    "#hwyskmMD = _join(params['best_path_skim_dir'], 'am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx')\n",
    "\n",
    "#transit skims - names\n",
    "#acc_egr = params['access_egress_modes']\n",
    "#transit_skim_files = []\n",
    "#for per in params['periods']:\n",
    "#    for acc in acc_egr:\n",
    "#        file_name = _join(params['best_path_skim_dir'], per+'_'+acc+'_v9_1_release11302022_bestpathresults.omx')\n",
    "#        transit_skim_files.append(file_name)\n",
    "\n",
    "#transit_skim_files = [r'C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx']\n",
    "#cores - 'BOARDS', 'DDIST', 'DTIME', 'FARE', 'IVT', 'IVTCOM', 'IVTEXP', 'IVTFRY', 'IVTHVY', 'IVTLOC', 'IVTLRT',\n",
    "# 'IWAIT', 'PIVTCOM', 'PIVTEXP', 'PIVTFRY', 'PIVTHVY', 'PIVTLOC', 'PIVTLRT', 'WACC', 'WAIT', 'WAUX', 'WEGR', 'XWAIT'\n",
    "\n",
    "ctramp_dir = params['ctramp_dir']\n",
    "actual_tt_cores = params['total_travel_time']\n",
    "perceived_tt_cores = params['perceived_travel_time']\n",
    "time_periods = params['periods']\n",
    "acc_egr = params['access_egress_modes']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "summary_columns = params['final_columns']\n",
    "\n",
    "preprocess_dir = _join(ctramp_dir, '_pre_process_files')\n",
    "perf_measure_columns = params['final_columns']\n",
    "period = params['periods']\n",
    "summary_dir = params['summary_dir']\n",
    "\n",
    "best_path_skim_extension = params['best_path_skim_extension']\n",
    "\n",
    "annual_transit_factor = params['annual_transit_factor']\n",
    "annual_auto_factor = params['annual_auto_factor']\n",
    "\n",
    "filename_extension = params['filename_extension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skm = omx.open_file(transit_skim_files[4])\n",
    "#print(transit_skim_files[4])\n",
    "#df = skm.list_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skm.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4584e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "\n",
    "#taz to RDM zones, super districts, county\n",
    "geo_cwks = pd.read_csv(_join(params['common_dir'], \"geographies.csv\")) #columns taz, rdm_zones, super_district, county\n",
    "\n",
    "#taz to priority population\n",
    "pp_perc = pd.read_excel(_join(params['common_dir'], \"TAZ_Tract_cwk_summary.xlsx\")) #columns = taz, pp_share \n",
    "\n",
    "#get geogrpahies and priority population in the same file\n",
    "geo_pp_cwks = pd.merge(geo_cwks, pp_perc, on = 'taz', how = 'left') \n",
    "\n",
    "#transbay od pairs\n",
    "transbay_od = pd.read_csv(_join(params['common_dir'], \"transbay_od.csv\")) #columns = transbay_o, transbay_d\n",
    "\n",
    "#non work destinations tazs\n",
    "non_work_tazs = pd.read_excel(_join(params['common_dir'], 'non_work_destinations.xlsx'))\n",
    "#non_work_tazs = list(non_work_tazs['non_wrk_taz'])\n",
    "\n",
    "#taz data for empoyments and resindent employments\n",
    "tazData = pd.read_csv(_join(params['model_dir'], params['zone_file']))\n",
    "tazDataTotemp = tazData[[\"ZONE\", \"TOTEMP\", \"RETEMPN\", \"FPSEMPN\", \"HEREMPN\", \"OTHEMPN\", \"AGREMPN\", \"MWTEMPN\"]]\n",
    "tazDataEmpres = tazData[[\"ZONE\", \"EMPRES\"]]\n",
    "tazDataPop = tazData[[\"ZONE\", \"TOTPOP\"]]\n",
    "\n",
    "#mat_core = params['connectivity_mat_core']\n",
    "time_thresholds = params['accessibility_thresholds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e8ff43-e803-4a22-acf3-3d1f45dfa6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ck = omx.open_file(transit_skim_files[0])\n",
    "#ck.list_matrices()\n",
    "\n",
    "all_tod_tt = pd.read_parquet(_join(preprocess_dir, 'tod_min_actual_travel_time.parquet'))\n",
    "perc_tod_tt = pd.read_parquet(_join(preprocess_dir, 'tod_min_perceived_travel_time.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05497cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_categories = {'TOTEMP': 'Total employment',\n",
    "                  'RETEMPN': 'Retail employment', \n",
    "                  'FPSEMPN': 'Financial and professional services employment', \n",
    "                  'HEREMPN': 'Health, educational and recreational service employment', \n",
    "                  'OTHEMPN': 'other employment',\n",
    "                  'AGREMPN': 'agricultural and natural resources employment', \n",
    "                  'MWTEMPN': 'wholesale trade and transportation employment'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59723ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTEMP Total employment\n",
      "RETEMPN Retail employment\n",
      "FPSEMPN Financial and professional services employment\n",
      "HEREMPN Health, educational and recreational service employment\n",
      "OTHEMPN other employment\n",
      "AGREMPN agricultural and natural resources employment\n",
      "MWTEMPN wholesale trade and transportation employment\n"
     ]
    }
   ],
   "source": [
    "for emp_cat in employment_categories:\n",
    "    print(emp_cat, employment_categories[emp_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7120fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retail trade employment; \n",
    "#financial and professional services employment;\n",
    "#health, educational and recreational service employment;  \n",
    "#agricultural and natural resources employment; \n",
    "#manufacturing, wholesale trade and transportation employment; and other employment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "165a0639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['am', 'ea', 'ev', 'md', 'pm'], dtype='object', name='tp')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tod_tt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9130d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_jobs(all_tod_tt, time_periods, time_thresholds, geo_pp_cwks, tt_verbose):\n",
    "\n",
    "    acc_jobs = []\n",
    "    acc_jobs_nwd = []\n",
    "    df = []\n",
    "    acc_jobs_pp = []\n",
    "    acc_jobs_rdm = []\n",
    "    acc_jobs_sd = []\n",
    "    acc_jobs_cnty = []\n",
    "    \n",
    "    for period in time_periods:\n",
    "        \n",
    "            \n",
    "        for emp_cat in employment_categories:\n",
    "            print(period, emp_cat)\n",
    "            emp = employment_categories[emp_cat]\n",
    "\n",
    "            timedaData = all_tod_tt[[period]].reset_index()\n",
    "            #print(timedaData.columns)\n",
    "            timedaData = timedaData.fillna(0)\n",
    "            timedaData[period] = timedaData[period]/100\n",
    "\n",
    "            #total employment based on destination\n",
    "            od_data = pd.merge(timedaData, tazDataTotemp, left_on='dest', right_on='ZONE', how = 'left')\n",
    "            #print(od_data.columns)\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                # print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[period] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])[emp_cat].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataEmpres, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_empres'] = oddata_min[emp_cat] * oddata_min['EMPRES']\n",
    "                job_acc_min = oddata_min['wt_empres'].sum()/oddata_min['EMPRES'].sum()\n",
    "\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "                df_temp_region = pd.DataFrame({'Description': f\"{emp} accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\",\n",
    "                                               'Population': 'Whole Population',\n",
    "                                               'Period': period,\n",
    "                                               'Geography': 'Regional total',\n",
    "                                               'Zone_ID': 'Region',\n",
    "                                               'Submetric': 'B1.1.1',\n",
    "                                               'Total_Increment': '',\n",
    "                                               'Value': job_acc_min}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "\n",
    "                 # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_cnty['Value'] =  oddata_min_cnty['wt_empres']/oddata_min_cnty['EMPRES']\n",
    "                    oddata_min_cnty['Description'] = f\"{emp} accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_cnty['Period'] = period\n",
    "                    oddata_min_cnty['Geography'] = 'County'\n",
    "                    oddata_min_cnty['Population'] = 'Whole Population'\n",
    "                    oddata_min_cnty.rename(columns={'county': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_cnty = oddata_min_cnty[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]   \n",
    "                    oddata_min_cnty['Submetric'] = 'B1.1.2'\n",
    "                    oddata_min_cnty['Total_Increment'] = ''\n",
    "                    acc_jobs_cnty.append(oddata_min_cnty)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_rdm['Value'] =  oddata_min_rdm['wt_empres']/oddata_min_rdm['EMPRES']\n",
    "                    oddata_min_rdm['Description'] = f\"{emp} accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_rdm['Period'] = period\n",
    "                    oddata_min_rdm['Geography'] = 'RDM'\n",
    "                    oddata_min_rdm['Population'] = 'Whole Population'\n",
    "                    oddata_min_rdm.rename(columns={'rdm_zones' : 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_rdm = oddata_min_rdm[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_rdm['Submetric'] = 'B1.1.3'\n",
    "                    oddata_min_rdm['Total_Increment'] = ''\n",
    "                    acc_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_sd['Value'] =  oddata_min_sd['wt_empres']/oddata_min_sd['EMPRES']\n",
    "                    oddata_min_sd['Description'] = f\"{emp} accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_sd['Period'] = period\n",
    "                    oddata_min_sd['Population'] = 'Whole Population'\n",
    "                    oddata_min_sd['Geography'] = 'Superdistrict'\n",
    "                    oddata_min_sd.rename(columns={'super_district': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_sd = oddata_min_sd[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_sd['Submetric'] = 'B1.1.4'\n",
    "                    oddata_min_sd['Total_Increment'] = ''\n",
    "                    acc_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_empres_pp'] = oddata_min[emp_cat] * oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['EMPRES_pp'] = oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_empres_pp','EMPRES_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['Value'] = oddata_min_pp['wt_empres_pp']/oddata_min_pp['EMPRES_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_nonpp['Value'] = oddata_min_nonpp['wt_empres']/oddata_min_nonpp['EMPRES']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb = oddata_min_comb.loc[oddata_min_comb['priority_population'] == 1]\n",
    "                    oddata_min_comb = oddata_min_comb.drop(columns=['priority_population'])\n",
    "                    oddata_min_comb['Description'] = f\"{emp} accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_comb['Period'] = period\n",
    "                    oddata_min_comb['Population'] = 'Priority population'\n",
    "                    oddata_min_comb['Geography'] = 'Regional total'\n",
    "                    oddata_min_comb['Zone_ID'] = 'Region'\n",
    "                    oddata_min_comb = oddata_min_comb[['Description', 'Population', 'Period', \n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_comb['Submetric'] = 'B1.1.5'\n",
    "                    oddata_min_comb['Total_Increment'] = ''\n",
    "                    acc_jobs_pp.append(oddata_min_comb)\n",
    "            \n",
    "    df_region = pd.concat(df).reset_index(drop=True)\n",
    "    df_pp = pd.concat(acc_jobs_pp).reset_index(drop=True)\n",
    "    df_rdm = pd.concat(acc_jobs_rdm).reset_index(drop=True)\n",
    "    df_sd = pd.concat(acc_jobs_sd).reset_index(drop=True)\n",
    "    df_cnty = pd.concat(acc_jobs_cnty).reset_index(drop=True)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d6d73f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am TOTEMP\n",
      "am RETEMPN\n",
      "am FPSEMPN\n",
      "am HEREMPN\n",
      "am OTHEMPN\n",
      "am AGREMPN\n",
      "am MWTEMPN\n",
      "md TOTEMP\n",
      "md RETEMPN\n",
      "md FPSEMPN\n",
      "md HEREMPN\n",
      "md OTHEMPN\n",
      "md AGREMPN\n",
      "md MWTEMPN\n",
      "pm TOTEMP\n",
      "pm RETEMPN\n",
      "pm FPSEMPN\n",
      "pm HEREMPN\n",
      "pm OTHEMPN\n",
      "pm AGREMPN\n",
      "pm MWTEMPN\n",
      "ev TOTEMP\n",
      "ev RETEMPN\n",
      "ev FPSEMPN\n",
      "ev HEREMPN\n",
      "ev OTHEMPN\n",
      "ev AGREMPN\n",
      "ev MWTEMPN\n",
      "ea TOTEMP\n",
      "ea RETEMPN\n",
      "ea FPSEMPN\n",
      "ea HEREMPN\n",
      "ea OTHEMPN\n",
      "ea AGREMPN\n",
      "ea MWTEMPN\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_accessibility_jobs(all_tod_tt, time_periods, time_thresholds, \n",
    "                                                                  geo_pp_cwks, \"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8b0d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decimals = 0  \n",
    "#df['column'] = df['column'].apply(lambda x: round(x, decimals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef40d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.1'\n",
    "comb_df['Metric_name'] = 'Jobs accessible from peoples homes - actual travel time'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Jobs'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "comb_df_act = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1716493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 B1.1.1 37323070.0\n",
      "140 B1.1.5 38806332.0\n",
      "34720 B1.1.3 10240529960.0\n",
      "4760 B1.1.4 1400442320.0\n",
      "1260 B1.1.2 401669633.0\n"
     ]
    }
   ],
   "source": [
    "unique_medtric_ids = comb_df_act['Submetric'].unique()\n",
    "for mids in unique_medtric_ids:\n",
    "    metric_name = 'jobs_accessible_from_home_actual_time_'\n",
    "    dfs = comb_df_act.loc[comb_df_act['Submetric']==mids]\n",
    "    #print(dfs.columns)\n",
    "    dfs = dfs[perf_measure_columns]\n",
    "    file_name = mids\n",
    "    dfs.to_csv(_join(summary_dir, metric_name + file_name + filename_extension +  '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Value'].sum())\n",
    "\n",
    "comb_df_act.to_csv(_join(summary_dir, 'jobs_accessible_from_home_actual_time_' + 'B1.1' + filename_extension + '.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5be16902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am TOTEMP\n",
      "am RETEMPN\n",
      "am FPSEMPN\n",
      "am HEREMPN\n",
      "am OTHEMPN\n",
      "am AGREMPN\n",
      "am MWTEMPN\n",
      "md TOTEMP\n",
      "md RETEMPN\n",
      "md FPSEMPN\n",
      "md HEREMPN\n",
      "md OTHEMPN\n",
      "md AGREMPN\n",
      "md MWTEMPN\n",
      "pm TOTEMP\n",
      "pm RETEMPN\n",
      "pm FPSEMPN\n",
      "pm HEREMPN\n",
      "pm OTHEMPN\n",
      "pm AGREMPN\n",
      "pm MWTEMPN\n",
      "ev TOTEMP\n",
      "ev RETEMPN\n",
      "ev FPSEMPN\n",
      "ev HEREMPN\n",
      "ev OTHEMPN\n",
      "ev AGREMPN\n",
      "ev MWTEMPN\n",
      "ea TOTEMP\n",
      "ea RETEMPN\n",
      "ea FPSEMPN\n",
      "ea HEREMPN\n",
      "ea OTHEMPN\n",
      "ea AGREMPN\n",
      "ea MWTEMPN\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_accessibility_jobs(perc_tod_tt, time_periods, time_thresholds, \n",
    "                                                                  geo_pp_cwks, \"perceived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a10c0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.1'\n",
    "comb_df['Metric_name'] = 'Jobs accessible from peoples homes - perceived travel time'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Jobs'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_perc = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a5abc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 B1.1.1 37323070.0\n",
      "140 B1.1.5 38806332.0\n",
      "34720 B1.1.3 10240529960.0\n",
      "4760 B1.1.4 1400442320.0\n",
      "1260 B1.1.2 401669633.0\n"
     ]
    }
   ],
   "source": [
    "unique_medtric_ids = comb_df_perc['Submetric'].unique()\n",
    "for mids in unique_medtric_ids:\n",
    "    metric_name = 'jobs_accessible_from_home_perceived_time_'\n",
    "    dfs = comb_df_act.loc[comb_df_act['Submetric']==mids]\n",
    "    #print(dfs.columns)\n",
    "    dfs = dfs[perf_measure_columns]\n",
    "    file_name = mids\n",
    "    dfs.to_csv(_join(summary_dir, metric_name + file_name + filename_extension +  '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Value'].sum())\n",
    "\n",
    "comb_df_act.to_csv(_join(summary_dir, 'jobs_accessible_from_home_perceived_time_' + 'B1.1' + filename_extension + '.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c69b8c",
   "metadata": {},
   "source": [
    "def get_non_work_destionations(all_tod_tt, time_periods, time_thresholds, geo_pp_cwks, non_work_dest_tazs, tt_verbose):\n",
    "\n",
    "    acc_jobs = []\n",
    "    df = []\n",
    "    nwd_acc_min = []\n",
    "    nwd_jobs_pp = []\n",
    "    nwd_jobs_rdm = []\n",
    "    nwd_jobs_sd = []\n",
    "    nwd_jobs_cnty = []\n",
    "    \n",
    "    for period in time_periods:\n",
    "        \n",
    "        if period in all_tod_tt.columns:\n",
    "\n",
    "            timedaData = all_tod_tt[[period]].reset_index()\n",
    "            print(timedaData.columns)\n",
    "            timedaData = timedaData.fillna(0)\n",
    "            timedaData = timedaData.loc[timedaData[period]>0]\n",
    "            timedaData[period] = timedaData[period]/100\n",
    "\n",
    "            #total non work destinations based on destination\n",
    "            od_data = pd.merge(timedaData, non_work_dest_tazs, left_on='dest', right_on='taz', how = 'inner')\n",
    "            od_data.isna().sum()\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                # print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[period] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['non_work_dest'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataPop, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_pop'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP']\n",
    "                nwd_acc_min = oddata_min['wt_pop'].sum()/oddata_min['non_work_dest'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "\n",
    "                df_temp_region = pd.DataFrame({'Description': \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\",\n",
    "                                               'Population': 'Whole Population',\n",
    "                                               'Period': period,\n",
    "                                               'Geography': 'Regional total',\n",
    "                                               'Zone_ID': 'Region',\n",
    "                                               'Submetric': 'B1.3.1',\n",
    "                                               'Total_Increment': '',\n",
    "                                               'Value': nwd_acc_min}, index=[0])\n",
    "                \n",
    "                \n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "\n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_pop_pp'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['pop_pp'] = oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_pop_pp','pop_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['Value'] = oddata_min_pp['wt_pop_pp']/oddata_min_pp['pop_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_nonpp['Value'] = oddata_min_nonpp['wt_pop']/oddata_min_nonpp['TOTPOP']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb = oddata_min_comb.loc[oddata_min_comb['priority_population'] == 1]\n",
    "                    oddata_min_comb = oddata_min_comb.drop(columns=['priority_population'])\n",
    "                    oddata_min_comb['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_comb['Period'] = period\n",
    "                    oddata_min_comb['Population'] = 'Priority population'\n",
    "                    oddata_min_comb['Geography'] = 'Regional total'\n",
    "                    oddata_min_comb['Zone_ID'] = 'Region'\n",
    "                    oddata_min_comb = oddata_min_comb[['Description', 'Population', 'Period', \n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_comb['Submetric'] = 'B1.3.2'\n",
    "                    oddata_min_comb['Total_Increment'] = ''\n",
    "                    nwd_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_rdm['Value'] =  oddata_min_rdm['wt_pop']/oddata_min_rdm['TOTPOP']\n",
    "                    oddata_min_rdm['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_rdm['Period'] = period\n",
    "                    oddata_min_rdm['Geography'] = 'RDM'\n",
    "                    oddata_min_rdm['Population'] = 'Whole Population'\n",
    "                    oddata_min_rdm.rename(columns={'rdm_zones' : 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_rdm = oddata_min_rdm[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_rdm['Submetric'] = 'B1.3.3'\n",
    "                    oddata_min_rdm['Total_Increment'] = ''\n",
    "                    nwd_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_sd['Value'] =  oddata_min_sd['wt_pop']/oddata_min_sd['TOTPOP']\n",
    "                    oddata_min_sd['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_sd['Period'] = period\n",
    "                    oddata_min_sd['Population'] = 'Whole Population'\n",
    "                    oddata_min_sd['Geography'] = 'Superdistrict'\n",
    "                    oddata_min_sd.rename(columns={'super_district': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_sd = oddata_min_sd[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_sd['Submetric'] = 'B1.3.4'\n",
    "                    oddata_min_sd['Total_Increment'] = ''\n",
    "                    nwd_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_cnty['Value'] =  oddata_min_cnty['wt_pop']/oddata_min_cnty['TOTPOP']\n",
    "                    oddata_min_cnty['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_cnty['Period'] = period\n",
    "                    oddata_min_cnty['Geography'] = 'County'\n",
    "                    oddata_min_cnty['Population'] = 'Whole Population'\n",
    "                    oddata_min_cnty.rename(columns={'county': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_cnty = oddata_min_cnty[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]   \n",
    "                    oddata_min_cnty['Submetric'] = 'B1.3.5'\n",
    "                    oddata_min_cnty['Total_Increment'] = ''\n",
    "                    nwd_jobs_cnty.append(oddata_min_cnty)\n",
    "                        \n",
    "        else:\n",
    "            print(f'{period} travel time doesn\\'t exist.')\n",
    "            \n",
    "    df_region = pd.concat(df).reset_index(drop=True)\n",
    "    df_pp = pd.concat(nwd_jobs_pp).reset_index(drop=True)\n",
    "    df_rdm = pd.concat(nwd_jobs_rdm).reset_index(drop=True)\n",
    "    df_sd = pd.concat(nwd_jobs_sd).reset_index(drop=True)\n",
    "    df_cnty = pd.concat(nwd_jobs_cnty).reset_index(drop=True)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0fdd99",
   "metadata": {},
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_non_work_destionations(all_tod_tt, time_periods, time_thresholds,\n",
    "                                                                      geo_pp_cwks, non_work_tazs, \"actual\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.3'\n",
    "comb_df['Metric_name'] = 'Non-work destinations accessible from people\\'s homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Destinations'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_nwd_act = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba3aff",
   "metadata": {},
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_non_work_destionations(perc_tod_tt, time_periods, time_thresholds,\n",
    "                                                                      geo_pp_cwks, non_work_tazs, \"perceived\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.3'\n",
    "comb_df['Metric_name'] = 'Non-work destinations accessible from people\\'s homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Destinations'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_nwd_perc = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93e085",
   "metadata": {},
   "source": [
    "comb_df_nwd = pd.concat([comb_df_nwd_act, comb_df_nwd_perc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comb_df = pd.concat([comb_df_acc, comb_df_nwd], ignore_index=True)\n",
    "#comb_df = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.ExcelWriter(os.path.join(summary_outputs, 'concept-BY15.xlsx'), engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "#    comb_df_acc.to_excel(writer, sheet_name='B1.1', startcol=0, index=False)\n",
    "#    comb_df_nwd.to_excel(writer, sheet_name='B1.3', startcol=0, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5fe1f",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d55e183",
   "metadata": {},
   "source": [
    "def get_accessibility_jobs(transit_skim_files, mat_core, geo_pp_cwks, non_work_dest_tazs):\n",
    "\n",
    "    acc_jobs = []\n",
    "    acc_jobs_nwd = []\n",
    "    df = []\n",
    "    acc_jobs_pp = []\n",
    "    acc_jobs_rdm = []\n",
    "    acc_jobs_sd = []\n",
    "    acc_jobs_cnty = []\n",
    "    \n",
    "    #for 25 transit skims files - this includes time periods\n",
    "    for transit_file in transit_skim_files:\n",
    "        \n",
    "        transit_file_name = os.path.split(transit_file)[-1]\n",
    "        \n",
    "        for core in mat_core:\n",
    "            # od data from skims\n",
    "            timedaData = convertMat2Df(transit_file, core)\n",
    "            timedaData = timedaData.loc[timedaData[core]>0]\n",
    "            timedaData[core] = timedaData[core]/100\n",
    "              \n",
    "            #total employment based on destination\n",
    "            od_data = pd.merge(timedaData, tazDataTotemp, left_on='dest', right_on='ZONE', how = 'left')\n",
    "            od_data.columns\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[core] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['TOTEMP'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataEmpres, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_empres'] = oddata_min['TOTEMP'] * oddata_min['EMPRES']\n",
    "                job_acc_min = oddata_min['wt_empres'].sum()/oddata_min['EMPRES'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "                \n",
    "                df_temp_region = pd.DataFrame({'transit_file': os.path.split(transit_file)[-1], 'time_threshold': threshold, 'jobs_from_home': job_acc_min, 'time': core}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "                \n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_empres_pp'] = oddata_min['TOTEMP'] * oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['EMPRES_pp'] = oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_empres_pp','EMPRES_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['jobs_from_home'] = oddata_min_pp['wt_empres_pp']/oddata_min_pp['EMPRES_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'jobs_from_home']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_nonpp['jobs_from_home'] = oddata_min_nonpp['wt_empres']/oddata_min_nonpp['EMPRES']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'jobs_from_home']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb['time_threshold'] = threshold\n",
    "                    oddata_min_comb['transit_file'] = transit_file_name\n",
    "                    oddata_min_comb['time'] = core\n",
    "                    acc_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_rdm['jobs_from_home'] =  oddata_min_rdm['wt_empres']/oddata_min_rdm['EMPRES']\n",
    "                    oddata_min_rdm['time_threshold'] = threshold\n",
    "                    oddata_min_rdm['transit_file'] = transit_file_name\n",
    "                    oddata_min_rdm['time'] = core\n",
    "                    oddata_min_rdm = oddata_min_rdm[['rdm_zones', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_sd['jobs_from_home'] =  oddata_min_sd['wt_empres']/oddata_min_sd['EMPRES']\n",
    "                    oddata_min_sd['time_threshold'] = threshold\n",
    "                    oddata_min_sd['transit_file'] = transit_file_name\n",
    "                    oddata_min_sd['time'] = core\n",
    "                    oddata_min_sd = oddata_min_sd[['super_district', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_cnty['jobs_from_home'] =  oddata_min_cnty['wt_empres']/oddata_min_cnty['EMPRES']\n",
    "                    oddata_min_cnty['time_threshold'] = threshold\n",
    "                    oddata_min_cnty['transit_file'] = transit_file_name\n",
    "                    oddata_min_cnty['time'] = core\n",
    "                    oddata_min_cnty = oddata_min_cnty[['county', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_cnty.append(oddata_min_cnty)\n",
    "            \n",
    "    df_region = pd.concat(df)\n",
    "    df_pp = pd.concat(acc_jobs_pp)\n",
    "    df_rdm = pd.concat(acc_jobs_rdm)\n",
    "    df_sd = pd.concat(acc_jobs_sd)\n",
    "    df_cnty = pd.concat(acc_jobs_cnty)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a58c34",
   "metadata": {},
   "source": [
    "def get_non_work_destionations(transit_skim_files, mat_core, geo_pp_cwks, non_work_dest_tazs):\n",
    "\n",
    "    acc_jobs = []\n",
    "    nwd_jobs_nwd = []\n",
    "    df = []\n",
    "    nwd_jobs_pp = []\n",
    "    nwd_jobs_rdm = []\n",
    "    nwd_jobs_sd = []\n",
    "    nwd_jobs_cnty = []\n",
    "    \n",
    "    \n",
    "    #for 25 transit skims files - this includes time periods\n",
    "    for transit_file in transit_skim_files:\n",
    "        \n",
    "        transit_file_name = os.path.split(transit_file)[-1]\n",
    "        \n",
    "        for core in mat_core:\n",
    "            # od data from skims\n",
    "            timedaData = convertMat2Df(transit_file, core)\n",
    "            timedaData = timedaData.loc[timedaData[core]>0]\n",
    "            timedaData[core] = timedaData[core]/100\n",
    "\n",
    "            #total non work destinations based on destination\n",
    "            od_data = pd.merge(timedaData, non_work_dest_tazs, left_on='dest', right_on='taz', how = 'inner')\n",
    "            od_data.isna().sum()\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[core] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['non_work_dest'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataPop, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_pop'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP']\n",
    "                nwd_acc_min = oddata_min['wt_pop'].sum()/oddata_min['non_work_dest'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "                \n",
    "                df_temp_region = pd.DataFrame({'transit_file': os.path.split(transit_file)[-1], 'time_threshold': threshold, 'nwd_from_home': nwd_acc_min, 'time': core}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "                \n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_pop_pp'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['pop_pp'] = oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_pop_pp','pop_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['nwd_from_home'] = oddata_min_pp['wt_pop_pp']/oddata_min_pp['pop_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'nwd_from_home']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_nonpp['nwd_from_home'] = oddata_min_nonpp['wt_pop']/oddata_min_nonpp['TOTPOP']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'nwd_from_home']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb['time_threshold'] = threshold\n",
    "                    oddata_min_comb['transit_file'] = transit_file_name\n",
    "                    oddata_min_comb['time'] = core\n",
    "                    nwd_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_rdm['nwd_from_home'] =  oddata_min_rdm['wt_pop']/oddata_min_rdm['TOTPOP']\n",
    "                    oddata_min_rdm['time_threshold'] = threshold\n",
    "                    oddata_min_rdm['transit_file'] = transit_file_name\n",
    "                    oddata_min_rdm['time'] = core\n",
    "                    oddata_min_rdm = oddata_min_rdm[['rdm_zones', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_sd['nwd_from_home'] =  oddata_min_sd['wt_pop']/oddata_min_sd['TOTPOP']\n",
    "                    oddata_min_sd['time_threshold'] = threshold\n",
    "                    oddata_min_sd['transit_file'] = transit_file_name\n",
    "                    oddata_min_sd['time'] = core\n",
    "                    oddata_min_sd = oddata_min_sd[['super_district', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_cnty['nwd_from_home'] =  oddata_min_cnty['wt_pop']/oddata_min_cnty['TOTPOP']\n",
    "                    oddata_min_cnty['time_threshold'] = threshold\n",
    "                    oddata_min_cnty['transit_file'] = transit_file_name\n",
    "                    oddata_min_cnty['time'] = core\n",
    "                    oddata_min_cnty = oddata_min_cnty[['county', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_cnty.append(oddata_min_cnty)\n",
    "            \n",
    "    df_region = pd.concat(df)\n",
    "    df_pp = pd.concat(nwd_jobs_pp)\n",
    "    df_rdm = pd.concat(nwd_jobs_rdm)\n",
    "    df_sd = pd.concat(nwd_jobs_sd)\n",
    "    df_cnty = pd.concat(nwd_jobs_cnty)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
