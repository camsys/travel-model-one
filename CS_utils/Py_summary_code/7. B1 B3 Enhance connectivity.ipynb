{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ee4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmatrix as omx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from utility import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a7689f-a667-4cfb-a2fc-88d8b851e3fe",
   "metadata": {},
   "source": [
    "#### Details\n",
    "Jobs accessible from people's homes : \n",
    "    count of jobs accessible to each zone within isochrone thresholds (both actual and perceived). Weighted average by workforce in origin zone.\n",
    "    PP metric: yes\n",
    "    Multi or Single path : Single\n",
    "    Modes : rail inclusive (Does this mean only rail OD pairs (IVTHWY + IVTCOM > 0) ?)\n",
    "    Purpose split: No\n",
    "    Period splits: Yes, average weekday and annual\n",
    "    Geography: region, zone origin and destination (RDM, Super district, county) : Just the origin zone ?   \n",
    "    \n",
    "Non-work destinations accessible from people's homes\n",
    "    count of Non-work-destinations accessible to each zone within isochrone thresholds (both actual and perceived). Weighted average by population in origin zone.\n",
    "    PP metric: yes\n",
    "    Multi or Single path : Single\n",
    "    Modes : rail inclusive (Does this mean only rail OD pairs (IVTHWY + IVTCOM > 0) ?)\n",
    "    Purpose split: No\n",
    "    Period splits: Yes, average weekday and annual\n",
    "    Geography: region, zone origin and destination (RDM, Super district, county) : Just the origin zone ?       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797c354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "#landuse_dir = _join(model_outputs_dir, params['zone_file'])\n",
    "\n",
    "#hwyskmMD = _join(params['best_path_skim_dir'], 'am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx')\n",
    "\n",
    "#transit skims - names\n",
    "#acc_egr = params['access_egress_modes']\n",
    "#transit_skim_files = []\n",
    "#for per in params['periods']:\n",
    "#    for acc in acc_egr:\n",
    "#        file_name = _join(params['best_path_skim_dir'], per+'_'+acc+'_v9_1_release11302022_bestpathresults.omx')\n",
    "#        transit_skim_files.append(file_name)\n",
    "\n",
    "#transit_skim_files = [r'C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx']\n",
    "#cores - 'BOARDS', 'DDIST', 'DTIME', 'FARE', 'IVT', 'IVTCOM', 'IVTEXP', 'IVTFRY', 'IVTHVY', 'IVTLOC', 'IVTLRT',\n",
    "# 'IWAIT', 'PIVTCOM', 'PIVTEXP', 'PIVTFRY', 'PIVTHVY', 'PIVTLOC', 'PIVTLRT', 'WACC', 'WAIT', 'WAUX', 'WEGR', 'XWAIT'\n",
    "\n",
    "summary_outputs = params['summary_dir']\n",
    "\n",
    "actual_tt_cores = params['total_travel_time']\n",
    "perceived_tt_cores = params['perceived_travel_time']\n",
    "time_periods = params['periods']\n",
    "acc_egr = params['access_egress_modes']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "summary_columns = params['final_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b58c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_WLK_TRN_KNR_v9_1_release11302022_bestpathresults.omx\n"
     ]
    }
   ],
   "source": [
    "skm = omx.open_file(transit_skim_files[4])\n",
    "print(transit_skim_files[4])\n",
    "df = skm.list_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "439c930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3332, 3332)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c5e1226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOARDS', 'DDIST', 'DTIME', 'FARE', 'IVT', 'IVTCOM', 'IVTEXP', 'IVTFRY', 'IVTHVY', 'IVTLOC', 'IVTLRT', 'IWAIT', 'PIVTCOM', 'PIVTEXP', 'PIVTFRY', 'PIVTHVY', 'PIVTLOC', 'PIVTLRT', 'WACC', 'WAIT', 'WAUX', 'WEGR', 'XWAIT']\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd5e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db833cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0939a700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_WLK_TRN_WLK_v9_1_release11302022_bestpathresults.omx\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_PNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_WLK_TRN_PNR_v9_1_release11302022_bestpathresults.omx\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\am_WLK_TRN_KNR_v9_1_release11302022_bestpathresults.omx\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\md_WLK_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\md_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\md_PNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\md_WLK_TRN_PNR_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\md_WLK_TRN_KNR_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\pm_WLK_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\pm_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\pm_PNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\pm_WLK_TRN_PNR_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\pm_WLK_TRN_KNR_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ev_WLK_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ev_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ev_PNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ev_WLK_TRN_PNR_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ev_WLK_TRN_KNR_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ea_WLK_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ea_KNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ea_PNR_TRN_WLK_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ea_WLK_TRN_PNR_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "C:\\VY-Projects\\Link21\\BaseYear2015\\Best Single Path\\ea_WLK_TRN_KNR_v9_1_release11302022_bestpathresults.omx doesn't exist\n",
      "CPU times: total: 2min 59s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# find the best path with lowest travel time for each time period\n",
    "\n",
    "perc_tod_tt = []\n",
    "all_tod_tt = []\n",
    "for per in time_periods:\n",
    "    \n",
    "    perc_df = []\n",
    "    tt_df = []\n",
    "    for acc in acc_egr:\n",
    "        file_name = _join(params['best_path_skim_dir'], per+'_'+acc+'_v9_1_release11302022_bestpathresults.omx')\n",
    "        if os.path.exists(file_name):\n",
    "            print(file_name)\n",
    "            skim = omx.open_file(file_name)\n",
    "            \n",
    "            # empty matrix \n",
    "            actl_mat_core = np.zeros(skim.shape())\n",
    "            percvd_mat_core = np.zeros(skim.shape())\n",
    "            \n",
    "            # iterate over all cores to get total travel time\n",
    "            for core in actual_tt_cores:\n",
    "                actl_mat_core = actl_mat_core + np.array(skim[core])\n",
    "                #print(mat_core.sum())\n",
    "                \n",
    "            for core in perceived_tt_cores:\n",
    "                percvd_mat_core = percvd_mat_core + np.array(skim[core])\n",
    "\n",
    "            df = pd.DataFrame(actl_mat_core)\n",
    "            df = pd.melt(df.reset_index(), id_vars='index', value_vars=df.columns)\n",
    "            df['index'] = df['index'] + 1\n",
    "            df['variable'] = df['variable'] + 1\n",
    "            df.columns = ['orig', 'dest', 'tt']\n",
    "            df['acc_egr'] = acc\n",
    "            tt_df.append(df)\n",
    "            \n",
    "            df = pd.DataFrame(percvd_mat_core)\n",
    "            df = pd.melt(df.reset_index(), id_vars='index', value_vars=df.columns)\n",
    "            df['index'] = df['index'] + 1\n",
    "            df['variable'] = df['variable'] + 1\n",
    "            df.columns = ['orig', 'dest', 'tt']\n",
    "            df['acc_egr'] = acc\n",
    "            perc_df.append(df)\n",
    "            \n",
    "        else:\n",
    "            print(f'{file_name} doesn\\'t exist')\n",
    "    \n",
    "    if len(tt_df)>0:\n",
    "        df_temp = pd.concat(tt_df)\n",
    "        df_temp = pd.pivot(df_temp, index=['orig', 'dest'], columns = ['acc_egr'], values = 'tt').reset_index()\n",
    "        df_temp['min_tt'] = df_temp[acc_egr][df_temp[acc_egr] > 0].min(axis=1)\n",
    "        df_temp = df_temp[['orig', 'dest', 'min_tt']]\n",
    "        df_temp['tp'] = per\n",
    "        all_tod_tt.append(df_temp)\n",
    "        \n",
    "    if len(perc_df)>0:\n",
    "        df_temp = pd.concat(perc_df)\n",
    "        df_temp = pd.pivot(df_temp, index=['orig', 'dest'], columns = ['acc_egr'], values = 'tt').reset_index()\n",
    "        df_temp['min_tt'] = df_temp[acc_egr][df_temp[acc_egr] > 0].min(axis=1)\n",
    "        df_temp = df_temp[['orig', 'dest', 'min_tt']]\n",
    "        df_temp['tp'] = per\n",
    "        perc_tod_tt.append(df_temp)\n",
    "    \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "all_tod_tt = pd.concat(all_tod_tt)\n",
    "all_tod_tt = pd.pivot(all_tod_tt, index=['orig', 'dest'], columns = ['tp'], values = 'min_tt')  \n",
    "\n",
    "\n",
    "perc_tod_tt = pd.concat(perc_tod_tt)\n",
    "perc_tod_tt = pd.pivot(perc_tod_tt, index=['orig', 'dest'], columns = ['tp'], values = 'min_tt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102c965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tod_tt.to_parquet(_join(params['best_path_skim_dir'], 'tod_min_actual_travel_time.parquet'))\n",
    "perc_tod_tt.to_parquet(_join(params['best_path_skim_dir'], 'tod_min_perceived_travel_time.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4584e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "\n",
    "#taz to RDM zones, super districts, county\n",
    "geo_cwks = pd.read_csv(_join(params['common_dir'], \"geographies.csv\")) #columns taz, rdm_zones, super_district, county\n",
    "\n",
    "#taz to priority population\n",
    "pp_perc = pd.read_excel(_join(params['common_dir'], \"TAZ_Tract_cwk_summary.xlsx\")) #columns = taz, pp_share \n",
    "\n",
    "#get geogrpahies and priority population in the same file\n",
    "geo_pp_cwks = pd.merge(geo_cwks, pp_perc, on = 'taz', how = 'left') \n",
    "\n",
    "#transbay od pairs\n",
    "transbay_od = pd.read_csv(_join(params['common_dir'], \"transbay_od.csv\")) #columns = transbay_o, transbay_d\n",
    "\n",
    "#non work destinations tazs\n",
    "non_work_tazs = pd.read_excel(_join(params['common_dir'], 'non_work_destinations.xlsx'))\n",
    "#non_work_tazs = list(non_work_tazs['non_wrk_taz'])\n",
    "\n",
    "#taz data for empoyments and resindent employments\n",
    "tazData = pd.read_csv(_join(params['model_dir'], params['zone_file']))\n",
    "tazDataTotemp = tazData[[\"ZONE\", \"TOTEMP\"]]\n",
    "tazDataEmpres = tazData[[\"ZONE\", \"EMPRES\"]]\n",
    "tazDataPop = tazData[[\"ZONE\", \"TOTPOP\"]]\n",
    "\n",
    "#mat_core = params['connectivity_mat_core']\n",
    "time_thresholds = params['accessibility_thresholds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8e8ff43-e803-4a22-acf3-3d1f45dfa6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ck = omx.open_file(transit_skim_files[0])\n",
    "#ck.list_matrices()\n",
    "\n",
    "all_tod_tt = pd.read_parquet(_join(params['best_path_skim_dir'], 'tod_min_actual_travel_time.parquet'))\n",
    "perc_tod_tt = pd.read_parquet(_join(params['best_path_skim_dir'], 'tod_min_perceived_travel_time.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9130d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_jobs(all_tod_tt, time_periods, time_thresholds, geo_pp_cwks, tt_verbose):\n",
    "\n",
    "    acc_jobs = []\n",
    "    acc_jobs_nwd = []\n",
    "    df = []\n",
    "    acc_jobs_pp = []\n",
    "    acc_jobs_rdm = []\n",
    "    acc_jobs_sd = []\n",
    "    acc_jobs_cnty = []\n",
    "    \n",
    "    for period in time_periods:\n",
    "        \n",
    "        if period in all_tod_tt.columns:\n",
    "            timedaData = all_tod_tt[[period]].reset_index()\n",
    "            print(timedaData.columns)\n",
    "            timedaData = timedaData.fillna(0)\n",
    "            timedaData[period] = timedaData[period]/100\n",
    "\n",
    "            #total employment based on destination\n",
    "            od_data = pd.merge(timedaData, tazDataTotemp, left_on='dest', right_on='ZONE', how = 'left')\n",
    "            print(od_data.columns)\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                # print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[period] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['TOTEMP'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataEmpres, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_empres'] = oddata_min['TOTEMP'] * oddata_min['EMPRES']\n",
    "                job_acc_min = oddata_min['wt_empres'].sum()/oddata_min['EMPRES'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "\n",
    "                df_temp_region = pd.DataFrame({'Description': \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\",\n",
    "                                               'Population': 'Whole Population',\n",
    "                                               'Period': period,\n",
    "                                               'Geography': 'Regional total',\n",
    "                                               'Zone_ID': 'Megaregion',\n",
    "                                               'Submetric': 'B1.1.1',\n",
    "                                               'Total_Increment': 'Total',\n",
    "                                               'Value': job_acc_min}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "\n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_empres_pp'] = oddata_min['TOTEMP'] * oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['EMPRES_pp'] = oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_empres_pp','EMPRES_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['Value'] = oddata_min_pp['wt_empres_pp']/oddata_min_pp['EMPRES_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_nonpp['Value'] = oddata_min_nonpp['wt_empres']/oddata_min_nonpp['EMPRES']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb = oddata_min_comb.loc[oddata_min_comb['priority_population'] == 1]\n",
    "                    oddata_min_comb = oddata_min_comb.drop(columns=['priority_population'])\n",
    "                    oddata_min_comb['Description'] = \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_comb['Period'] = period\n",
    "                    oddata_min_comb['Population'] = 'Priority population'\n",
    "                    oddata_min_comb['Geography'] = 'Regional total'\n",
    "                    oddata_min_comb['Zone_ID'] = 'Megaregion'\n",
    "                    oddata_min_comb = oddata_min_comb[['Description', 'Population', 'Period', \n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_comb['Submetric'] = 'B1.1.2'\n",
    "                    oddata_min_comb['Total_Increment'] = 'Increment'\n",
    "                    acc_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_rdm['Value'] =  oddata_min_rdm['wt_empres']/oddata_min_rdm['EMPRES']\n",
    "                    oddata_min_rdm['Description'] = \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_rdm['Period'] = period\n",
    "                    oddata_min_rdm['Geography'] = 'RDM'\n",
    "                    oddata_min_rdm['Population'] = 'Whole Population'\n",
    "                    oddata_min_rdm.rename(columns={'rdm_zones' : 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_rdm = oddata_min_rdm[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_rdm['Submetric'] = 'B1.1.3'\n",
    "                    oddata_min_rdm['Total_Increment'] = 'Increment'\n",
    "                    acc_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_sd['Value'] =  oddata_min_sd['wt_empres']/oddata_min_sd['EMPRES']\n",
    "                    oddata_min_sd['Description'] = \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_sd['Period'] = period\n",
    "                    oddata_min_sd['Population'] = 'Whole Population'\n",
    "                    oddata_min_sd['Geography'] = 'Superdistrict'\n",
    "                    oddata_min_sd.rename(columns={'super_district': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_sd = oddata_min_sd[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_sd['Submetric'] = 'B1.1.4'\n",
    "                    oddata_min_sd['Total_Increment'] = 'Increment'\n",
    "                    acc_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_cnty['Value'] =  oddata_min_cnty['wt_empres']/oddata_min_cnty['EMPRES']\n",
    "                    oddata_min_cnty['Description'] = \"Jobs accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_cnty['Period'] = period\n",
    "                    oddata_min_cnty['Geography'] = 'County'\n",
    "                    oddata_min_cnty['Population'] = 'Whole Population'\n",
    "                    oddata_min_cnty.rename(columns={'county': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_cnty = oddata_min_cnty[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]   \n",
    "                    oddata_min_cnty['Submetric'] = 'B1.1.5'\n",
    "                    oddata_min_cnty['Total_Increment'] = 'Increment'\n",
    "                    acc_jobs_cnty.append(oddata_min_cnty)\n",
    "                        \n",
    "        else:\n",
    "            print(f'{period} travel time doesn\\'t exist.')\n",
    "            \n",
    "    df_region = pd.concat(df).reset_index(drop=True)\n",
    "    df_pp = pd.concat(acc_jobs_pp).reset_index(drop=True)\n",
    "    df_rdm = pd.concat(acc_jobs_rdm).reset_index(drop=True)\n",
    "    df_sd = pd.concat(acc_jobs_sd).reset_index(drop=True)\n",
    "    df_cnty = pd.concat(acc_jobs_cnty).reset_index(drop=True)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b0d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decimals = 0  \n",
    "#df['column'] = df['column'].apply(lambda x: round(x, decimals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef40d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig', 'dest', 'am'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'am', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "md travel time doesn't exist.\n",
      "pm travel time doesn't exist.\n",
      "ev travel time doesn't exist.\n",
      "ea travel time doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_accessibility_jobs(all_tod_tt, time_periods, time_thresholds, \n",
    "                                                                  geo_pp_cwks, \"actual\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.1'\n",
    "comb_df['Metric_name'] = 'Jobs accessible from peoples’ homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Jobs'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_act = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10c0d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig', 'dest', 'am'], dtype='object', name='tp')\n",
      "Index(['orig', 'dest', 'am', 'ZONE', 'TOTEMP'], dtype='object')\n",
      "md travel time doesn't exist.\n",
      "pm travel time doesn't exist.\n",
      "ev travel time doesn't exist.\n",
      "ea travel time doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_accessibility_jobs(perc_tod_tt, time_periods, time_thresholds, \n",
    "                                                                  geo_pp_cwks, \"perceived\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.1'\n",
    "comb_df['Metric_name'] = 'Jobs accessible from peoples’ homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Jobs'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_perc = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cbb0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df_acc = pd.concat([comb_df_act, comb_df_perc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3224c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept_ID</th>\n",
       "      <th>Metric_ID</th>\n",
       "      <th>Metric_name</th>\n",
       "      <th>Submetric</th>\n",
       "      <th>Description</th>\n",
       "      <th>Population</th>\n",
       "      <th>Period</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Zone_ID</th>\n",
       "      <th>Origin_zone</th>\n",
       "      <th>Dest_zone</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Total_Increment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 30 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>179488.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 45 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>281058.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 60 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>439633.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.1</td>\n",
       "      <td>Jobs accessible within actual 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>878916.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.2</td>\n",
       "      <td>Jobs accessible within actual 30 minutes</td>\n",
       "      <td>Priority population</td>\n",
       "      <td>am</td>\n",
       "      <td>Regional total</td>\n",
       "      <td>Megaregion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>154545.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>County</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>928747.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>County</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>983984.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>County</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>974328.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>County</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>930812.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>BaseYear2015</td>\n",
       "      <td>B1.1</td>\n",
       "      <td>Jobs accessible from peoples’ homes</td>\n",
       "      <td>B1.1.5</td>\n",
       "      <td>Jobs accessible within perceived 90 minutes</td>\n",
       "      <td>Whole Population</td>\n",
       "      <td>am</td>\n",
       "      <td>County</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>887868.0</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Increment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2744 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Concept_ID Metric_ID                          Metric_name Submetric  \\\n",
       "0     BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "1     BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "2     BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "3     BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.1   \n",
       "4     BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.2   \n",
       "...            ...       ...                                  ...       ...   \n",
       "2739  BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "2740  BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "2741  BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "2742  BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "2743  BaseYear2015      B1.1  Jobs accessible from peoples’ homes    B1.1.5   \n",
       "\n",
       "                                      Description           Population Period  \\\n",
       "0        Jobs accessible within actual 30 minutes     Whole Population     am   \n",
       "1        Jobs accessible within actual 45 minutes     Whole Population     am   \n",
       "2        Jobs accessible within actual 60 minutes     Whole Population     am   \n",
       "3        Jobs accessible within actual 90 minutes     Whole Population     am   \n",
       "4        Jobs accessible within actual 30 minutes  Priority population     am   \n",
       "...                                           ...                  ...    ...   \n",
       "2739  Jobs accessible within perceived 90 minutes     Whole Population     am   \n",
       "2740  Jobs accessible within perceived 90 minutes     Whole Population     am   \n",
       "2741  Jobs accessible within perceived 90 minutes     Whole Population     am   \n",
       "2742  Jobs accessible within perceived 90 minutes     Whole Population     am   \n",
       "2743  Jobs accessible within perceived 90 minutes     Whole Population     am   \n",
       "\n",
       "           Geography     Zone_ID Origin_zone Dest_zone Purpose     Value  \\\n",
       "0     Regional total  Megaregion                                179488.0   \n",
       "1     Regional total  Megaregion                                281058.0   \n",
       "2     Regional total  Megaregion                                439633.0   \n",
       "3     Regional total  Megaregion                                878916.0   \n",
       "4     Regional total  Megaregion                                154545.0   \n",
       "...              ...         ...         ...       ...     ...       ...   \n",
       "2739          County           5                                928747.0   \n",
       "2740          County           6                                983984.0   \n",
       "2741          County           7                                974328.0   \n",
       "2742          County           8                                930812.0   \n",
       "2743          County           9                                887868.0   \n",
       "\n",
       "     Units Total_Increment  \n",
       "0     Jobs           Total  \n",
       "1     Jobs           Total  \n",
       "2     Jobs           Total  \n",
       "3     Jobs           Total  \n",
       "4     Jobs       Increment  \n",
       "...    ...             ...  \n",
       "2739  Jobs       Increment  \n",
       "2740  Jobs       Increment  \n",
       "2741  Jobs       Increment  \n",
       "2742  Jobs       Increment  \n",
       "2743  Jobs       Increment  \n",
       "\n",
       "[2744 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd75f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_work_destionations(all_tod_tt, time_periods, time_thresholds, geo_pp_cwks, non_work_dest_tazs, tt_verbose):\n",
    "\n",
    "    acc_jobs = []\n",
    "    df = []\n",
    "    nwd_acc_min = []\n",
    "    nwd_jobs_pp = []\n",
    "    nwd_jobs_rdm = []\n",
    "    nwd_jobs_sd = []\n",
    "    nwd_jobs_cnty = []\n",
    "    \n",
    "    for period in time_periods:\n",
    "        \n",
    "        if period in all_tod_tt.columns:\n",
    "\n",
    "            timedaData = all_tod_tt[[period]].reset_index()\n",
    "            print(timedaData.columns)\n",
    "            timedaData = timedaData.fillna(0)\n",
    "            timedaData = timedaData.loc[timedaData[period]>0]\n",
    "            timedaData[period] = timedaData[period]/100\n",
    "\n",
    "            #total non work destinations based on destination\n",
    "            od_data = pd.merge(timedaData, non_work_dest_tazs, left_on='dest', right_on='taz', how = 'inner')\n",
    "            od_data.isna().sum()\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                # print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[period] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['non_work_dest'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataPop, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_pop'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP']\n",
    "                nwd_acc_min = oddata_min['wt_pop'].sum()/oddata_min['non_work_dest'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "\n",
    "                df_temp_region = pd.DataFrame({'Description': \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\",\n",
    "                                               'Population': 'Whole Population',\n",
    "                                               'Period': period,\n",
    "                                               'Geography': 'Regional total',\n",
    "                                               'Zone_ID': 'Megaregion',\n",
    "                                               'Submetric': 'B1.3.1',\n",
    "                                               'Total_Increment': 'Total',\n",
    "                                               'Value': nwd_acc_min}, index=[0])\n",
    "                \n",
    "                \n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "\n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_pop_pp'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['pop_pp'] = oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_pop_pp','pop_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['Value'] = oddata_min_pp['wt_pop_pp']/oddata_min_pp['pop_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_nonpp['Value'] = oddata_min_nonpp['wt_pop']/oddata_min_nonpp['TOTPOP']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'Value']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb = oddata_min_comb.loc[oddata_min_comb['priority_population'] == 1]\n",
    "                    oddata_min_comb = oddata_min_comb.drop(columns=['priority_population'])\n",
    "                    oddata_min_comb['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_comb['Period'] = period\n",
    "                    oddata_min_comb['Population'] = 'Priority population'\n",
    "                    oddata_min_comb['Geography'] = 'Regional total'\n",
    "                    oddata_min_comb['Zone_ID'] = 'Megaregion'\n",
    "                    oddata_min_comb = oddata_min_comb[['Description', 'Population', 'Period', \n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_comb['Submetric'] = 'B1.3.2'\n",
    "                    oddata_min_comb['Total_Increment'] = 'Increment'\n",
    "                    nwd_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_rdm['Value'] =  oddata_min_rdm['wt_pop']/oddata_min_rdm['TOTPOP']\n",
    "                    oddata_min_rdm['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_rdm['Period'] = period\n",
    "                    oddata_min_rdm['Geography'] = 'RDM'\n",
    "                    oddata_min_rdm['Population'] = 'Whole Population'\n",
    "                    oddata_min_rdm.rename(columns={'rdm_zones' : 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_rdm = oddata_min_rdm[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_rdm['Submetric'] = 'B1.3.3'\n",
    "                    oddata_min_rdm['Total_Increment'] = 'Increment'\n",
    "                    nwd_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_sd['Value'] =  oddata_min_sd['wt_pop']/oddata_min_sd['TOTPOP']\n",
    "                    oddata_min_sd['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_sd['Period'] = period\n",
    "                    oddata_min_sd['Population'] = 'Whole Population'\n",
    "                    oddata_min_sd['Geography'] = 'Superdistrict'\n",
    "                    oddata_min_sd.rename(columns={'super_district': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_sd = oddata_min_sd[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]\n",
    "                    oddata_min_sd['Submetric'] = 'B1.3.4'\n",
    "                    oddata_min_sd['Total_Increment'] = 'Increment'\n",
    "                    nwd_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_cnty['Value'] =  oddata_min_cnty['wt_pop']/oddata_min_cnty['TOTPOP']\n",
    "                    oddata_min_cnty['Description'] = \"Non-work destinations accessible within \" + tt_verbose + \" \" + str(threshold) + \" minutes\"\n",
    "                    oddata_min_cnty['Period'] = period\n",
    "                    oddata_min_cnty['Geography'] = 'County'\n",
    "                    oddata_min_cnty['Population'] = 'Whole Population'\n",
    "                    oddata_min_cnty.rename(columns={'county': 'Zone_ID'}, inplace=True)\n",
    "                    oddata_min_cnty = oddata_min_cnty[['Description', 'Population', 'Period',\n",
    "                                                     'Geography', 'Zone_ID', 'Value']]   \n",
    "                    oddata_min_cnty['Submetric'] = 'B1.3.5'\n",
    "                    oddata_min_cnty['Total_Increment'] = 'Increment'\n",
    "                    nwd_jobs_cnty.append(oddata_min_cnty)\n",
    "                        \n",
    "        else:\n",
    "            print(f'{period} travel time doesn\\'t exist.')\n",
    "            \n",
    "    df_region = pd.concat(df).reset_index(drop=True)\n",
    "    df_pp = pd.concat(nwd_jobs_pp).reset_index(drop=True)\n",
    "    df_rdm = pd.concat(nwd_jobs_rdm).reset_index(drop=True)\n",
    "    df_sd = pd.concat(nwd_jobs_sd).reset_index(drop=True)\n",
    "    df_cnty = pd.concat(nwd_jobs_cnty).reset_index(drop=True)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ace19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig', 'dest', 'am'], dtype='object', name='tp')\n",
      "md travel time doesn't exist.\n",
      "pm travel time doesn't exist.\n",
      "ev travel time doesn't exist.\n",
      "ea travel time doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_non_work_destionations(all_tod_tt, time_periods, time_thresholds,\n",
    "                                                                      geo_pp_cwks, non_work_tazs, \"actual\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.3'\n",
    "comb_df['Metric_name'] = 'Non-work destinations accessible from people\\'s homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Destinations'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_nwd_act = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a7c865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig', 'dest', 'am'], dtype='object', name='tp')\n",
      "md travel time doesn't exist.\n",
      "pm travel time doesn't exist.\n",
      "ev travel time doesn't exist.\n",
      "ea travel time doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "df_region, df_pp, df_rdm, df_sd, df_cnty = get_non_work_destionations(perc_tod_tt, time_periods, time_thresholds,\n",
    "                                                                      geo_pp_cwks, non_work_tazs, \"perceived\")\n",
    "\n",
    "comb_df = pd.concat([df_region, df_pp, df_rdm, df_sd, df_cnty], ignore_index=True)\n",
    "\n",
    "comb_df['Concept_ID'] = concept_id\n",
    "comb_df['Metric_ID'] = 'B1.3'\n",
    "comb_df['Metric_name'] = 'Non-work destinations accessible from people\\'s homes'\n",
    "comb_df['Origin_zone'] = ''\n",
    "comb_df['Dest_zone'] = ''\n",
    "comb_df['Purpose'] = ''\n",
    "comb_df['Units'] = 'Destinations'\n",
    "comb_df['Value'] = comb_df['Value'].apply(lambda x: round(x, decimals))\n",
    "\n",
    "comb_df_nwd_perc = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3087a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df_nwd = pd.concat([comb_df_nwd_act, comb_df_nwd_perc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d87b8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comb_df = pd.concat([comb_df_acc, comb_df_nwd], ignore_index=True)\n",
    "#comb_df = comb_df[summary_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5282af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(summary_outputs, 'concept-BY15.xlsx'), engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    comb_df_acc.to_excel(writer, sheet_name='B1.1', startcol=0, index=False)\n",
    "    comb_df_nwd.to_excel(writer, sheet_name='B1.3', startcol=0, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5fe1f",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d55e183",
   "metadata": {},
   "source": [
    "def get_accessibility_jobs(transit_skim_files, mat_core, geo_pp_cwks, non_work_dest_tazs):\n",
    "\n",
    "    acc_jobs = []\n",
    "    acc_jobs_nwd = []\n",
    "    df = []\n",
    "    acc_jobs_pp = []\n",
    "    acc_jobs_rdm = []\n",
    "    acc_jobs_sd = []\n",
    "    acc_jobs_cnty = []\n",
    "    \n",
    "    #for 25 transit skims files - this includes time periods\n",
    "    for transit_file in transit_skim_files:\n",
    "        \n",
    "        transit_file_name = os.path.split(transit_file)[-1]\n",
    "        \n",
    "        for core in mat_core:\n",
    "            # od data from skims\n",
    "            timedaData = convertMat2Df(transit_file, core)\n",
    "            timedaData = timedaData.loc[timedaData[core]>0]\n",
    "            timedaData[core] = timedaData[core]/100\n",
    "              \n",
    "            #total employment based on destination\n",
    "            od_data = pd.merge(timedaData, tazDataTotemp, left_on='dest', right_on='ZONE', how = 'left')\n",
    "            od_data.columns\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[core] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['TOTEMP'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataEmpres, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_empres'] = oddata_min['TOTEMP'] * oddata_min['EMPRES']\n",
    "                job_acc_min = oddata_min['wt_empres'].sum()/oddata_min['EMPRES'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "                \n",
    "                df_temp_region = pd.DataFrame({'transit_file': os.path.split(transit_file)[-1], 'time_threshold': threshold, 'jobs_from_home': job_acc_min, 'time': core}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "                \n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_empres_pp'] = oddata_min['TOTEMP'] * oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['EMPRES_pp'] = oddata_min['EMPRES'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_empres_pp','EMPRES_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['jobs_from_home'] = oddata_min_pp['wt_empres_pp']/oddata_min_pp['EMPRES_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'jobs_from_home']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_nonpp['jobs_from_home'] = oddata_min_nonpp['wt_empres']/oddata_min_nonpp['EMPRES']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'jobs_from_home']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb['time_threshold'] = threshold\n",
    "                    oddata_min_comb['transit_file'] = transit_file_name\n",
    "                    oddata_min_comb['time'] = core\n",
    "                    acc_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_rdm['jobs_from_home'] =  oddata_min_rdm['wt_empres']/oddata_min_rdm['EMPRES']\n",
    "                    oddata_min_rdm['time_threshold'] = threshold\n",
    "                    oddata_min_rdm['transit_file'] = transit_file_name\n",
    "                    oddata_min_rdm['time'] = core\n",
    "                    oddata_min_rdm = oddata_min_rdm[['rdm_zones', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_sd['jobs_from_home'] =  oddata_min_sd['wt_empres']/oddata_min_sd['EMPRES']\n",
    "                    oddata_min_sd['time_threshold'] = threshold\n",
    "                    oddata_min_sd['transit_file'] = transit_file_name\n",
    "                    oddata_min_sd['time'] = core\n",
    "                    oddata_min_sd = oddata_min_sd[['super_district', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_empres','EMPRES'].sum().reset_index()\n",
    "                    oddata_min_cnty['jobs_from_home'] =  oddata_min_cnty['wt_empres']/oddata_min_cnty['EMPRES']\n",
    "                    oddata_min_cnty['time_threshold'] = threshold\n",
    "                    oddata_min_cnty['transit_file'] = transit_file_name\n",
    "                    oddata_min_cnty['time'] = core\n",
    "                    oddata_min_cnty = oddata_min_cnty[['county', 'jobs_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    acc_jobs_cnty.append(oddata_min_cnty)\n",
    "            \n",
    "    df_region = pd.concat(df)\n",
    "    df_pp = pd.concat(acc_jobs_pp)\n",
    "    df_rdm = pd.concat(acc_jobs_rdm)\n",
    "    df_sd = pd.concat(acc_jobs_sd)\n",
    "    df_cnty = pd.concat(acc_jobs_cnty)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a58c34",
   "metadata": {},
   "source": [
    "def get_non_work_destionations(transit_skim_files, mat_core, geo_pp_cwks, non_work_dest_tazs):\n",
    "\n",
    "    acc_jobs = []\n",
    "    nwd_jobs_nwd = []\n",
    "    df = []\n",
    "    nwd_jobs_pp = []\n",
    "    nwd_jobs_rdm = []\n",
    "    nwd_jobs_sd = []\n",
    "    nwd_jobs_cnty = []\n",
    "    \n",
    "    \n",
    "    #for 25 transit skims files - this includes time periods\n",
    "    for transit_file in transit_skim_files:\n",
    "        \n",
    "        transit_file_name = os.path.split(transit_file)[-1]\n",
    "        \n",
    "        for core in mat_core:\n",
    "            # od data from skims\n",
    "            timedaData = convertMat2Df(transit_file, core)\n",
    "            timedaData = timedaData.loc[timedaData[core]>0]\n",
    "            timedaData[core] = timedaData[core]/100\n",
    "\n",
    "            #total non work destinations based on destination\n",
    "            od_data = pd.merge(timedaData, non_work_dest_tazs, left_on='dest', right_on='taz', how = 'inner')\n",
    "            od_data.isna().sum()\n",
    "\n",
    "            #for time thresholds - currently set in config files\n",
    "            for threshold in time_thresholds:\n",
    "                print(f'processing {transit_file} for time threshold {threshold}')\n",
    "                # create data for all destinations\n",
    "                oddata_min = od_data.loc[od_data[core] <= threshold]\n",
    "                oddata_min = oddata_min.groupby(['orig'])['non_work_dest'].sum().reset_index()\n",
    "\n",
    "                # adding employed residents\n",
    "                oddata_min = pd.merge(oddata_min, tazDataPop, left_on= ['orig'], right_on =['ZONE'], how ='left')\n",
    "\n",
    "                # regional \n",
    "                oddata_min['wt_pop'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP']\n",
    "                nwd_acc_min = oddata_min['wt_pop'].sum()/oddata_min['non_work_dest'].sum()\n",
    "                #acc_jobs.append(job_acc_min)\n",
    "                \n",
    "                df_temp_region = pd.DataFrame({'transit_file': os.path.split(transit_file)[-1], 'time_threshold': threshold, 'nwd_from_home': nwd_acc_min, 'time': core}, index=[0])\n",
    "                df.append(df_temp_region)\n",
    "\n",
    "                # adding priority population and geographies\n",
    "                oddata_min = pd.merge(oddata_min, geo_pp_cwks, left_on= ['orig'], right_on =['taz'], how ='left')\n",
    "                \n",
    "                # for prioirty population\n",
    "                if 'pp_share' in geo_pp_cwks.columns:\n",
    "                    oddata_min['priority_population'] = oddata_min['pp_share'].apply(lambda x: 1 if x > 0 else 0)\n",
    "                    oddata_min['wt_pop_pp'] = oddata_min['non_work_dest'] * oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min['pop_pp'] = oddata_min['TOTPOP'] * oddata_min['pp_share']/100\n",
    "                    oddata_min_pp = oddata_min[oddata_min['priority_population']==1]\n",
    "                    oddata_min_nonpp = oddata_min[oddata_min['priority_population']==0]\n",
    "                    oddata_min_pp = oddata_min_pp.groupby(['priority_population'])['wt_pop_pp','pop_pp'].sum().reset_index()\n",
    "                    oddata_min_pp['nwd_from_home'] = oddata_min_pp['wt_pop_pp']/oddata_min_pp['pop_pp']\n",
    "                    oddata_min_pp = oddata_min_pp[['priority_population', 'nwd_from_home']]\n",
    "\n",
    "                    oddata_min_nonpp = oddata_min_nonpp.groupby(['priority_population'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_nonpp['nwd_from_home'] = oddata_min_nonpp['wt_pop']/oddata_min_nonpp['TOTPOP']\n",
    "                    oddata_min_nonpp = oddata_min_nonpp[['priority_population', 'nwd_from_home']]\n",
    "\n",
    "                    oddata_min_comb = pd.concat([oddata_min_pp, oddata_min_nonpp], ignore_index=False)\n",
    "                    oddata_min_comb['time_threshold'] = threshold\n",
    "                    oddata_min_comb['transit_file'] = transit_file_name\n",
    "                    oddata_min_comb['time'] = core\n",
    "                    nwd_jobs_pp.append(oddata_min_comb)\n",
    "\n",
    "                # for RDM zones\n",
    "                if 'rdm_zones' in geo_pp_cwks.columns:\n",
    "                    oddata_min_rdm = oddata_min.groupby(['rdm_zones'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_rdm['nwd_from_home'] =  oddata_min_rdm['wt_pop']/oddata_min_rdm['TOTPOP']\n",
    "                    oddata_min_rdm['time_threshold'] = threshold\n",
    "                    oddata_min_rdm['transit_file'] = transit_file_name\n",
    "                    oddata_min_rdm['time'] = core\n",
    "                    oddata_min_rdm = oddata_min_rdm[['rdm_zones', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_rdm.append(oddata_min_rdm)\n",
    "\n",
    "                # for superdistrict\n",
    "                if 'super_district' in geo_pp_cwks.columns:\n",
    "                    oddata_min_sd = oddata_min.groupby(['super_district'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_sd['nwd_from_home'] =  oddata_min_sd['wt_pop']/oddata_min_sd['TOTPOP']\n",
    "                    oddata_min_sd['time_threshold'] = threshold\n",
    "                    oddata_min_sd['transit_file'] = transit_file_name\n",
    "                    oddata_min_sd['time'] = core\n",
    "                    oddata_min_sd = oddata_min_sd[['super_district', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_sd.append(oddata_min_sd)\n",
    "\n",
    "                # for county\n",
    "                if 'county' in geo_pp_cwks.columns:\n",
    "                    oddata_min_cnty = oddata_min.groupby(['county'])['wt_pop','TOTPOP'].sum().reset_index()\n",
    "                    oddata_min_cnty['nwd_from_home'] =  oddata_min_cnty['wt_pop']/oddata_min_cnty['TOTPOP']\n",
    "                    oddata_min_cnty['time_threshold'] = threshold\n",
    "                    oddata_min_cnty['transit_file'] = transit_file_name\n",
    "                    oddata_min_cnty['time'] = core\n",
    "                    oddata_min_cnty = oddata_min_cnty[['county', 'nwd_from_home', 'time_threshold', 'transit_file', 'time']] \n",
    "                    nwd_jobs_cnty.append(oddata_min_cnty)\n",
    "            \n",
    "    df_region = pd.concat(df)\n",
    "    df_pp = pd.concat(nwd_jobs_pp)\n",
    "    df_rdm = pd.concat(nwd_jobs_rdm)\n",
    "    df_sd = pd.concat(nwd_jobs_sd)\n",
    "    df_cnty = pd.concat(nwd_jobs_cnty)\n",
    "    \n",
    "    return df_region, df_pp, df_rdm, df_sd, df_cnty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
