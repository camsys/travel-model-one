{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8eb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmatrix as omx\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "from utility import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ecc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "summary_outputs = params['summary_dir']\n",
    "concept_id = params['concept_id']\n",
    "ctramp_dir = params['ctramp_dir']\n",
    "iteration = params['iteration']\n",
    "model_year=params['model_year']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "time_period_mapping = params['time_periods_mapping']\n",
    "link21_purp_mapping = params['purpose_mapping']\n",
    "mode_cat_mapping = params['mode_mapping']\n",
    "time_periods = params['periods']\n",
    "acc_egg_modes = params['access_egress_modes']\n",
    "\n",
    "preprocess_dir = _join(ctramp_dir, '_pre_process_files')\n",
    "summary_dir = params['summary_dir']\n",
    "\n",
    "filename_extension = params['filename_extension']\n",
    "perf_measure_columns = params['final_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs of CT-RAMP model for tour and trip file\n",
    "household_model_dir = _join(model_outputs_dir, \"main\")\n",
    "\n",
    "# input household and person data\n",
    "#person_file = _join(ctramp_dir, 'main\\\\personData_' + str(iteration) + '.csv')\n",
    "#household_file = _join(ctramp_dir, 'main\\\\householdData_' + str(iteration) + '.csv')\n",
    "\n",
    "#person = pd.read_csv(person_file)\n",
    "\n",
    "#hh = pd.read_csv(household_file, usecols = ['hh_id', 'taz'])\n",
    "#hh = hh.rename(columns = {'taz': 'home_zone'})\n",
    "\n",
    "#taz to RDM zones, super districts, county\n",
    "geo_cwks = pd.read_csv(_join(params['common_dir'], \"geographies.csv\")) #columns taz, rdm_zones, super_district, county\n",
    "\n",
    "#taz to priority population\n",
    "pp_perc = pd.read_excel(_join(params['common_dir'], \"TAZ_Tract_cwk_summary.xlsx\")) #columns = taz, pp_share \n",
    "\n",
    "# transbay od pairs\n",
    "#transbay_od = pd.read_csv(_join(params['common_dir'], \"transbay_od.csv\")) #columns = transbay_o, transbay_d\n",
    "\n",
    "demand_matrices_dir = _join(model_outputs_dir, \"demand_matrices\")\n",
    "transit_demand_dir = _join(demand_matrices_dir, \"transit\")\n",
    "transit_skims_dir = _join(skims_dir, \"transit\")\n",
    "best_path_skim_dir = params['best_path_skim_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trips = create_trip_roster(ctramp_dir, transbay_od, geo_cwks, link21_purp_mapping)\n",
    "#df_trn = df_trips.loc[df_trips['trip_mode'].isin([6,7,8])]\n",
    "\n",
    "#df_trn['Period'] = df_trn['depart_hour'].map(time_period_mapping)\n",
    "#df_trn['Mode'] = df_trn['trip_mode'].map(mode_cat_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef60825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_trips = pd.read_parquet(_join(preprocess_dir, 'trip_roster.parquet'))\n",
    "all_trips = pd.read_parquet(_join(preprocess_dir, 'trip_roster_'+str(model_year)+'_Baseline_R2_Run5.parquet'))\n",
    "all_trips.columns\n",
    "df_trn = all_trips.loc[all_trips['trip_mode'].isin([6,7,8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5265f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#time_periods = ['AM']\n",
    "df_temp = []\n",
    "\n",
    "for period in time_periods:\n",
    "    print(f'processing - {period}')\n",
    "    \n",
    "    df_trn_pd = df_trn[df_trn['Period'] == period.lower()]\n",
    "    df_trn_wlk = df_trn_pd[df_trn_pd['Mode'] == 'WALK_TRANSIT']\n",
    "    df_trn_pnr = df_trn_pd[df_trn_pd['Mode'] == 'PNR_TRANSIT']\n",
    "    df_trn_knr = df_trn_pd[df_trn_pd['Mode'] == 'KNR_TRANSIT']\n",
    "    \n",
    "    #for acc_egg in acc_egg_modes:\n",
    "    #for Walk transit Walk\n",
    "    df_skm_wk = pd.read_parquet(_join(preprocess_dir, period.lower() +'_WLK_TRN_WLK' + '_cores.parquet'))\n",
    "    \n",
    "    \n",
    "    df_skm_wk = df_skm_wk.loc[df_skm_wk['ivt']>0]\n",
    "\n",
    "\n",
    "    df_wlk = pd.merge(df_trn_wlk, df_skm_wk, \n",
    "                          left_on =['orig_taz', 'dest_taz'], \n",
    "                          right_on=['orig', 'dest'], \n",
    "                          how ='inner')\n",
    "\n",
    "    # PNR Transit\n",
    "    df_skm_pnr_ib = pd.read_parquet(_join(preprocess_dir, period.lower() +'_WLK_TRN_PNR' + '_cores.parquet'))\n",
    "    df_skm_pnr_ib = df_skm_pnr_ib[df_skm_pnr_ib['ivt']>0]\n",
    "\n",
    "    df_skm_pnr_ob = pd.read_parquet(_join(preprocess_dir, period.lower() +'_PNR_TRN_WLK' + '_cores.parquet')) \n",
    "    df_skm_pnr_ob = df_skm_pnr_ob[df_skm_pnr_ob['ivt']>0]\n",
    "\n",
    "    df_trn_pnr_ib = df_trn_pnr[df_trn_pnr['inbound'] == 1] # returning home\n",
    "    df_trn_pnr_ib = pd.merge(df_trn_pnr_ib, df_skm_pnr_ib, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_trn_pnr_ob = df_trn_pnr[df_trn_pnr['inbound'] != 1] # returning home\n",
    "    df_trn_pnr_ob = pd.merge(df_trn_pnr_ob, df_skm_pnr_ob, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_pnr = pd.concat([df_trn_pnr_ib, df_trn_pnr_ob], ignore_index=True)\n",
    "\n",
    "        # KNR Transit\n",
    "    df_skm_knr_ib = pd.read_parquet(_join(preprocess_dir, period.lower() +'_WLK_TRN_KNR' + '_cores.parquet'))\n",
    "    df_skm_knr_ib = df_skm_pnr_ib[df_skm_pnr_ib['ivt']>0]\n",
    "\n",
    "    df_skm_knr_ob = pd.read_parquet(_join(preprocess_dir, period.lower() +'_KNR_TRN_WLK' + '_cores.parquet')) \n",
    "    df_skm_knr_ob = df_skm_knr_ob[df_skm_knr_ob['ivt']>0]\n",
    "\n",
    "    df_trn_knr_ib = df_trn_knr[df_trn_knr['inbound'] == 1] # returning home\n",
    "    df_trn_knr_ib = pd.merge(df_trn_knr_ib, df_skm_knr_ib, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_trn_knr_ob = df_trn_knr[df_trn_knr['inbound'] != 1] # returning home\n",
    "    df_trn_knr_ob = pd.merge(df_trn_knr_ob, df_skm_knr_ob, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_knr = pd.concat([df_trn_knr_ib, df_trn_knr_ob], ignore_index=True)\n",
    "\n",
    "    df_trn_rail = pd.concat([df_wlk, df_pnr, df_knr], ignore_index=True)\n",
    "    df_temp.append(df_trn_rail)\n",
    "    \n",
    "\n",
    "df_trn_rail = pd.concat(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af0ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn_rail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75595f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn_rail.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a070c0",
   "metadata": {},
   "source": [
    "# summarise for prioirty population\n",
    "summary_cols = params['description_a1.2']\n",
    "\n",
    "time_periods = ['AM']\n",
    "\n",
    "\n",
    "pp_df = []\n",
    "reg_df = []\n",
    "county_df = []\n",
    "sd_df = []\n",
    "tb_df = []\n",
    "rdm_df = []\n",
    "\n",
    "\n",
    "for columns in summary_cols:\n",
    "    \n",
    "    for period in time_periods:\n",
    "    \n",
    "        df_temp = df_trn_rail[(df_trn_rail[columns] > 0) & (df_trn_rail['Period'] == period.lower())]\n",
    "        \n",
    "        #regional value\n",
    "        region_value = df_temp[columns].mean()\n",
    "        reg_df_temp = pd.DataFrame({'Population': 'Whole Population',\n",
    "                              'Period': period,\n",
    "                              'Value': region_value,\n",
    "                              'Orig_zone' : '',\n",
    "                              'Dest_zone' : '',\n",
    "                              'Zone_ID' : 'Megaregion',\n",
    "                              'Geography' : 'Regional',\n",
    "                              'Metric':summary_cols[columns][1],\n",
    "                              'Submetric':summary_cols[columns][1]+'.1',\n",
    "                              'Description' : summary_cols[columns][0],\n",
    "                              'Units' : summary_cols[columns][2],\n",
    "                              'Metric_name' : summary_cols[columns][3]}, index=[0])\n",
    "        reg_df.append(reg_df_temp)\n",
    "        \n",
    "        # transbay region\n",
    "        tb_value = df_temp[df_temp['transbay_od']==1]\n",
    "        tb_value = tb_value[columns].mean()\n",
    "        \n",
    "        tb_df_temp = pd.DataFrame({'Population': 'Whole Population',\n",
    "                                   'Period': period,\n",
    "                                   'Value': tb_value,\n",
    "                                   'Orig_zone' : '',\n",
    "                                   'Dest_zone' : '',\n",
    "                                   'Zone_ID' : 'Megaregion',\n",
    "                                   'Geography' : 'Transbay',\n",
    "                                   'Metric':summary_cols[columns][1],\n",
    "                                   'Submetric':summary_cols[columns][1]+'.6',\n",
    "                                   'Description' : summary_cols[columns][0],\n",
    "                                   'Units' : summary_cols[columns][2],\n",
    "                                   'Metric_name' : summary_cols[columns][3]}, index=[0])\n",
    "                                    \n",
    "        tb_df.append(tb_df_temp)  \n",
    "                \n",
    "        #county \n",
    "        county_df_temp = df_temp.groupby(['orig_county', 'dest_county'])[columns].mean().reset_index()\n",
    "        county_df_temp = rename_columns(county_df_temp, ['orig_county', 'dest_county', columns])\n",
    "        \n",
    "        county_df_temp['Period'] = period\n",
    "        county_df_temp['Population'] = 'Whole Population'\n",
    "        county_df_temp['Zone_Id'] = ''\n",
    "        county_df_temp['Geography'] = 'County'\n",
    "        county_df_temp['Description'] = summary_cols[columns][0]\n",
    "        county_df_temp['Metric'] = summary_cols[columns][1]\n",
    "        county_df_temp['Submetric'] = summary_cols[columns][1]+'.5'\n",
    "        county_df_temp['Units'] = summary_cols[columns][2]\n",
    "        county_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "        county_df.append(county_df_temp)\n",
    "        \n",
    "        #RDM Zones\n",
    "        rdm_df_temp = df_temp.groupby(['orig_rdm_zones', 'dest_rdm_zones'])[columns].mean().reset_index()\n",
    "        rdm_df_temp =  rename_columns(rdm_df_temp, ['orig_rdm_zones', 'dest_rdm_zones', columns])\n",
    "        \n",
    "        rdm_df_temp['Period'] = period\n",
    "        rdm_df_temp['Population'] = 'Whole Population'\n",
    "        rdm_df_temp['Zone_ID'] = ''\n",
    "        rdm_df_temp['Geography'] = 'RDM'\n",
    "        rdm_df_temp['Description'] = summary_cols[columns][0]     \n",
    "        rdm_df_temp['Metric'] = summary_cols[columns][1]\n",
    "        rdm_df_temp['Submetric'] = summary_cols[columns][1]+'.3'\n",
    "        rdm_df_temp['Units'] = summary_cols[columns][2]\n",
    "        rdm_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "        rdm_df.append(rdm_df_temp)\n",
    "        \n",
    "        #super district\n",
    "        sd_df_temp = df_temp.groupby(['orig_super_dist', 'dest_super_dist'])[columns].mean().reset_index()\n",
    "        sd_df_temp = rename_columns(sd_df_temp, ['orig_super_dist', 'dest_super_dist', columns])\n",
    "        \n",
    "        sd_df_temp['Period'] = period\n",
    "        sd_df_temp['Population'] = 'Whole Population'\n",
    "        sd_df_temp['Zone_ID'] = ''\n",
    "        sd_df_temp['Geography'] = 'Superdistrict'\n",
    "        sd_df_temp['Description'] = summary_cols[columns][0]\n",
    "        sd_df_temp['Metric'] = summary_cols[columns][1]\n",
    "        sd_df_temp['Submetric'] = summary_cols[columns][1]+'.4'\n",
    "        sd_df_temp['Units'] = summary_cols[columns][2]\n",
    "        sd_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "        sd_df.append(sd_df_temp)\n",
    "                \n",
    "        #prioirty population\n",
    "        df_temp['pp_share'] = df_temp['pp_share']/100\n",
    "        pp_value = weighted_average(df_temp, 'ivt', 'pp_share')\n",
    "        pp_df_temp = pd.DataFrame({'Population': 'Prioirty Population',\n",
    "                              'Period': period,\n",
    "                              'Value': pp_value,\n",
    "                              'Orig_zone' : '',\n",
    "                              'Dest_zone' : '',\n",
    "                              'Zone_ID' : 'Megaregion',\n",
    "                              'Geography' : 'Regional',\n",
    "                              'Metric':summary_cols[columns][1],\n",
    "                              'Submetric':summary_cols[columns][1]+'.2',\n",
    "                              'Description' : summary_cols[columns][0],\n",
    "                              'Units' : summary_cols[columns][2],\n",
    "                              'Metric_name' : summary_cols[columns][3]}, index=[0])\n",
    "        pp_df.append(pp_df_temp)\n",
    "    \n",
    "    \n",
    "pp_df = pd.concat(pp_df)\n",
    "reg_df = pd.concat(reg_df)\n",
    "county_df = pd.concat(county_df)\n",
    "sd_df = pd.concat(sd_df)\n",
    "rdm_df = pd.concat(rdm_df)\n",
    "tb_df = pd.concat(tb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2674bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols = params['description_a1.2']\n",
    "summary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efdb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_periods = ['AM']\n",
    "\n",
    "\n",
    "pp_df = []\n",
    "reg_df = []\n",
    "county_df = []\n",
    "sd_df = []\n",
    "tb_df = []\n",
    "rdm_df = []\n",
    "\n",
    "\n",
    "for columns in summary_cols:\n",
    "    \n",
    "    #for period in time_periods:\n",
    "    print(columns)\n",
    "    df_temp = df_trn_rail[(df_trn_rail[columns] > 0)]\n",
    "    df_temp[columns+'_trips'] = (df_temp[columns] * df_temp['trips'])/100\n",
    "\n",
    "    #regional value\n",
    "    reg_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    reg_df_temp1 = reg_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    reg_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    reg_df_temp2 = reg_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    \n",
    "    #reg_df_temp1 = df_temp.groupby(['Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #reg_df_temp2 = df_temp.groupby(['Period'])['trips'].sum().reset_index()\n",
    "    reg_df_temp = pd.merge(reg_df_temp1, reg_df_temp2, on=['Period', 'Income'], how='left')\n",
    "    reg_df_temp[columns] = reg_df_temp[columns+'_trips']/reg_df_temp['trips']\n",
    "    reg_df_temp = reg_df_temp[['Period', 'Income', columns]]\n",
    "    reg_df_temp = reg_df_temp.rename(columns={columns:'Value'})\n",
    "    reg_df_temp['Population'] = 'Whole Population'\n",
    "    reg_df_temp['Origin_zone'] = ''\n",
    "    reg_df_temp['Dest_zone'] = ''\n",
    "    reg_df_temp['Zone_ID'] = ''\n",
    "    reg_df_temp['Concept_ID'] = concept_id\n",
    "    reg_df_temp['Geography'] = 'Regional'\n",
    "    reg_df_temp['Purpose'] = ''\n",
    "    reg_df_temp['Mode'] = ''\n",
    "    reg_df_temp['Total_Increment'] = ''\n",
    "    reg_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    reg_df_temp['Submetric'] = summary_cols[columns][1]+'.1'\n",
    "    reg_df_temp['Description'] = 'Average ' + summary_cols[columns][0]+ ' in the region'\n",
    "    reg_df_temp['Units'] = summary_cols[columns][2]\n",
    "    reg_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #reg_df.append(reg_df_temp)\n",
    "\n",
    "    # transbay region\n",
    "    tb_df_t = df_temp[df_temp['transbay_od']==1]\n",
    "    tb_df_temp = tb_df_t.copy()\n",
    "    tb_df_temp1 = summarize_all_combinations(tb_df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    tb_df_temp1 = tb_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    tb_df_temp2 = summarize_all_combinations(tb_df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    tb_df_temp2 = tb_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    \n",
    "    #tb_df_temp1 = tb_df_temp.groupby(['Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #tb_df_temp2 = tb_df_temp.groupby(['Period'])['trips'].sum().reset_index()\n",
    "    tb_df_temp = pd.merge(tb_df_temp1, tb_df_temp2, on=['Period', 'Income'], how='left')\n",
    "    tb_df_temp[columns] = tb_df_temp[columns+'_trips']/tb_df_temp['trips']\n",
    "    tb_df_temp = tb_df_temp[['Period', 'Income', columns]]\n",
    "    tb_df_temp = tb_df_temp.rename(columns={columns:'Value'})\n",
    "\n",
    "    tb_df_temp['Concept_ID'] = concept_id\n",
    "    tb_df_temp['Population'] = 'Whole Population'\n",
    "    tb_df_temp['Origin_zone'] = ''\n",
    "    tb_df_temp['Dest_zone'] = ''\n",
    "    tb_df_temp['Zone_ID'] = ''\n",
    "    tb_df_temp['Purpose'] = ''\n",
    "    tb_df_temp['Mode'] = ''\n",
    "    tb_df_temp['Geography'] = 'Transbay'\n",
    "    tb_df_temp['Total_Increment'] = ''\n",
    "    tb_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    tb_df_temp['Submetric'] = summary_cols[columns][1]+'.2'\n",
    "    tb_df_temp['Description'] = 'Average' + summary_cols[columns][0] + ' in the transbay region'\n",
    "    tb_df_temp['Units'] = summary_cols[columns][2]\n",
    "    tb_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "\n",
    "    #tb_df.append(tb_df_temp)         \n",
    "\n",
    "    #county \n",
    "    #county_df_temp1 = df_temp.groupby(['orig_county', 'dest_county', 'Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #county_df_temp2 = df_temp.groupby(['orig_county', 'dest_county', 'Period'])['trips'].sum().reset_index()\n",
    "    county_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['orig_county', 'dest_county', 'Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    county_df_temp1 = county_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    county_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['orig_county', 'dest_county', 'Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    county_df_temp2 = county_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    \n",
    "    county_df_temp = pd.merge(county_df_temp1, county_df_temp2, on=['orig_county', 'dest_county', 'Period', 'Income'], how='left')\n",
    "    county_df_temp[columns] = county_df_temp[columns+'_trips']/county_df_temp['trips']\n",
    "    county_df_temp = county_df_temp[['orig_county', 'dest_county', 'Period', 'Income' ,columns]]\n",
    "    county_df_temp = county_df_temp.rename(columns={columns:'Value', \n",
    "                                                    'orig_county': 'Origin_zone',\n",
    "                                                    'dest_county': 'Dest_zone'})\n",
    "    county_df_temp['Population'] = 'Whole Population'\n",
    "    county_df_temp['Zone_ID'] = ''\n",
    "    county_df_temp['Concept_ID'] = concept_id\n",
    "    county_df_temp['Geography'] = 'County'\n",
    "    county_df_temp['Purpose'] = ''\n",
    "    county_df_temp['Mode'] = ''\n",
    "    county_df_temp['Total_Increment'] = ''\n",
    "    county_df_temp['Description'] = 'Average ' + summary_cols[columns][0] + ' in the origin and destination county'\n",
    "    county_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    county_df_temp['Submetric'] = summary_cols[columns][1]+'.3'\n",
    "    county_df_temp['Units'] = summary_cols[columns][2]\n",
    "    county_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #county_df.append(county_df_temp)\n",
    "\n",
    "\n",
    "    #RDM Zones\n",
    "    rdm_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    rdm_df_temp1 = rdm_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    rdm_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    rdm_df_temp2 = rdm_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    #rdm_df_temp1 = df_temp.groupby(['orig_rdm_zones', 'dest_rdm_zones', 'Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #rdm_df_temp2 = df_temp.groupby(['orig_rdm_zones', 'dest_rdm_zones', 'Period'])['trips'].sum().reset_index()\n",
    "    rdm_df_temp = pd.merge(rdm_df_temp1, rdm_df_temp2, on=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], how='left')\n",
    "    rdm_df_temp[columns] = rdm_df_temp[columns+'_trips']/rdm_df_temp['trips']\n",
    "    rdm_df_temp = rdm_df_temp[['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income', columns]]\n",
    "    rdm_df_temp = rdm_df_temp.rename(columns={'orig_rdm_zones': 'Origin_zone', \n",
    "                                              'dest_rdm_zones': 'Dest_zone', \n",
    "                                              columns: 'Value'})\n",
    "\n",
    "    rdm_df_temp['Population'] = 'Whole Population'\n",
    "    rdm_df_temp['Zone_ID'] = ''\n",
    "    rdm_df_temp['Geography'] = 'RDM'\n",
    "    rdm_df_temp['Concept_ID'] = concept_id\n",
    "    rdm_df_temp['Purpose'] = ''\n",
    "    rdm_df_temp['Mode'] = ''\n",
    "    rdm_df_temp['Total_Increment'] = ''\n",
    "    rdm_df_temp['Description'] = summary_cols[columns][0] + ' in the origin and destination RDM zones'  \n",
    "    rdm_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    rdm_df_temp['Submetric'] = summary_cols[columns][1]+'.4'\n",
    "    rdm_df_temp['Units'] = summary_cols[columns][2]\n",
    "    rdm_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #rdm_df.append(rdm_df_temp)\n",
    "\n",
    "        #super district   \n",
    "    sd_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['orig_super_dist', 'dest_super_dist', 'Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    sd_df_temp1 = sd_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    sd_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['orig_super_dist', 'dest_super_dist', 'Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    sd_df_temp2 = sd_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    #sd_df_temp1 = df_temp.groupby(['orig_super_dist', 'dest_super_dist', 'Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #sd_df_temp2 = df_temp.groupby(['orig_super_dist', 'dest_super_dist', 'Period'])['trips'].sum().reset_index()\n",
    "    \n",
    "    sd_df_temp = pd.merge(sd_df_temp1, sd_df_temp2, on=['orig_super_dist', 'dest_super_dist', 'Period', 'Income'], how='left')\n",
    "    sd_df_temp[columns] = sd_df_temp[columns+'_trips']/sd_df_temp['trips']\n",
    "    sd_df_temp = sd_df_temp[['orig_super_dist', 'dest_super_dist', 'Period', 'Income', columns]]\n",
    "    sd_df_temp = sd_df_temp.rename(columns={'orig_super_dist': 'Origin_zone', \n",
    "                                            'dest_super_dist': 'Dest_zone',\n",
    "                                             columns: 'Value'})\n",
    "    sd_df_temp['Population'] = 'Whole Population'\n",
    "    sd_df_temp['Zone_ID'] = ''\n",
    "    sd_df_temp['Concept_ID'] = concept_id\n",
    "    sd_df_temp['Purpose'] = ''\n",
    "    sd_df_temp['Mode'] = ''\n",
    "    sd_df_temp['Total_Increment'] = ''\n",
    "    sd_df_temp['Geography'] = 'Superdistrict'\n",
    "    sd_df_temp['Description'] = summary_cols[columns][0] + ' in the origin and destination Super district'  \n",
    "    sd_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    sd_df_temp['Submetric'] = summary_cols[columns][1]+'.5'\n",
    "    sd_df_temp['Units'] = summary_cols[columns][2]\n",
    "    sd_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #sd_df.append(sd_df_temp)\n",
    "\n",
    "        #prioirty population\n",
    "    df_temp['pp_share'] = df_temp['pp_share']/100\n",
    "    df_temp['pp_trips'] = df_temp['pp_share'] * df_temp['trips']\n",
    "    df_temp['pp_'+columns] = df_temp['pp_trips'] * df_temp[columns] / 100\n",
    "    \n",
    "    pp_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column='pp_'+columns)\n",
    "    pp_df_temp1 = pp_df_temp1.rename(columns={'Value': 'pp_'+columns})\n",
    "    \n",
    "    pp_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column='pp_trips')\n",
    "    pp_df_temp2 = pp_df_temp2.rename(columns={'Value': 'pp_trips'})\n",
    "\n",
    "    #pp_df_temp1 = df_temp.groupby(['Period'])['pp_'+columns].sum().reset_index()\n",
    "    #pp_df_temp2 = df_temp.groupby(['Period'])['pp_trips'].sum().reset_index()\n",
    "    pp_df_temp = pd.merge(pp_df_temp1, pp_df_temp2, on=['Period', 'Income'], how='left')\n",
    "    pp_df_temp[columns] = pp_df_temp['pp_'+columns]/pp_df_temp['pp_trips']\n",
    "    pp_df_temp = pp_df_temp[['Period', 'Income' ,columns]]\n",
    "    pp_df_temp = pp_df_temp.rename(columns={columns:'Value'})\n",
    "\n",
    "    pp_df_temp['Population'] = 'Prioirty Population'\n",
    "    pp_df_temp['Origin_zone'] = ''\n",
    "    pp_df_temp['Dest_zone'] = ''\n",
    "    pp_df_temp['Zone_ID'] = ''\n",
    "    pp_df_temp['Purpose'] = ''\n",
    "    pp_df_temp['Mode'] = ''\n",
    "    pp_df_temp['Concept_ID'] = concept_id\n",
    "    pp_df_temp['Geography'] = 'Region'\n",
    "    pp_df_temp['Total_Increment'] = ''\n",
    "    pp_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    pp_df_temp['Submetric'] = summary_cols[columns][1]+'.6'\n",
    "    pp_df_temp['Description'] = summary_cols[columns][0] + ' in the region'\n",
    "    pp_df_temp['Units'] = summary_cols[columns][2]\n",
    "    pp_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #pp_df.append(pp_df_temp)\n",
    "    \n",
    "    pp_rdm_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                                  summary_column='pp_'+columns)\n",
    "    pp_rdm_df_temp1 = pp_rdm_df_temp1.rename(columns={'Value': 'pp_'+columns})\n",
    "    \n",
    "    pp_rdm_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                                  summary_column='pp_trips')\n",
    "    pp_rdm_df_temp2 = pp_rdm_df_temp2.rename(columns={'Value': 'pp_trips'})\n",
    "    \n",
    "    pp_rdm_df_temp = pd.merge(pp_rdm_df_temp1, pp_rdm_df_temp2, on=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], how='left')\n",
    "    pp_rdm_df_temp[columns] = pp_rdm_df_temp['pp_'+columns]/pp_rdm_df_temp['pp_trips']\n",
    "    pp_rdm_df_temp = pp_rdm_df_temp[['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income', columns]]\n",
    "    pp_rdm_df_temp = pp_rdm_df_temp.rename(columns={columns:'Value'})\n",
    "    \n",
    "    pp_rdm_df_temp['Population'] = 'Prioirty Population'\n",
    "    pp_rdm_df_temp['Origin_zone'] = ''\n",
    "    pp_rdm_df_temp['Dest_zone'] = ''\n",
    "    pp_rdm_df_temp['Zone_ID'] = ''\n",
    "    pp_rdm_df_temp['Purpose'] = ''\n",
    "    pp_rdm_df_temp['Mode'] = ''\n",
    "    pp_rdm_df_temp['Concept_ID'] = concept_id\n",
    "    pp_rdm_df_temp['Geography'] = 'RDM'\n",
    "    pp_rdm_df_temp['Total_Increment'] = ''\n",
    "    pp_rdm_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    pp_rdm_df_temp['Submetric'] = summary_cols[columns][1]+'.7'\n",
    "    pp_rdm_df_temp['Description'] = 'Average ' + summary_cols[columns][0] + ' in the region'\n",
    "    pp_rdm_df_temp['Units'] = summary_cols[columns][2]\n",
    "    pp_rdm_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #pp_df_rdm.append(pp_rdm_df_temp)\n",
    "    \n",
    "    all_dfs = [reg_df_temp, tb_df_temp, county_df_temp, rdm_df_temp, sd_df_temp, pp_df_temp, pp_rdm_df_temp]\n",
    "\n",
    "    for dfs in all_dfs:\n",
    "        metric_name = '_' + summary_cols[columns][3].replace(' ', '_') + '_'\n",
    "        dfs = dfs.reset_index(drop=True)\n",
    "        dfs = dfs[perf_measure_columns]\n",
    "        file_name = dfs['Submetric'][0]\n",
    "        geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "        dfs.to_csv(_join(summary_dir, file_name + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "        print(len(dfs), file_name, dfs['Metric_name'][0])\n",
    "\n",
    "    combined_df = pd.concat([reg_df_temp, tb_df_temp, county_df_temp, rdm_df_temp, df_temp, pp_df_temp]).reset_index(drop=True)\n",
    "    combined_df.to_csv(_join(summary_dir, summary_cols[columns][1] + metric_name + concept_id + '_region' +filename_extension+'.csv'), index=None)\n",
    "       \n",
    "#pp_df = pd.concat(pp_df)\n",
    "#reg_df = pd.concat(reg_df)\n",
    "#county_df = pd.concat(county_df)\n",
    "#sd_df = pd.concat(sd_df)\n",
    "#rdm_df = pd.concat(rdm_df)\n",
    "#tb_df = pd.concat(tb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a508b939",
   "metadata": {},
   "source": [
    "all_dfs = pd.concat([reg_df, tb_df, county_df, rdm_df, sd_df, pp_df], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "unique_metric_ids = all_dfs['Metric_ID'].unique()\n",
    "\n",
    "for mids in unique_metric_ids:\n",
    "    print(mids)\n",
    "    dfs = all_dfs.loc[all_dfs['Metric_ID']==mids]\n",
    "    usbmi = dfs['Submetric'].unique()\n",
    "    \n",
    "    for mi in usbmi:\n",
    "        print(mi)\n",
    "        dfs_temp = dfs.loc[dfs['Submetric'] == mi]\n",
    "        dfs_temp = dfs_temp[perf_measure_columns]\n",
    "        dfs_temp = dfs_temp.reset_index(drop=True)\n",
    "        file_name = mi \n",
    "        metric_name = dfs_temp['Metric_name'][0].replace(' ', '_')\n",
    "        geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "        dfs_temp.to_csv(_join(summary_dir, file_name + '_' + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "        print(len(dfs_temp), file_name, dfs_temp['Metric_name'][0], dfs_temp['Value'].sum())\n",
    "    \n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    file_name = mids \n",
    "    metric_name = dfs['Metric_name'][0]\n",
    "    dfs.to_csv(_join(summary_dir, file_name + metric_name + '_' + concept_id + '_region' + filename_extension +  '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Metric_name'][0], dfs['Value'].sum())\n",
    "    \n",
    "    #'A3.1' + '_weekday_linked_trips_' + concept_id + '_region' +filename_extension+'.csv'\n",
    "    \n",
    "    #metric_name = dfs['Metric_name'][0]\n",
    "    #\n",
    "    #\n",
    "    #dfs.to_csv(_join(summary_dir, metric_name + file_name + filename_extension +  '.csv'), index=None)\n",
    "    #print(len(dfs), file_name, dfs['Metric_name'][0], dfs['Value'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31594c",
   "metadata": {},
   "source": [
    "## B2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa80bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6d8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73555e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
