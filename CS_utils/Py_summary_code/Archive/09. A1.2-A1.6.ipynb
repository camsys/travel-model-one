{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8eb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openmatrix as omx\n",
    "import random\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "from utility import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84ecc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    \n",
    "_join = os.path.join\n",
    "_dir = os.path.dirname\n",
    "_norm = os.path.normpath\n",
    "\n",
    "# paths\n",
    "model_outputs_dir = params['model_dir']\n",
    "skims_dir = _join(model_outputs_dir, \"skims\")\n",
    "summary_outputs = params['summary_dir']\n",
    "concept_id = params['concept_id']\n",
    "ctramp_dir = params['ctramp_dir']\n",
    "iteration = params['iteration']\n",
    "\n",
    "concept_id = params['concept_id']\n",
    "time_period_mapping = params['time_periods_mapping']\n",
    "link21_purp_mapping = params['purpose_mapping']\n",
    "mode_cat_mapping = params['mode_mapping']\n",
    "time_periods = params['periods']\n",
    "acc_egg_modes = params['access_egress_modes']\n",
    "\n",
    "preprocess_dir = _join(ctramp_dir, '_pre_process_files')\n",
    "summary_dir = _join(params['summary_dir'], 'revised_A1')\n",
    "Path(summary_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "filename_extension = params['filename_extension']\n",
    "perf_measure_columns = params['final_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9e742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs of CT-RAMP model for tour and trip file\n",
    "household_model_dir = _join(model_outputs_dir, \"main\")\n",
    "\n",
    "# input household and person data\n",
    "#person_file = _join(ctramp_dir, 'main\\\\personData_' + str(iteration) + '.csv')\n",
    "#household_file = _join(ctramp_dir, 'main\\\\householdData_' + str(iteration) + '.csv')\n",
    "\n",
    "#person = pd.read_csv(person_file)\n",
    "\n",
    "#hh = pd.read_csv(household_file, usecols = ['hh_id', 'taz'])\n",
    "#hh = hh.rename(columns = {'taz': 'home_zone'})\n",
    "\n",
    "#taz to RDM zones, super districts, county\n",
    "geo_cwks = pd.read_csv(_join(params['common_dir'], \"geographies.csv\")) #columns taz, rdm_zones, super_district, county\n",
    "\n",
    "#taz to priority population\n",
    "pp_perc = pd.read_excel(_join(params['common_dir'], \"TAZ_Tract_cwk_summary.xlsx\")) #columns = taz, pp_share \n",
    "\n",
    "# transbay od pairs\n",
    "#transbay_od = pd.read_csv(_join(params['common_dir'], \"transbay_od.csv\")) #columns = transbay_o, transbay_d\n",
    "\n",
    "demand_matrices_dir = _join(model_outputs_dir, \"demand_matrices\")\n",
    "transit_demand_dir = _join(demand_matrices_dir, \"transit\")\n",
    "transit_skims_dir = _join(skims_dir, \"transit\")\n",
    "best_path_skim_dir = params['best_path_skim_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6e892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trips = create_trip_roster(ctramp_dir, transbay_od, geo_cwks, link21_purp_mapping)\n",
    "#df_trn = df_trips.loc[df_trips['trip_mode'].isin([6,7,8])]\n",
    "\n",
    "#df_trn['Period'] = df_trn['depart_hour'].map(time_period_mapping)\n",
    "#df_trn['Mode'] = df_trn['trip_mode'].map(mode_cat_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef60825",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trips = pd.read_parquet(_join(preprocess_dir, 'trip_roster.parquet'))\n",
    "#all_trips = pd.read_parquet(_join(preprocess_dir, 'trip_roster_2050_Baseline_R2_Run4.parquet'))\n",
    "df_trn = all_trips.loc[all_trips['trip_mode'].isin([6,7,8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7491f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5265f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing - am\n",
      "processing - md\n",
      "processing - pm\n",
      "processing - ev\n",
      "processing - ea\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#time_periods = ['AM']\n",
    "df_temp = []\n",
    "\n",
    "for period in time_periods:\n",
    "    print(f'processing - {period}')\n",
    "    \n",
    "    df_trn_pd = df_trn[df_trn['Period'] == period.lower()]\n",
    "    df_trn_wlk = df_trn_pd[df_trn_pd['Mode'] == 'WALK_TRANSIT']\n",
    "    df_trn_pnr = df_trn_pd[df_trn_pd['Mode'] == 'PNR_TRANSIT']\n",
    "    df_trn_knr = df_trn_pd[df_trn_pd['Mode'] == 'KNR_TRANSIT']\n",
    "    \n",
    "    #for acc_egg in acc_egg_modes:\n",
    "    #for Walk transit Walk\n",
    "    df_skm_wk = pd.read_parquet(_join(preprocess_dir, period.lower() +'_WLK_TRN_WLK' + '_cores.parquet'))\n",
    "    \n",
    "    \n",
    "    df_skm_wk = df_skm_wk.loc[df_skm_wk['ivt']>0]\n",
    "\n",
    "\n",
    "    df_wlk = pd.merge(df_trn_wlk, df_skm_wk, \n",
    "                          left_on =['orig_taz', 'dest_taz'], \n",
    "                          right_on=['orig', 'dest'], \n",
    "                          how ='inner')\n",
    "\n",
    "    # PNR Transit\n",
    "    df_skm_pnr_ib = pd.read_parquet(_join(preprocess_dir, period.lower() +'_WLK_TRN_PNR' + '_cores.parquet'))\n",
    "    df_skm_pnr_ib = df_skm_pnr_ib[df_skm_pnr_ib['ivt']>0]\n",
    "\n",
    "    df_skm_pnr_ob = pd.read_parquet(_join(preprocess_dir, period.lower() +'_PNR_TRN_WLK' + '_cores.parquet')) \n",
    "    df_skm_pnr_ob = df_skm_pnr_ob[df_skm_pnr_ob['ivt']>0]\n",
    "\n",
    "    df_trn_pnr_ib = df_trn_pnr[df_trn_pnr['inbound'] == 1] # returning home\n",
    "    df_trn_pnr_ib = pd.merge(df_trn_pnr_ib, df_skm_pnr_ib, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_trn_pnr_ob = df_trn_pnr[df_trn_pnr['inbound'] != 1] # returning home\n",
    "    df_trn_pnr_ob = pd.merge(df_trn_pnr_ob, df_skm_pnr_ob, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_pnr = pd.concat([df_trn_pnr_ib, df_trn_pnr_ob], ignore_index=True)\n",
    "\n",
    "        # KNR Transit\n",
    "    df_skm_knr_ib = pd.read_parquet(_join(preprocess_dir, period.lower() +'_WLK_TRN_KNR' + '_cores.parquet'))\n",
    "    df_skm_knr_ib = df_skm_knr_ib[df_skm_knr_ib['ivt']>0]\n",
    "\n",
    "    df_skm_knr_ob = pd.read_parquet(_join(preprocess_dir, period.lower() +'_KNR_TRN_WLK' + '_cores.parquet')) \n",
    "    df_skm_knr_ob = df_skm_knr_ob[df_skm_knr_ob['ivt']>0]\n",
    "\n",
    "    df_trn_knr_ib = df_trn_knr[df_trn_knr['inbound'] == 1] # returning home\n",
    "    df_trn_knr_ib = pd.merge(df_trn_knr_ib, df_skm_knr_ib, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_trn_knr_ob = df_trn_knr[df_trn_knr['inbound'] != 1] # returning home\n",
    "    df_trn_knr_ob = pd.merge(df_trn_knr_ob, df_skm_knr_ob, \n",
    "                              left_on =['orig_taz', 'dest_taz'], \n",
    "                              right_on=['orig', 'dest'], how ='inner')\n",
    "\n",
    "    df_knr = pd.concat([df_trn_knr_ib, df_trn_knr_ob], ignore_index=True)\n",
    "\n",
    "    df_trn_rail = pd.concat([df_wlk, df_pnr, df_knr], ignore_index=True)\n",
    "    df_temp.append(df_trn_rail)\n",
    "    \n",
    "\n",
    "df_trn_rail = pd.concat(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77af0ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hh_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>orig_purpose</th>\n",
       "      <th>dest_purpose</th>\n",
       "      <th>orig_taz</th>\n",
       "      <th>dest_taz</th>\n",
       "      <th>depart_hour</th>\n",
       "      <th>trip_mode</th>\n",
       "      <th>sampleRate</th>\n",
       "      <th>...</th>\n",
       "      <th>Mode</th>\n",
       "      <th>orig</th>\n",
       "      <th>dest</th>\n",
       "      <th>ivt</th>\n",
       "      <th>wacc</th>\n",
       "      <th>wait</th>\n",
       "      <th>wegr</th>\n",
       "      <th>dtime</th>\n",
       "      <th>xwait</th>\n",
       "      <th>trip_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1777399</td>\n",
       "      <td>4318129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Work</td>\n",
       "      <td>atwork</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WALK_TRANSIT</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>548.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1870289</td>\n",
       "      <td>4478513.0</td>\n",
       "      <td>1</td>\n",
       "      <td>escort</td>\n",
       "      <td>Home</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WALK_TRANSIT</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>548.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1839171</td>\n",
       "      <td>4424217.0</td>\n",
       "      <td>0</td>\n",
       "      <td>eatout</td>\n",
       "      <td>social</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WALK_TRANSIT</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>548.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1715705</td>\n",
       "      <td>4204192.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>othmaint</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WALK_TRANSIT</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>548.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1714331</td>\n",
       "      <td>4201741.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>work</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>WALK_TRANSIT</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "      <td>548.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63438</th>\n",
       "      <td>1612850</td>\n",
       "      <td>3969170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>work</td>\n",
       "      <td>3328</td>\n",
       "      <td>333</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>KNR_TRANSIT</td>\n",
       "      <td>3328</td>\n",
       "      <td>333</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2478.0</td>\n",
       "      <td>7174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63439</th>\n",
       "      <td>1615089</td>\n",
       "      <td>3973315.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>work</td>\n",
       "      <td>3330</td>\n",
       "      <td>2226</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>KNR_TRANSIT</td>\n",
       "      <td>3330</td>\n",
       "      <td>2226</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>5052.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63440</th>\n",
       "      <td>1616438</td>\n",
       "      <td>3976062.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>work</td>\n",
       "      <td>3332</td>\n",
       "      <td>613</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>KNR_TRANSIT</td>\n",
       "      <td>3332</td>\n",
       "      <td>613</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>8155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63441</th>\n",
       "      <td>3469127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>othmaint</td>\n",
       "      <td>1224</td>\n",
       "      <td>1046</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>KNR_TRANSIT</td>\n",
       "      <td>1224</td>\n",
       "      <td>1046</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63442</th>\n",
       "      <td>3109929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Home</td>\n",
       "      <td>eatout</td>\n",
       "      <td>1517</td>\n",
       "      <td>1524</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>KNR_TRANSIT</td>\n",
       "      <td>1517</td>\n",
       "      <td>1524</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2121.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5059.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1787986 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hh_id  person_id  inbound orig_purpose dest_purpose  orig_taz  \\\n",
       "0      1777399  4318129.0        0         Work       atwork       136   \n",
       "1      1870289  4478513.0        1       escort         Home       136   \n",
       "2      1839171  4424217.0        0       eatout       social       136   \n",
       "3      1715705  4204192.0        0         Home     othmaint       136   \n",
       "4      1714331  4201741.0        0         Home         work       136   \n",
       "...        ...        ...      ...          ...          ...       ...   \n",
       "63438  1612850  3969170.0        0         Home         work      3328   \n",
       "63439  1615089  3973315.0        0         Home         work      3330   \n",
       "63440  1616438  3976062.0        0         Home         work      3332   \n",
       "63441  3469127        NaN        0         Home     othmaint      1224   \n",
       "63442  3109929        NaN        0         Home       eatout      1517   \n",
       "\n",
       "       dest_taz  depart_hour  trip_mode  sampleRate  ...          Mode  orig  \\\n",
       "0            10            9          6         1.0  ...  WALK_TRANSIT   136   \n",
       "1            10            8          6         1.0  ...  WALK_TRANSIT   136   \n",
       "2            10            9          6         1.0  ...  WALK_TRANSIT   136   \n",
       "3            10            7          6         1.0  ...  WALK_TRANSIT   136   \n",
       "4            10            8          6         1.0  ...  WALK_TRANSIT   136   \n",
       "...         ...          ...        ...         ...  ...           ...   ...   \n",
       "63438       333            5          8         1.0  ...   KNR_TRANSIT  3328   \n",
       "63439      2226            5          8         1.0  ...   KNR_TRANSIT  3330   \n",
       "63440       613            5          8         1.0  ...   KNR_TRANSIT  3332   \n",
       "63441      1046            5          8         1.0  ...   KNR_TRANSIT  1224   \n",
       "63442      1524            5          8         1.0  ...   KNR_TRANSIT  1517   \n",
       "\n",
       "       dest     ivt    wacc   wait    wegr   dtime  xwait  trip_time  \n",
       "0        10   548.0  1206.0   80.0  1549.0     0.0    0.0     3383.0  \n",
       "1        10   548.0  1206.0   80.0  1549.0     0.0    0.0     3383.0  \n",
       "2        10   548.0  1206.0   80.0  1549.0     0.0    0.0     3383.0  \n",
       "3        10   548.0  1206.0   80.0  1549.0     0.0    0.0     3383.0  \n",
       "4        10   548.0  1206.0   80.0  1549.0     0.0    0.0     3383.0  \n",
       "...     ...     ...     ...    ...     ...     ...    ...        ...  \n",
       "63438   333  1100.0     0.0  130.0  2478.0  7174.0    0.0    10882.0  \n",
       "63439  2226  2206.0     0.0  300.0   727.0  5052.0    0.0     8285.0  \n",
       "63440   613   100.0     0.0  125.0   462.0  8155.0    0.0     8842.0  \n",
       "63441  1046  1156.0     0.0  500.0  2885.0   496.0    0.0     5037.0  \n",
       "63442  1524  1877.0     0.0  500.0  2121.0   561.0    0.0     5059.0  \n",
       "\n",
       "[1787986 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn_rail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75595f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hh_id', 'person_id', 'inbound', 'orig_purpose', 'dest_purpose',\n",
       "       'orig_taz', 'dest_taz', 'depart_hour', 'trip_mode', 'sampleRate',\n",
       "       'trip_type', 'trips', 'transbay_od', 'orig_rdm_zones',\n",
       "       'orig_super_dist', 'orig_county', 'dest_rdm_zones', 'dest_super_dist',\n",
       "       'dest_county', 'home_zone', 'income', 'Income', 'pp_share',\n",
       "       'link21_trip_purp', 'Period', 'Mode', 'orig', 'dest', 'ivt', 'wacc',\n",
       "       'wait', 'wegr', 'dtime', 'xwait', 'trip_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn_rail.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a070c0",
   "metadata": {},
   "source": [
    "# summarise for prioirty population\n",
    "summary_cols = params['description_a1.2']\n",
    "\n",
    "time_periods = ['AM']\n",
    "\n",
    "\n",
    "pp_df = []\n",
    "reg_df = []\n",
    "county_df = []\n",
    "sd_df = []\n",
    "tb_df = []\n",
    "rdm_df = []\n",
    "\n",
    "\n",
    "for columns in summary_cols:\n",
    "    \n",
    "    for period in time_periods:\n",
    "    \n",
    "        df_temp = df_trn_rail[(df_trn_rail[columns] > 0) & (df_trn_rail['Period'] == period.lower())]\n",
    "        \n",
    "        #regional value\n",
    "        region_value = df_temp[columns].mean()\n",
    "        reg_df_temp = pd.DataFrame({'Population': 'Whole Population',\n",
    "                              'Period': period,\n",
    "                              'Value': region_value,\n",
    "                              'Orig_zone' : '',\n",
    "                              'Dest_zone' : '',\n",
    "                              'Zone_ID' : 'Megaregion',\n",
    "                              'Geography' : 'Regional',\n",
    "                              'Metric':summary_cols[columns][1],\n",
    "                              'Submetric':summary_cols[columns][1]+'.1',\n",
    "                              'Description' : summary_cols[columns][0],\n",
    "                              'Units' : summary_cols[columns][2],\n",
    "                              'Metric_name' : summary_cols[columns][3]}, index=[0])\n",
    "        reg_df.append(reg_df_temp)\n",
    "        \n",
    "        # transbay region\n",
    "        tb_value = df_temp[df_temp['transbay_od']==1]\n",
    "        tb_value = tb_value[columns].mean()\n",
    "        \n",
    "        tb_df_temp = pd.DataFrame({'Population': 'Whole Population',\n",
    "                                   'Period': period,\n",
    "                                   'Value': tb_value,\n",
    "                                   'Orig_zone' : '',\n",
    "                                   'Dest_zone' : '',\n",
    "                                   'Zone_ID' : 'Megaregion',\n",
    "                                   'Geography' : 'Transbay',\n",
    "                                   'Metric':summary_cols[columns][1],\n",
    "                                   'Submetric':summary_cols[columns][1]+'.6',\n",
    "                                   'Description' : summary_cols[columns][0],\n",
    "                                   'Units' : summary_cols[columns][2],\n",
    "                                   'Metric_name' : summary_cols[columns][3]}, index=[0])\n",
    "                                    \n",
    "        tb_df.append(tb_df_temp)  \n",
    "                \n",
    "        #county \n",
    "        county_df_temp = df_temp.groupby(['orig_county', 'dest_county'])[columns].mean().reset_index()\n",
    "        county_df_temp = rename_columns(county_df_temp, ['orig_county', 'dest_county', columns])\n",
    "        \n",
    "        county_df_temp['Period'] = period\n",
    "        county_df_temp['Population'] = 'Whole Population'\n",
    "        county_df_temp['Zone_Id'] = ''\n",
    "        county_df_temp['Geography'] = 'County'\n",
    "        county_df_temp['Description'] = summary_cols[columns][0]\n",
    "        county_df_temp['Metric'] = summary_cols[columns][1]\n",
    "        county_df_temp['Submetric'] = summary_cols[columns][1]+'.5'\n",
    "        county_df_temp['Units'] = summary_cols[columns][2]\n",
    "        county_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "        county_df.append(county_df_temp)\n",
    "        \n",
    "        #RDM Zones\n",
    "        rdm_df_temp = df_temp.groupby(['orig_rdm_zones', 'dest_rdm_zones'])[columns].mean().reset_index()\n",
    "        rdm_df_temp =  rename_columns(rdm_df_temp, ['orig_rdm_zones', 'dest_rdm_zones', columns])\n",
    "        \n",
    "        rdm_df_temp['Period'] = period\n",
    "        rdm_df_temp['Population'] = 'Whole Population'\n",
    "        rdm_df_temp['Zone_ID'] = ''\n",
    "        rdm_df_temp['Geography'] = 'RDM'\n",
    "        rdm_df_temp['Description'] = summary_cols[columns][0]     \n",
    "        rdm_df_temp['Metric'] = summary_cols[columns][1]\n",
    "        rdm_df_temp['Submetric'] = summary_cols[columns][1]+'.3'\n",
    "        rdm_df_temp['Units'] = summary_cols[columns][2]\n",
    "        rdm_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "        rdm_df.append(rdm_df_temp)\n",
    "        \n",
    "        #super district\n",
    "        sd_df_temp = df_temp.groupby(['orig_super_dist', 'dest_super_dist'])[columns].mean().reset_index()\n",
    "        sd_df_temp = rename_columns(sd_df_temp, ['orig_super_dist', 'dest_super_dist', columns])\n",
    "        \n",
    "        sd_df_temp['Period'] = period\n",
    "        sd_df_temp['Population'] = 'Whole Population'\n",
    "        sd_df_temp['Zone_ID'] = ''\n",
    "        sd_df_temp['Geography'] = 'Superdistrict'\n",
    "        sd_df_temp['Description'] = summary_cols[columns][0]\n",
    "        sd_df_temp['Metric'] = summary_cols[columns][1]\n",
    "        sd_df_temp['Submetric'] = summary_cols[columns][1]+'.4'\n",
    "        sd_df_temp['Units'] = summary_cols[columns][2]\n",
    "        sd_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "        sd_df.append(sd_df_temp)\n",
    "                \n",
    "        #prioirty population\n",
    "        df_temp['pp_share'] = df_temp['pp_share']/100\n",
    "        pp_value = weighted_average(df_temp, 'ivt', 'pp_share')\n",
    "        pp_df_temp = pd.DataFrame({'Population': 'Prioirty Population',\n",
    "                              'Period': period,\n",
    "                              'Value': pp_value,\n",
    "                              'Orig_zone' : '',\n",
    "                              'Dest_zone' : '',\n",
    "                              'Zone_ID' : 'Megaregion',\n",
    "                              'Geography' : 'Regional',\n",
    "                              'Metric':summary_cols[columns][1],\n",
    "                              'Submetric':summary_cols[columns][1]+'.2',\n",
    "                              'Description' : summary_cols[columns][0],\n",
    "                              'Units' : summary_cols[columns][2],\n",
    "                              'Metric_name' : summary_cols[columns][3]}, index=[0])\n",
    "        pp_df.append(pp_df_temp)\n",
    "    \n",
    "    \n",
    "pp_df = pd.concat(pp_df)\n",
    "reg_df = pd.concat(reg_df)\n",
    "county_df = pd.concat(county_df)\n",
    "sd_df = pd.concat(sd_df)\n",
    "rdm_df = pd.concat(rdm_df)\n",
    "tb_df = pd.concat(tb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2674bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ivt': ['in-vehicle travel time',\n",
       "  'A1.2',\n",
       "  'minutes',\n",
       "  'actual in vehicle travel time'],\n",
       " 'wait': ['wait time', 'A1.3', 'minutes', 'actual wait time'],\n",
       " 'wacc': ['walk access time', 'A1.4', 'minutes', 'actual walk access time'],\n",
       " 'wegr': ['walk egress time', 'A1.5', 'minutes', 'actual walk egress time'],\n",
       " 'dtime': ['drive time', 'A1.6', 'minutes', 'actual drive time'],\n",
       " 'xwait': ['transfer time', 'A1.7', 'minutes', 'actual transfer time'],\n",
       " 'trip_time': ['total trip time', 'A1.8', 'minutes', 'actual total trip time']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_cols = params['description_a1.2']\n",
    "summary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efdb2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivt\n",
      "30 A1.2.1 actual in vehicle travel time\n",
      "30 A1.2.2 actual in vehicle travel time\n",
      "2391 A1.2.3 actual in vehicle travel time\n",
      "625346 A1.2.4 actual in vehicle travel time\n",
      "23747 A1.2.5 actual in vehicle travel time\n",
      "30 A1.2.6 actual in vehicle travel time\n",
      "625346 A1.2.7 actual in vehicle travel time\n",
      "wait\n",
      "30 A1.3.1 actual wait time\n",
      "30 A1.3.2 actual wait time\n",
      "2391 A1.3.3 actual wait time\n",
      "625346 A1.3.4 actual wait time\n",
      "23747 A1.3.5 actual wait time\n",
      "30 A1.3.6 actual wait time\n",
      "625346 A1.3.7 actual wait time\n",
      "wacc\n",
      "30 A1.4.1 actual walk access time\n",
      "30 A1.4.2 actual walk access time\n",
      "2170 A1.4.3 actual walk access time\n",
      "503342 A1.4.4 actual walk access time\n",
      "20982 A1.4.5 actual walk access time\n",
      "30 A1.4.6 actual walk access time\n",
      "503342 A1.4.7 actual walk access time\n",
      "wegr\n",
      "30 A1.5.1 actual walk egress time\n",
      "30 A1.5.2 actual walk egress time\n",
      "2303 A1.5.3 actual walk egress time\n",
      "523090 A1.5.4 actual walk egress time\n",
      "21872 A1.5.5 actual walk egress time\n",
      "30 A1.5.6 actual walk egress time\n",
      "523090 A1.5.7 actual walk egress time\n",
      "dtime\n",
      "30 A1.6.1 actual drive time\n",
      "30 A1.6.2 actual drive time\n",
      "2356 A1.6.3 actual drive time\n",
      "502278 A1.6.4 actual drive time\n",
      "23171 A1.6.5 actual drive time\n",
      "30 A1.6.6 actual drive time\n",
      "502278 A1.6.7 actual drive time\n",
      "xwait\n",
      "30 A1.7.1 actual transfer time\n",
      "30 A1.7.2 actual transfer time\n",
      "2365 A1.7.3 actual transfer time\n",
      "525671 A1.7.4 actual transfer time\n",
      "23262 A1.7.5 actual transfer time\n",
      "30 A1.7.6 actual transfer time\n",
      "525671 A1.7.7 actual transfer time\n",
      "trip_time\n",
      "30 A1.8.1 actual total trip time\n",
      "30 A1.8.2 actual total trip time\n",
      "2391 A1.8.3 actual total trip time\n",
      "625346 A1.8.4 actual total trip time\n",
      "23747 A1.8.5 actual total trip time\n",
      "30 A1.8.6 actual total trip time\n",
      "625346 A1.8.7 actual total trip time\n"
     ]
    }
   ],
   "source": [
    "#time_periods = ['AM']\n",
    "\n",
    "\n",
    "pp_df = []\n",
    "reg_df = []\n",
    "county_df = []\n",
    "sd_df = []\n",
    "tb_df = []\n",
    "rdm_df = []\n",
    "\n",
    "\n",
    "for columns in summary_cols:\n",
    "    \n",
    "    #for period in time_periods:\n",
    "    print(columns)\n",
    "    df_temp = df_trn_rail[(df_trn_rail[columns] > 0)]\n",
    "    df_temp[columns+'_trips'] = (df_temp[columns] * df_temp['trips'])/100\n",
    "\n",
    "    #regional value\n",
    "    reg_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    reg_df_temp1 = reg_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    reg_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    reg_df_temp2 = reg_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    \n",
    "    #reg_df_temp1 = df_temp.groupby(['Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #reg_df_temp2 = df_temp.groupby(['Period'])['trips'].sum().reset_index()\n",
    "    reg_df_temp = pd.merge(reg_df_temp1, reg_df_temp2, on=['Period', 'Income'], how='left')\n",
    "    reg_df_temp[columns] = reg_df_temp[columns+'_trips']/reg_df_temp['trips']\n",
    "    reg_df_temp = reg_df_temp[['Period', 'Income', columns]]\n",
    "    reg_df_temp = reg_df_temp.rename(columns={columns:'Value'})\n",
    "    reg_df_temp['Population'] = 'Whole Population'\n",
    "    reg_df_temp['Origin_zone'] = ''\n",
    "    reg_df_temp['Dest_zone'] = ''\n",
    "    reg_df_temp['Zone_ID'] = ''\n",
    "    reg_df_temp['Concept_ID'] = concept_id\n",
    "    reg_df_temp['Geography'] = 'Regional'\n",
    "    reg_df_temp['Purpose'] = ''\n",
    "    reg_df_temp['Mode'] = ''\n",
    "    reg_df_temp['Total_Increment'] = ''\n",
    "    reg_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    reg_df_temp['Submetric'] = summary_cols[columns][1]+'.1'\n",
    "    reg_df_temp['Description'] = 'Average ' + summary_cols[columns][0]+ ' in the region'\n",
    "    reg_df_temp['Units'] = summary_cols[columns][2]\n",
    "    reg_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #reg_df.append(reg_df_temp)\n",
    "\n",
    "    # transbay region\n",
    "    tb_df_t = df_temp[df_temp['transbay_od']==1]\n",
    "    tb_df_temp = tb_df_t.copy()\n",
    "    tb_df_temp1 = summarize_all_combinations(tb_df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    tb_df_temp1 = tb_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    tb_df_temp2 = summarize_all_combinations(tb_df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    tb_df_temp2 = tb_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    \n",
    "    #tb_df_temp1 = tb_df_temp.groupby(['Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #tb_df_temp2 = tb_df_temp.groupby(['Period'])['trips'].sum().reset_index()\n",
    "    tb_df_temp = pd.merge(tb_df_temp1, tb_df_temp2, on=['Period', 'Income'], how='left')\n",
    "    tb_df_temp[columns] = tb_df_temp[columns+'_trips']/tb_df_temp['trips']\n",
    "    tb_df_temp = tb_df_temp[['Period', 'Income', columns]]\n",
    "    tb_df_temp = tb_df_temp.rename(columns={columns:'Value'})\n",
    "\n",
    "    tb_df_temp['Concept_ID'] = concept_id\n",
    "    tb_df_temp['Population'] = 'Whole Population'\n",
    "    tb_df_temp['Origin_zone'] = ''\n",
    "    tb_df_temp['Dest_zone'] = ''\n",
    "    tb_df_temp['Zone_ID'] = ''\n",
    "    tb_df_temp['Purpose'] = ''\n",
    "    tb_df_temp['Mode'] = ''\n",
    "    tb_df_temp['Geography'] = 'Transbay'\n",
    "    tb_df_temp['Total_Increment'] = ''\n",
    "    tb_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    tb_df_temp['Submetric'] = summary_cols[columns][1]+'.2'\n",
    "    tb_df_temp['Description'] = 'Average' + summary_cols[columns][0] + ' in the transbay region'\n",
    "    tb_df_temp['Units'] = summary_cols[columns][2]\n",
    "    tb_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "\n",
    "    #tb_df.append(tb_df_temp)         \n",
    "\n",
    "    #county \n",
    "    #county_df_temp1 = df_temp.groupby(['orig_county', 'dest_county', 'Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #county_df_temp2 = df_temp.groupby(['orig_county', 'dest_county', 'Period'])['trips'].sum().reset_index()\n",
    "    county_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['orig_county', 'dest_county', 'Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    county_df_temp1 = county_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    county_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['orig_county', 'dest_county', 'Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    county_df_temp2 = county_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    \n",
    "    county_df_temp = pd.merge(county_df_temp1, county_df_temp2, on=['orig_county', 'dest_county', 'Period', 'Income'], how='left')\n",
    "    county_df_temp[columns] = county_df_temp[columns+'_trips']/county_df_temp['trips']\n",
    "    county_df_temp = county_df_temp[['orig_county', 'dest_county', 'Period', 'Income' ,columns]]\n",
    "    county_df_temp = county_df_temp.rename(columns={columns:'Value', \n",
    "                                                    'orig_county': 'Origin_zone',\n",
    "                                                    'dest_county': 'Dest_zone'})\n",
    "    county_df_temp['Population'] = 'Whole Population'\n",
    "    county_df_temp['Zone_ID'] = ''\n",
    "    county_df_temp['Concept_ID'] = concept_id\n",
    "    county_df_temp['Geography'] = 'County'\n",
    "    county_df_temp['Purpose'] = ''\n",
    "    county_df_temp['Mode'] = ''\n",
    "    county_df_temp['Total_Increment'] = ''\n",
    "    county_df_temp['Description'] = 'Average ' + summary_cols[columns][0] + ' in the origin and destination county'\n",
    "    county_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    county_df_temp['Submetric'] = summary_cols[columns][1]+'.3'\n",
    "    county_df_temp['Units'] = summary_cols[columns][2]\n",
    "    county_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #county_df.append(county_df_temp)\n",
    "\n",
    "\n",
    "    #RDM Zones\n",
    "    rdm_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    rdm_df_temp1 = rdm_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    rdm_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    rdm_df_temp2 = rdm_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    #rdm_df_temp1 = df_temp.groupby(['orig_rdm_zones', 'dest_rdm_zones', 'Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #rdm_df_temp2 = df_temp.groupby(['orig_rdm_zones', 'dest_rdm_zones', 'Period'])['trips'].sum().reset_index()\n",
    "    rdm_df_temp = pd.merge(rdm_df_temp1, rdm_df_temp2, on=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], how='left')\n",
    "    rdm_df_temp[columns] = rdm_df_temp[columns+'_trips']/rdm_df_temp['trips']\n",
    "    rdm_df_temp = rdm_df_temp[['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income', columns]]\n",
    "    rdm_df_temp = rdm_df_temp.rename(columns={'orig_rdm_zones': 'Origin_zone', \n",
    "                                              'dest_rdm_zones': 'Dest_zone', \n",
    "                                              columns: 'Value'})\n",
    "\n",
    "    rdm_df_temp['Population'] = 'Whole Population'\n",
    "    rdm_df_temp['Zone_ID'] = ''\n",
    "    rdm_df_temp['Geography'] = 'RDM'\n",
    "    rdm_df_temp['Concept_ID'] = concept_id\n",
    "    rdm_df_temp['Purpose'] = ''\n",
    "    rdm_df_temp['Mode'] = ''\n",
    "    rdm_df_temp['Total_Increment'] = ''\n",
    "    rdm_df_temp['Description'] = summary_cols[columns][0] + ' in the origin and destination RDM zones'  \n",
    "    rdm_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    rdm_df_temp['Submetric'] = summary_cols[columns][1]+'.4'\n",
    "    rdm_df_temp['Units'] = summary_cols[columns][2]\n",
    "    rdm_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #rdm_df.append(rdm_df_temp)\n",
    "\n",
    "        #super district   \n",
    "    sd_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['orig_super_dist', 'dest_super_dist', 'Period', 'Income'], \n",
    "                                                  summary_column=columns+'_trips')\n",
    "    sd_df_temp1 = sd_df_temp1.rename(columns={'Value': columns+'_trips'})\n",
    "    \n",
    "    sd_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['orig_super_dist', 'dest_super_dist', 'Period', 'Income'], \n",
    "                                                  summary_column='trips')\n",
    "    sd_df_temp2 = sd_df_temp2.rename(columns={'Value': 'trips'})\n",
    "    #sd_df_temp1 = df_temp.groupby(['orig_super_dist', 'dest_super_dist', 'Period'])[columns+'_trips'].sum().reset_index()\n",
    "    #sd_df_temp2 = df_temp.groupby(['orig_super_dist', 'dest_super_dist', 'Period'])['trips'].sum().reset_index()\n",
    "    \n",
    "    sd_df_temp = pd.merge(sd_df_temp1, sd_df_temp2, on=['orig_super_dist', 'dest_super_dist', 'Period', 'Income'], how='left')\n",
    "    sd_df_temp[columns] = sd_df_temp[columns+'_trips']/sd_df_temp['trips']\n",
    "    sd_df_temp = sd_df_temp[['orig_super_dist', 'dest_super_dist', 'Period', 'Income', columns]]\n",
    "    sd_df_temp = sd_df_temp.rename(columns={'orig_super_dist': 'Origin_zone', \n",
    "                                            'dest_super_dist': 'Dest_zone',\n",
    "                                             columns: 'Value'})\n",
    "    sd_df_temp['Population'] = 'Whole Population'\n",
    "    sd_df_temp['Zone_ID'] = ''\n",
    "    sd_df_temp['Concept_ID'] = concept_id\n",
    "    sd_df_temp['Purpose'] = ''\n",
    "    sd_df_temp['Mode'] = ''\n",
    "    sd_df_temp['Total_Increment'] = ''\n",
    "    sd_df_temp['Geography'] = 'Superdistrict'\n",
    "    sd_df_temp['Description'] = summary_cols[columns][0] + ' in the origin and destination Super district'  \n",
    "    sd_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    sd_df_temp['Submetric'] = summary_cols[columns][1]+'.5'\n",
    "    sd_df_temp['Units'] = summary_cols[columns][2]\n",
    "    sd_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #sd_df.append(sd_df_temp)\n",
    "\n",
    "        #prioirty population\n",
    "    df_temp['pp_share'] = df_temp['pp_share']/100\n",
    "    df_temp['pp_trips'] = df_temp['pp_share'] * df_temp['trips']\n",
    "    df_temp['pp_'+columns] = df_temp['pp_trips'] * df_temp[columns] / 100\n",
    "    \n",
    "    pp_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column='pp_'+columns)\n",
    "    pp_df_temp1 = pp_df_temp1.rename(columns={'Value': 'pp_'+columns})\n",
    "    \n",
    "    pp_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['Period', 'Income'], \n",
    "                                                  summary_column='pp_trips')\n",
    "    pp_df_temp2 = pp_df_temp2.rename(columns={'Value': 'pp_trips'})\n",
    "\n",
    "    #pp_df_temp1 = df_temp.groupby(['Period'])['pp_'+columns].sum().reset_index()\n",
    "    #pp_df_temp2 = df_temp.groupby(['Period'])['pp_trips'].sum().reset_index()\n",
    "    pp_df_temp = pd.merge(pp_df_temp1, pp_df_temp2, on=['Period', 'Income'], how='left')\n",
    "    pp_df_temp[columns] = pp_df_temp['pp_'+columns]/pp_df_temp['pp_trips']\n",
    "    pp_df_temp = pp_df_temp[['Period', 'Income' ,columns]]\n",
    "    pp_df_temp = pp_df_temp.rename(columns={columns:'Value'})\n",
    "\n",
    "    pp_df_temp['Population'] = 'Prioirty Population'\n",
    "    pp_df_temp['Origin_zone'] = ''\n",
    "    pp_df_temp['Dest_zone'] = ''\n",
    "    pp_df_temp['Zone_ID'] = ''\n",
    "    pp_df_temp['Purpose'] = ''\n",
    "    pp_df_temp['Mode'] = ''\n",
    "    pp_df_temp['Concept_ID'] = concept_id\n",
    "    pp_df_temp['Geography'] = 'Region'\n",
    "    pp_df_temp['Total_Increment'] = ''\n",
    "    pp_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    pp_df_temp['Submetric'] = summary_cols[columns][1]+'.6'\n",
    "    pp_df_temp['Description'] = summary_cols[columns][0] + ' in the region'\n",
    "    pp_df_temp['Units'] = summary_cols[columns][2]\n",
    "    pp_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #pp_df.append(pp_df_temp)\n",
    "    \n",
    "    pp_rdm_df_temp1 = summarize_all_combinations(df_temp, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                                  summary_column='pp_'+columns)\n",
    "    pp_rdm_df_temp1 = pp_rdm_df_temp1.rename(columns={'Value': 'pp_'+columns})\n",
    "    \n",
    "    pp_rdm_df_temp2 = summarize_all_combinations(df_temp, groupby_columns=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], \n",
    "                                                  summary_column='pp_trips')\n",
    "    pp_rdm_df_temp2 = pp_rdm_df_temp2.rename(columns={'Value': 'pp_trips'})\n",
    "    \n",
    "    pp_rdm_df_temp = pd.merge(pp_rdm_df_temp1, pp_rdm_df_temp2, on=['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income'], how='left')\n",
    "    pp_rdm_df_temp[columns] = pp_rdm_df_temp['pp_'+columns]/pp_rdm_df_temp['pp_trips']\n",
    "    pp_rdm_df_temp = pp_rdm_df_temp[['orig_rdm_zones', 'dest_rdm_zones', 'Period', 'Income', columns]]\n",
    "    pp_rdm_df_temp = pp_rdm_df_temp.rename(columns={columns:'Value',\n",
    "                                                    'orig_rdm_zones': 'Origin_zone', \n",
    "                                                    'dest_rdm_zones': 'Dest_zone'})\n",
    "    \n",
    "    pp_rdm_df_temp['Population'] = 'Prioirty Population'\n",
    "    #pp_rdm_df_temp['Origin_zone'] = ''\n",
    "    #pp_rdm_df_temp['Dest_zone'] = ''\n",
    "    pp_rdm_df_temp['Zone_ID'] = ''\n",
    "    pp_rdm_df_temp['Purpose'] = ''\n",
    "    pp_rdm_df_temp['Mode'] = ''\n",
    "    pp_rdm_df_temp['Concept_ID'] = concept_id\n",
    "    pp_rdm_df_temp['Geography'] = 'RDM'\n",
    "    pp_rdm_df_temp['Total_Increment'] = ''\n",
    "    pp_rdm_df_temp['Metric_ID'] = summary_cols[columns][1]\n",
    "    pp_rdm_df_temp['Submetric'] = summary_cols[columns][1]+'.7'\n",
    "    pp_rdm_df_temp['Description'] = 'Average ' + summary_cols[columns][0] + ' in the region'\n",
    "    pp_rdm_df_temp['Units'] = summary_cols[columns][2]\n",
    "    pp_rdm_df_temp['Metric_name'] = summary_cols[columns][3]\n",
    "    #pp_df_rdm.append(pp_rdm_df_temp)\n",
    "    \n",
    "    all_dfs = [reg_df_temp, tb_df_temp, county_df_temp, rdm_df_temp, sd_df_temp, pp_df_temp, pp_rdm_df_temp]\n",
    "\n",
    "    for dfs in all_dfs:\n",
    "        metric_name = '_' + summary_cols[columns][3].replace(' ', '_') + '_'\n",
    "        dfs = dfs.reset_index(drop=True)\n",
    "        dfs = dfs[perf_measure_columns]\n",
    "        file_name = dfs['Submetric'][0]\n",
    "        geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "        dfs.to_csv(_join(summary_dir, file_name + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "        print(len(dfs), file_name, dfs['Metric_name'][0])\n",
    "\n",
    "    combined_df = pd.concat([reg_df_temp, tb_df_temp, county_df_temp, rdm_df_temp, df_temp, pp_df_temp]).reset_index(drop=True)\n",
    "    combined_df.to_csv(_join(summary_dir, summary_cols[columns][1] + metric_name + concept_id + '_region' +filename_extension+'.csv'), index=None)\n",
    "       \n",
    "#pp_df = pd.concat(pp_df)\n",
    "#reg_df = pd.concat(reg_df)\n",
    "#county_df = pd.concat(county_df)\n",
    "#sd_df = pd.concat(sd_df)\n",
    "#rdm_df = pd.concat(rdm_df)\n",
    "#tb_df = pd.concat(tb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a508b939",
   "metadata": {},
   "source": [
    "all_dfs = pd.concat([reg_df, tb_df, county_df, rdm_df, sd_df, pp_df], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "unique_metric_ids = all_dfs['Metric_ID'].unique()\n",
    "\n",
    "for mids in unique_metric_ids:\n",
    "    print(mids)\n",
    "    dfs = all_dfs.loc[all_dfs['Metric_ID']==mids]\n",
    "    usbmi = dfs['Submetric'].unique()\n",
    "    \n",
    "    for mi in usbmi:\n",
    "        print(mi)\n",
    "        dfs_temp = dfs.loc[dfs['Submetric'] == mi]\n",
    "        dfs_temp = dfs_temp[perf_measure_columns]\n",
    "        dfs_temp = dfs_temp.reset_index(drop=True)\n",
    "        file_name = mi \n",
    "        metric_name = dfs_temp['Metric_name'][0].replace(' ', '_')\n",
    "        geography = '_' + dfs['Geography'][0].replace(' ', '_')\n",
    "        dfs_temp.to_csv(_join(summary_dir, file_name + '_' + metric_name + concept_id + geography + filename_extension + '.csv'), index=None)\n",
    "        print(len(dfs_temp), file_name, dfs_temp['Metric_name'][0], dfs_temp['Value'].sum())\n",
    "    \n",
    "    dfs = dfs.reset_index(drop=True)\n",
    "    file_name = mids \n",
    "    metric_name = dfs['Metric_name'][0]\n",
    "    dfs.to_csv(_join(summary_dir, file_name + metric_name + '_' + concept_id + '_region' + filename_extension +  '.csv'), index=None)\n",
    "    print(len(dfs), file_name, dfs['Metric_name'][0], dfs['Value'].sum())\n",
    "    \n",
    "    #'A3.1' + '_weekday_linked_trips_' + concept_id + '_region' +filename_extension+'.csv'\n",
    "    \n",
    "    #metric_name = dfs['Metric_name'][0]\n",
    "    #\n",
    "    #\n",
    "    #dfs.to_csv(_join(summary_dir, metric_name + file_name + filename_extension +  '.csv'), index=None)\n",
    "    #print(len(dfs), file_name, dfs['Metric_name'][0], dfs['Value'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31594c",
   "metadata": {},
   "source": [
    "## B2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa80bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6d8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73555e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
